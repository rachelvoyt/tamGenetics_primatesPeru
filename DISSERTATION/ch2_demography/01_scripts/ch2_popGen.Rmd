---
title: "ch2_popGen"
author: "Rachel Voyt"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1 Overview

Pop gen stats

Resources: - Tom Jenkins tutorial
(<https://tomjenkins.netlify.app/tutorials/r-popgen-getting-started/>)

# 2 Packages

```{r}
library(adegenet)
library(ggpubr)
library(gt)
library(gtExtras)
library(hierfstat)

library(paletteer) # https://r-graph-gallery.com/color-palette-finder.html
my_colors <- paletteer::paletteer_d("ghibli::PonyoLight")
print(my_colors)

#install_github("nikostourvas/PopGenUtils")
library("PopGenUtils")
library(poppr)
library(reshape2)
library(RColorBrewer)
library(scales)
library(data.table)
library(tidyverse)

library(conflicted)
conflicts_prefer(base::unique)
conflicts_prefer(base::duplicated)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::lag)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::slice)
conflicts_prefer(purrr::reduce)

source("./project_scripts/ravo_ch2Scripts.R")
source("./project_scripts/ravo_gtScripts.R")
#if (!require("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("msa")
source("./project_scripts/GTscore/GTscore_modified.R")
source("project_scripts/ggplot_theme_Publication-2.R") # for pretty ggplot themes
```

# 3 Data

## 3.1 metadata

```{r}
md <- read.csv("./metadataReconciliation/tamRun5_metadata_v5.csv") %>%
  mutate(captureYear = str_sub(captureDate, 1, 4)) %>%
  relocate(captureYear, .after = captureDate)

md_hairOnly <- md %>%
  filter(sampleType == "hair")

sampleRef <- read.csv("./project_data/master_sampleInfo_v2.csv")

lociRef <- read.csv("./project_data/master_lociInfo.csv")
```

## 3.2 capData

Capture data includes all records of individual captures from 2009-2019.

Use the latest version of capData_byIndiv (from
tamGenetics_paper3_dataOrganization), then 1) filter to first capture
for each animalID 2) filter again to animalIDs in tamRun5

**note** exclude those in capData w/"UNK" animalID; did a lot of digging
in ch2_dataOrganization.Rmd and most likely these entries need to be
ditched

```{r}
capData_2009to2023 <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/captureData_byIndividual_v6.csv") %>%
  # ditch UNK animalIDs
  filter(animalID != "UNK") %>%
  mutate(
    captureYear = str_sub(captureDate, 1, 4),
    captureYear = as.numeric(captureYear)
  ) %>%
  relocate(captureYear, .after = captureDate)
  # adjust rowID 1 ageClass to "UNK" >> keep as adult for now
  #mutate(
  #  ageClass = case_when(
  #    rowID == 1 ~ "UNK",
  #    .default = ageClass
  #  )
  #)

capData_2009to2019 <- capData_2009to2023 %>%
  filter(rowID <= 613)

capData_2009to2023_firstEntry <- capData_2009to2023[match(unique(capData_2009to2023$animalID), capData_2009to2023$animalID),] %>%
  select(rowID, captureDate, captureYear, animalID, ageClass, ageClass_classifier, animalName1, animalName2, groupName, species, sex, notes_MD, notes_RV)

capData_2009to2019_firstEntry <- capData_2009to2023_firstEntry %>%
  filter(rowID <= 613)
```

## 3.3 capHist

Filtered to 2009-2019 only

```{r}
capHist_2009to2019 <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/captureHistories_byIndiv_2009to2023.csv", colClasses = "character") %>%
  # filter to 2009-2019 only
  mutate(ch = str_sub(ch, 1, 11)) %>%
  filter(ch != "00000000000")
```

## 3.4 birth/death year

```{r}
birthData <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/birthAssignments_capData_tamRun5_v3.csv") %>%
  # edit for animalID 90 ageClass recode to juvenile
  mutate(
    age_capData = case_when(
      animalID == 90 ~ "juvenile",
      .default = age_capData
    ),
    birthYear_est = case_when(
      animalID == 90 ~ 2010,
      .default = birthYear_est
    )
  )

birthAssignments <- birthData %>%
  select(animalID, birthYear_est, species) %>%
  na.omit() %>%
  distinct() %>%
  arrange(animalID)

deathData <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/deathAssignments_capData_tamRun5_v1.csv")

deathAssignments <- deathData %>%
  select(animalID, deathYear_est) %>%
  na.omit() %>%
  distinct() %>%
  arrange(animalID) %>%
  mutate(animalID = as.character(animalID))
```

## 3.5 parityAssignments

Using "parity2" -- meaning either left or right (vs avg) meets threshold

```{r}
parityAssignments <- get_parityStatus(capData_file = capData_2009to2019) %>%
  select(animalID, captureDate, parity2) %>%
  dplyr::rename("parity" = "parity2") %>%
  mutate(
    captureYear = str_sub(captureDate, 1, 4)
  ) %>%
  #select(-captureDate) %>%
  distinct() %>%
  merge(., sampleRef[, c("animalID", "birthYear_est", "natalGroup")], by = "animalID", all.x = T) %>%
  merge(., capData_2009to2019[, c("animalID", "captureDate", "groupName")], by = c("animalID", "captureDate")) %>%
  dplyr::rename("capGroup" = "groupName")

parousOnly <- parityAssignments %>%
  filter(parity == "parous") %>%
  arrange(animalID, captureYear)

parityAssigments_firstParous <- parousOnly[match(unique(parousOnly$animalID), parousOnly$animalID),] %>%
  filter(parity == "parous") %>%
  dplyr::rename("parityYear" = "captureYear") %>%
  mutate(natalCap_match = natalGroup == capGroup)
```

## 3.6 likelyTwins

created in ch2_demography.Rmd

```{r}
likelyTwins <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/twinList_tamRun5_6June2024.csv")

twinList <- likelyTwins %>%
  select(twin1, twin2, twin3) %>%
  arrange(twin1) %>%
  mutate(twinSet = str_c("twinSet", row_number())) %>%
  pivot_longer(-twinSet,
               names_to = "twinID",
               values_to = "animalID") %>%
  na.omit() %>%
  merge(., sampleRef[, c("animalID", "sampleID_franz", "seqRun", "sampleType")], by = "animalID", all.x = T) %>%
  filter(seqRun == "run5") %>%
  filter(sampleType == "hair") %>%
  relocate(twinSet) %>%
  arrange(twinSet)
```

## 3.7 genos

```{r}
genos10x <- read.table("./05_tamRun5/03_run5GTscore/fullSet_polyGenResults_singleSNP_10x.txt", header = T, na.strings = "0") %>%
  `rownames<-`(sub('[_][^_]+$', '', rownames(.)))
```

quick overview --

species sex count 1 LWED F 64 2 LWED M 70 3 SIMP F 47 4 SIMP M 52

samples from indivs born during study period: species count 1 LWED 62 2
SIMP 52

```{r}
hairGenoData_overview <- md %>%
  filter(species %in% c("LWED", "SIMP")) %>%
  filter(sampleType == "hair") %>%
  select(animalID, species, sex) %>%
  distinct()

# number of F & M by species
hairGenoData_overview %>%
  group_by(species, sex) %>%
  summarise(count = n()) %>%
  as.data.frame()

# number born during study period (by species)
hairGenoData_overview %>%
  filter(animalID %in% birthAssignments$animalID) %>%
  group_by(species) %>%
  summarise(count = n()) %>%
  as.data.frame()
```

# 4 Basic demography stuff

## Time in study

**2009 to 2023**

The dataframe below includes the animalIDs of all individuals in
capData_byIndiv_v5 from 2009 to 2023. It includes the first and last
years and groups in which the individual was captured as well as the
difference between those two years.

```{r}
# first anti-sort for last entries in capture records
capData_2009to2023_antiSort <- capData_2009to2023 %>%
  arrange(desc(rowID))

# then create df
capData_2009to2023_first.lastEntry <- capData_2009to2023_antiSort[match(unique(capData_2009to2023_antiSort$animalID), capData_2009to2023_antiSort$animalID),] %>%
  
  arrange(as.numeric(animalID)) %>%
  select(animalID, captureYear, groupName, species, sex) %>%
  dplyr::rename("captureYear_last" = "captureYear",
                "groupName_last" = "groupName") %>%
  merge(., capData_2009to2023_firstEntry[, c("animalID", "captureDate", "groupName")], by = "animalID") %>%
  mutate(
    captureYear_first = str_sub(captureDate, 1, 4)
  ) %>%
  select(-captureDate) %>%
  dplyr::rename("groupName_first" = "groupName") %>%
  mutate(
    captureYear_first = as.numeric(captureYear_first),
    captureYear_last = as.numeric(captureYear_last),
    diff_lastFirst = captureYear_last - captureYear_first,
    groupMatch = case_when(
      groupName_first == groupName_last ~ "yes",
      .default = "no"
    )
  ) %>%
  relocate(animalID, groupName_first, groupName_last, groupMatch, captureYear_first, captureYear_last, diff_lastFirst) %>%
  
  # see who started in study as a juvenile
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  
  # then calculate age at last capture
  mutate(
    age_lastCap = case_when(
      !is.na(birthYear_est) ~ diff_lastFirst,
      .default = NA
    )
  )
```

**2009 to 2019**

```{r}
# first anti-sort for last entries in capture records
capData_2009to2019_antiSort <- capData_2009to2019 %>%
  arrange(desc(rowID))

# then create df
capData_2009to2019_first.lastEntry <- capData_2009to2019_antiSort[match(unique(capData_2009to2019_antiSort$animalID), capData_2009to2019_antiSort$animalID),] %>%
  
  arrange(as.numeric(animalID)) %>%
  select(animalID, captureYear, groupName, species, sex) %>%
  dplyr::rename("captureYear_last" = "captureYear",
                "groupName_last" = "groupName") %>%
  merge(., capData_2009to2019_firstEntry[, c("animalID", "captureDate", "groupName")], by = "animalID") %>%
  mutate(
    captureYear_first = str_sub(captureDate, 1, 4)
  ) %>%
  select(-captureDate) %>%
  dplyr::rename("groupName_first" = "groupName") %>%
  mutate(
    captureYear_first = as.numeric(captureYear_first),
    captureYear_last = as.numeric(captureYear_last),
    diff_lastFirst = captureYear_last - captureYear_first,
    groupMatch = case_when(
      groupName_first == groupName_last ~ "yes",
      .default = "no"
    )
  ) %>%
  relocate(animalID, groupName_first, groupName_last, groupMatch, captureYear_first, captureYear_last, diff_lastFirst) %>%
  
  # see who started in study as a juvenile
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  
  # then calculate age at last capture
  mutate(
    age_lastCap = case_when(
      !is.na(birthYear_est) ~ diff_lastFirst,
      .default = NA
    )
  )
```


## Indivs present per year

Maybe good to get a list of who was present in the population each year??

```{r}
library(dplyr)
library(purrr)
conflicts_prefer(purrr::reduce)

presenceMatrix <- capData_2009to2023_first.lastEntry %>%
  select(animalID, species, sex, captureYear_first, captureYear_last) %>%
  reduce(2009:2023, .init = ., ~ .x %>%
    mutate("{.y}" := ifelse(.y >= captureYear_first & .y <= captureYear_last, animalID, NA))) %>%
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  relocate(birthYear_est, .before = captureYear_first)

colSums(!is.na(presenceMatrix)) %>%
  as.data.frame()
```

## Group numbers

```{r}
# 15 lwed groups, 9 simp groups
capData_2009to2019 %>%
  filter(groupName != "Loners") %>%
  group_by(species) %>%
  summarise(nGroups = length(unique(groupName)))

# really quick and dirty avg group size estimates...
lwed_grpSizes <- capData_2009to2019 %>%
  filter(species == "LWED") %>%
  group_by(groupName, captureYear) %>%
  summarise(count = n()) %>%
  filter(groupName != "Loners")
round(mean(lwed_grpSizes$count)) # 5

simp_grpSizes <- capData_2009to2019 %>%
  filter(species == "SIMP") %>%
  group_by(groupName, captureYear) %>%
  summarise(count = n()) %>%
  filter(groupName != "Loners")
round(mean(simp_grpSizes$count)) # 5
```

## Group membership

```{r}
groupMembership <- capData_2009to2019 %>%
  select(animalID, captureDate, captureYear, groupName) %>%
  # first need to get cases w/multiple groups in one year into single col
  distinct() %>%
  mutate(temp = str_c(animalID, "_", captureYear)) %>%
  arrange(temp, captureDate) %>%
  mutate(dup = if_else(duplicated(temp), "entry2", "entry1")) %>%
  select(temp, groupName, dup) %>%
  distinct() %>%
  pivot_wider(names_from = dup,
              values_from = groupName) %>%
  mutate(
    groupName = case_when(
      is.na(entry2) ~ entry1,
      entry1 == entry2 ~ entry1,
      entry1 != entry2 ~ str_c(entry1, entry2, sep = "_")
    )
  ) %>%
  separate("temp", into = c("animalID", "captureYear")) %>%
  select(animalID, captureYear, groupName) %>%
  mutate(captureYear = str_c("grp", captureYear)) %>%
  # now can make big df
  pivot_wider(names_from = captureYear,
              values_from = groupName) %>%
  arrange(as.numeric(animalID)) %>%
  relocate(c(animalID, grp2009, grp2010, grp2011, grp2012, grp2013, grp2014))
```

## Age at first dispersal

```{r}
dispersal <- groupMembership %>%
  # filter to known birth years only
  filter(animalID %in% birthAssignments$animalID) %>%
  pivot_longer(!animalID,
               names_to = "year",
               values_to = "groupName") %>%
  na.omit() %>%
  merge(., birthAssignments, by = "animalID") %>%
  mutate(
    year = as.numeric(gsub("grp", "", year)),
    age = year - birthYear_est
    ) %>%
  # ditch age -1 (just the two in 2009 and they have other values that make it so doing this doesn't matter)
  filter(age >= 0) %>%
  select(species, animalID, age, groupName, year) %>%
  # remove indivs captured only once
  group_by(animalID) %>%
  filter(n()>1) %>%
  ungroup() %>%
  arrange(species, animalID, age)
  
  
  mutate(
    year = gsub("grp", "", year),
    grp_age0 = case_when(
      year == birthYear_est ~ groupName,
      .default = NA
    ),
    grp_age1 = case_when(
      year == birthYear_est + 1 ~ groupName,
      .default = NA
    ),
    grp_age2 = case_when(
      year == birthYear_est + 2 ~ groupName,
      .default = NA
    )
  )
  
mutate(
    year = gsub("grp", "", year),
    grp_age0 = case_when(
      year == birthYear_est ~ groupName,
      .default = NA
    ),
    grp_age1 = case_when(
      year == birthYear_est + 1 ~ groupName,
      .default = NA
    ),
    grp_age2 = case_when(
      year == birthYear_est + 2 ~ groupName,
      .default = NA
    )
  )

data.frame(
  grp_yr0 = xxx,
  grp_yr1 = xxx,
  grp_yr2 = xxx
)
```


# 4 Filter genos

Prior to using genotyping results in additional analyses, I'm using the
following filters for quality control:

1.  Species mismatches - remove any that conflict w/metadata
2.  Sex mismatches - remove any where majority of sex loci conflict
    w/metadata
3.  Duplicates - for any duplicate pairs identified, remove the sample
    with lower geno success
4.  Separate genos by species & filter loci to retain only those for individual identification, then (following Arpin et al. 2024):
    1.  Remove loci with \>50% missing data
    2.  Remove samples with \>50% missing data
    3.  Remove loci with minor allele freq \<0.03

## 4.1 Species/sex checks

### species checks

4 species mismatches, though each was genotyped at only one locus - will
probably get filtered out when ditching poorly performing loci/samples

```{r}
genos_forChecks <- genos10x %>%
  # subset to hair samples
  select(md[md$species %in% c("LWED", "SIMP") & md$sampleType == "hair", "sampleID"])

speciesChecks <- assignSpecies(genos_forChecks, md, "sampleID")

toRemove_speciesChecks <- speciesChecks %>%
  filter(mdMatch == F) %>%
  select(sampleID) %>%
  pull()
```

### sex checks

15 sex mismatches, though 12 of these are MIX. Vast majority clear up if
go by the majority of calls -- not terribly worried about it though, bc
when I tried before to first ditch poorly performing samples and then
run assignSex, only got 3 mismatches and all were MIX (one 50/50, two
with majority correct).

--just checked the sampleSummary for the samples where mdMajMatch were
either F or NA -- all of these had shit genoSuccess so they'll be
ditched regardless

```{r}
# run sexChecks (can use same geno file as speciesChecks)
sexChecks <- assignSex(genos_forChecks, md, "sampleID", exclude_nonTargetSp = "yes") %>%
  filter(mdMatch == FALSE) %>%
  mutate(
    majSex = case_when(
      propF > propM ~ "F",
      propM > propF ~ "M",
      .default = NA
    ),
    mdMajMatch = mdSex == majSex
  ) %>%
  relocate(c(majSex, mdMajMatch), .after = "mdSex")

toRemove_sexChecks <- sexChecks %>%
  filter(mdMajMatch == F | is.na(mdMajMatch)) %>%
  select(sampleID) %>%
  pull()
```

## 4.2 Dup checks

Here I'm using my version of the GTscore "IDduplicateSamples" function;
I modified it only slightly so that I could use a dataframe as input vs.
the polygen output.

Results show tamRun5.211/tamRun5.264 as the only likely duplicate pair -
this is the set that I already caught in metadataReconciliation.Rmd for
animalID 200

**tamRun5.211 has the higher genotype success -- ditch tamRun5.264**

```{r}
run5_dupTest_10x <- get_dupSamples(genos_forChecks)

# view likely dups - only one pair (tamRun5.211/tamRun5.264)
run5_likelyDups <- run5_dupTest_10x %>%
  filter(proportionCommon >= 0.5) %>%
  filter(proportionMatch > 0.9)
run5_likelyDups

View(md %>% filter(sampleID %in% c(run5_likelyDups$Sample1, run5_likelyDups$Sample2)))

# tamRun5.211 has the higher genotype success -- ditch tamRun5.264
run5_sampleSum <- read.csv("./05_tamRun5/03_run5GTscore/summaryFiles/master_sampleSummary_10x.csv")

run5_sampleSum %>% filter(Sample %in% c(run5_likelyDups$Sample1, run5_likelyDups$Sample2)) %>% select(Sample, GenotypeRate)

toRemove_dupChecks <- "tamRun5.264"
```

## 4.3 Poor performance

I found that some of the loci that were supposed to be sex-specific
sometimes showed some variation in the other species -- as such, I'm
opting to ignore the species designation for INDID SNPs and instead add
a blanket filter to remove any loci whose minAF is less than 0.03
(following Arpin et al. 2024, who used this cutoff)

First though, apply filters based on species/sex checks, dupChecks, and
genotype success--

```{r}
lwed_genos_temp <- genos10x %>%
  # subset to hair + INDID only
  select(md[md$species == "LWED" & md$sampleType == "hair", "sampleID"]) %>%
  filter(!str_detect(rownames(.), "SEXID|SPECIESID")) %>%
  t() %>%
  as.data.frame() %>%
  # 1. remove any species/sex mismatches
  filter(!rownames(.) %in% toRemove_speciesChecks) %>%
  filter(!rownames(.) %in% toRemove_sexChecks) %>%
  # 2. remove any dups
  filter(!rownames(.) %in% toRemove_dupChecks) %>%
  # 3. remove SNPs with >50% missing data
  select(where(~sum(!is.na(.x))/length(.x) >= 0.5)) %>%
  # 4. remove samples with >50% missing data
  filter((rowSums(!is.na(.)) / ncol(.)) >= 0.5)

simp_genos_temp <- genos10x %>%
  # subset to hair + INDID only
  select(md[md$species == "SIMP" & md$sampleType == "hair", "sampleID"]) %>%
  filter(!str_detect(rownames(.), "SEXID|SPECIESID")) %>%
  t() %>%
  as.data.frame() %>%
  # 1. remove any species/sex mismatches
  filter(!rownames(.) %in% toRemove_speciesChecks) %>%
  filter(!rownames(.) %in% toRemove_sexChecks) %>%
  # 2. remove any dups
  filter(!rownames(.) %in% toRemove_dupChecks) %>%
  # 3. remove SNPs with >50% missing data
  select(where(~sum(!is.na(.x))/length(.x) >= 0.5)) %>%
  # 4. remove samples with >50% missing data
  filter((rowSums(!is.na(.)) / ncol(.)) >= 0.5)
```

Then use these genos to check and filter based on minAF

**LWED**

```{r}
locusTable <- read.table("./05_tamRun5/03_run5GTscore/fullSet_LocusTable_singleSNPs.txt", header = T) %>%
  mutate(
    Locus_ID = sub('[_][^_]+$', '', Locus_ID)
  )

lwed_locusTable <- locusTable %>%
  filter(Locus_ID %in% colnames(lwed_genos_temp))

lwed_readCounts_forFreqChecks <- read.table("./05_tamRun5/03_run5GTscore/fullSet_AlleleReads_singleSNPs_10x.txt") %>%
  select(md[md$species == "LWED" & md$sampleType == "hair", "sampleID"]) %>%
  `rownames<-`(sub('[_][^_]+$', '', rownames(.))) %>%
  filter(rownames(.) %in% colnames(lwed_genos_temp)) %>%
  select(rownames(lwed_genos_temp))

lwed_genos_forFreqChecks <- read.table("./05_tamRun5/03_run5GTscore/fullSet_polyGenResults_singleSNP_10x.txt", header = T) %>%
  select(md[md$species == "LWED" & md$sampleType == "hair", "sampleID"]) %>%
  `rownames<-`(sub('[_][^_]+$', '', rownames(.))) %>%
  filter(rownames(.) %in% colnames(lwed_genos_temp)) %>%
  select(rownames(lwed_genos_temp))

lwed_alleleFreqs <- summarizeGTscore(lwed_readCounts_forFreqChecks, lwed_locusTable, lwed_genos_forFreqChecks)

lwed_toRemove_afChecks <- lwed_alleleFreqs %>%
  filter(minAF < 0.03) %>%
  select(Locus_ID) %>%
  pull()
```

**SIMP**

```{r}
simp_locusTable <- locusTable %>%
  filter(Locus_ID %in% colnames(simp_genos_temp))

simp_readCounts_forFreqChecks <- read.table("./05_tamRun5/03_run5GTscore/fullSet_AlleleReads_singleSNPs_10x.txt") %>%
  select(md[md$species == "SIMP" & md$sampleType == "hair", "sampleID"]) %>%
  `rownames<-`(sub('[_][^_]+$', '', rownames(.))) %>%
  filter(rownames(.) %in% colnames(simp_genos_temp)) %>%
  select(rownames(simp_genos_temp))

simp_genos_forFreqChecks <- read.table("./05_tamRun5/03_run5GTscore/fullSet_polyGenResults_singleSNP_10x.txt", header = T) %>%
  select(md[md$species == "SIMP" & md$sampleType == "hair", "sampleID"]) %>%
  `rownames<-`(sub('[_][^_]+$', '', rownames(.))) %>%
  filter(rownames(.) %in% colnames(simp_genos_temp)) %>%
  select(rownames(simp_genos_temp))

simp_alleleFreqs <- summarizeGTscore(simp_readCounts_forFreqChecks, simp_locusTable, simp_genos_forFreqChecks)

simp_toRemove_afChecks <- simp_alleleFreqs %>%
  filter(minAF < 0.03) %>%
  select(Locus_ID) %>%
  pull()
```

## 4.4 Final genos

### genos

```{r}
lwed_genos <- lwed_genos_temp %>%
  select(!all_of(lwed_toRemove_afChecks)) %>%
  rownames_to_column("sampleID") %>%
  mutate(pop = "lwed") %>%
  merge(., md[, c("animalID", "sampleID", "sex", "captureYear")], by = "sampleID", all.x = T) %>%
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  relocate(sampleID, animalID, sex, birthYear_est, pop, captureYear)

simp_genos <- simp_genos_temp %>%
  select(!all_of(simp_toRemove_afChecks)) %>%
  rownames_to_column("sampleID") %>%
  mutate(pop = "simp") %>%
  merge(., md[, c("animalID", "sampleID", "sex", "captureYear")], by = "sampleID", all.x = T) %>%
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  relocate(sampleID, animalID, sex, birthYear_est, pop, captureYear)
```

### genind

```{r}
lwed_genind <- adegenet::df2genind(X = lwed_genos[,c(7:59)],
                                  sep = ",",
                                  ind.names = lwed_genos$sampleID,
                                  pop = lwed_genos$pop,
                                  NA.char = "NA",
                                  ploidy = 2,
                                  type = "codom")
lwed_genind@other$sex <- lwed_genos$sex
lwed_genind@other$birthYear <- lwed_genos$birthYear_est
lwed_genind@other$captureYear <- lwed_genos$captureYear

simp_genind <- adegenet::df2genind(X = simp_genos[,c(7:54)],
                                  sep = ",",
                                  ind.names = simp_genos$sampleID,
                                  pop = simp_genos$pop,
                                  NA.char = "NA",
                                  ploidy = 2,
                                  type = "codom")
simp_genind@other$sex <- simp_genos$sex
simp_genind@other$birthYear <- simp_genos$birthYear_est
simp_genind@other$captureYear <- simp_genos$captureYear
```

## 4.5 Quick overview of filtered geno data:

Retained LWED data include... - 72 indivs + 53 loci - avg 94% geno
success among samples - 43 non-juvs, 29 juvs

Retained SIMP data include... - 55 indivs + 48 loci - avg 93% geno
success among samples - 27 non-juvs, 28 juvs

```{r}
# LWED
lwed_genind
mean(propTyped(lwed_genind, by = "ind")) # 0.9360587
median(propTyped(lwed_genind, by = "ind")) # 1

sum(is.na(lwed_genos$birthYear_est)) # 43 non-juvs remaining
sum(!is.na(lwed_genos$birthYear_est)) # 29 juvs remaining

# SIMP
simp_genind
mean(propTyped(simp_genind, by = "ind")) # 0.932197
median(propTyped(simp_genind, by = "ind")) # 1

sum(is.na(simp_genos$birthYear_est)) # 27 non-juvs remaining
sum(!is.na(simp_genos$birthYear_est)) # 28 juvs remaining
```

# 5 Basic popGen

adegenet hierfstat, inbreedR

## Data

```{r}
lwed_genos_popgen.hf <- genind2hierfstat(lwed_genind) %>%
  filter(pop != "dumpop") %>%
  select(-pop) %>%
  rownames_to_column("sampleID")

simp_genos_popgen.hf <- genind2hierfstat(simp_genind) %>%
  filter(pop != "dumpop") %>%
  select(-pop) %>%
  rownames_to_column("sampleID")
```

## 5.1 Descriptive stats

we can use the summary() function from 'adegenet' to provide the
following: - Number of alleles per locus - Observed heterozygosity -
Expected heterozygosity

Ho - observed heterozygosity; proportion of heterozygotes observed at each locus
Hs - gene diversity w/in subpops (expected heterozygosity w/in groups); calculated based on allele freqs
Ht - gene diversity across entire pop; total expected heterozygosity
Dst - genetic diversity b/t subpops
Htp - total gene diversity accounting for diffs among pops (NA b/c no b/t-subpop diversity)
Dstp - prop of total gene diversity due to diffs b/t pops
Fst - fixation index; measures pop differentiation due to genetic structure; 0 here indicates no differentiation b/t subpops
Fstp - similar to Fst, but accounts for differentiation b/t pops (NA b/c no subpops)
Fis - inbreeding coefficient w/in subpops, compares Ho to Hs; + values suggest deficit of hets (inbreeding), (-) values suggest excess hets
Dest - Jost's D (measure of differentiation); NA b/c no differentiation detected

```{r}
# LWED
lwed_genind_sum <- adegenet::summary(lwed_genind)
lwed_genind_sum

lwed_basicStats <- basic.stats(lwed_genind)
lwed_basicStats

mean(lwed_basicStats$Ho, na.rm = T) # 0.460
min(lwed_basicStats$Ho, na.rm = T) # 0.169
max(lwed_basicStats$Ho, na.rm = T) # 0.612

mean(lwed_basicStats$Hs, na.rm = T) # 0.457
min(lwed_basicStats$Hs, na.rm = T) # 0.179
max(lwed_basicStats$Hs, na.rm = T) # 0.504

lwed_basicStats$overall # Ht = 0.457

# SIMP
simp_genind_sum <- adegenet::summary(simp_genind)
simp_genind_sum
simp_basicStats <- basic.stats(simp_genind)
simp_basicStats

mean(simp_basicStats$Ho, na.rm = T) # 0.434
min(simp_basicStats$Ho, na.rm = T) # 0.058
max(simp_basicStats$Ho, na.rm = T) # 0.611

mean(simp_basicStats$Hs, na.rm = T) # 0.439
min(simp_basicStats$Hs, na.rm = T) # 0.128
max(simp_basicStats$Hs, na.rm = T) # 0.505

simp_basicStats$overall # Ht 0.4390
```

## F-stats

The fixation index (FST)

Get per-locus f-stats w/pegas:

```{r}
library(pegas)
lwed_ftab <- Fst(as.loci(lwed_genind))
lwed_ftab
wc(lwed_genind)

simp_ftab <- Fst(as.loci(simp_genind))
simp_ftab
wc(simp_genind)

data("microbov")
microbov$tab
seppop(microbov)$Salers
```

## Inbreeding

**With adegenet:**

LWED:
```{r}
# compute mean inbreeding for each individual
lwed_meanInbreed <- adegenet::inbreeding(lwed_genind, res.type = "estimate")

# plot resulting distribution:
lwed_Fbar <- sapply(lwed_meanInbreed, mean)
hist(lwed_Fbar, main = "Avg inbreeding in saddleback tamarins")

# someone has high inbreeding (>0.4); that someone is tamaRun5.360
which(lwed_Fbar > 0.4)

# tamRun5.360 distribution def shows inbreeding, w/~50% chance of being homozygote through inheritance from a common ancestor of its parents
lwed_F <- inbreeding(lwed_genind, res.type = "function")[which(lwed_Fbar>0.4)]
lwed_F
plot(lwed_F$tamRun5.360, main = "Inbreeding of individual", xlab = "Inbreeding (F)", ylab = "Probability density")
```

SIMP:
```{r}
# compute mean inbreeding for each individual
simp_meanInbreed <- adegenet::inbreeding(simp_genind, res.type = "estimate")

# plot resulting distribution:
simp_Fbar <- sapply(simp_meanInbreed, mean)
hist(simp_Fbar, main = "Avg inbreeding in emperor tamarins")

# someone has high inbreeding (>0.4); that someone is tamRun5.197 & tamRun5.249 
which(simp_Fbar > 0.4)

# tamRun5.197 also has 50%ish chance of being homozygote, while tamRun5.249 has 60%ish chance
simp_F <- inbreeding(simp_genind, res.type = "function")[which(simp_Fbar>0.4)]
simp_F
plot(simp_F$tamRun5.197, main = "Inbreeding of tamRun5.197", xlab = "Inbreeding (F)", ylab = "Probability density")
plot(simp_F$tamRun5.249, main = "Inbreeding of tamRun5.249", xlab = "Inbreeding (F)", ylab = "Probability density")
```

**With inbreedR:**

```{r}
library(inbreedR)
```

LWED:
```{r}
lwed_genos_ir <- lwed_genind$tab %>%
  convert_raw(.)

# g2
g2_lwed <- g2_snps(lwed_genos_ir, nperm = 1000, nboot = 1000, CI = 0.95, parallel = F, ncores = NULL)
g2_lwed
# calculate sMLH
het_lwed <- sMLH(lwed_genos_ir)
het_lwed
# variance in sMLH
het.var_lwed <- var(het_lwed)
het.var_lwed
# r2 b/t inbreeding and heterozygosity
hf_lwed <- r2_hf(lwed_genos_ir, type = "snps", nboot = 10)

hhc_lwed <- HHC(lwed_genos_ir, reps = 100)

plot(g2_lwed, col = "#94C5CCFF")
plot(hhc_lwed, col = "#94C5CCFF")
```

SIMP:
```{r}
simp_genos_ir <- simp_genind$tab %>%
  convert_raw(.)

# g2
g2_simp <- g2_snps(simp_genos_ir, nperm = 1000, nboot = 1000, CI = 0.95, parallel = F, ncores = NULL)
g2_simp
# calculate sMLH
het_simp <- sMLH(simp_genos_ir)
het_simp
# variance in sMLH
het.var_simp <- var(het_simp)
het.var_simp
# r2 b/t inbreeding and heterozygosity
hf_simp <- r2_hf(simp_genos_ir, type = "snps", nboot = 10)

plot(g2_simp, col = "#94C5CCFF")
```

## Bartlett test

We can then test whether there's a significant difference exists between
mean observed and expected heterozygosity values using the **Bartlett
test of homogeneity of variances**.

There appears to be a significant different between observed and
expected heterozygosity for both LWED and SIMP

```{r}
# LWED
## p = 0.001065
bartlett.test(list(lwed_genind_sum$Hexp, lwed_genind_sum$Hobs)) 

t.test(lwed_genind_sum$Hexp, lwed_genind_sum$Hobs, paired = T, var.equal = T, alternative = "greater")

# SIMP
## p = 0.001576
bartlett.test(list(simp_genind_sum$Hexp, simp_genind_sum$Hobs)) 

t.test(simp_genind_sum$Hexp, simp_genind_sum$Hobs, paired = T, var.equal = T, alternative = "greater")
```

## HWE

The Hardy-Weinberg test function in 'adegenet' has been removed and
replaced by 'hw.test' in the package 'pegas'. This function uses both
the classical chi-squared test based on expected genotype frequencies
calculated from the allelic frequencies as well as an exact test based
on Monte Carlo permutations of alleles.

**NOTE** that B = 0 is used for the parametric version of the test;
larger numbers will indicate the number of permutations to use for the
Monte-Carlo version.

```{r}
library(pegas)
lwed_hwt <- hw.test(lwed_genind, B = 0)
simp_hwt <- hw.test(simp_genind, B = 0)
```

## Population structure

As of version 2.0.0, adegenet relies on hierfstat and pegas for most F
statistics.

```{r}
library(hierfstat)
wc(lwed_genind) # FST 0, FIS -0.005851178
wc(simp_genind) # FST 0, FIS 0.01158646
```

Use pegas to provide estimates by locus:

```{r}
library(pegas)
lwed_ftab <- Fst(as.loci(lwed_genind))
simp_ftab <- Fst(as.loci(simp_genind))

lwed_ftab
simp_ftab
```

```{r}
lwed_basicStats <- basic.stats(lwed_genind, diploid = T)
simp_basicStats <- basic.stats(simp_genind, diploid = T)

lwed_basicStats$overall
simp_basicStats$overall
```

lwed_basicStats\$overall Ho Hs Ht Dst Htp Dstp Fst Fstp Fis Dest 0.4599
0.4573 0.4573 0.0000 NaN NaN 0.0000 NaN -0.0059 NaN

simp_basicStats\$overall Ho Hs Ht Dst Htp Dstp Fst Fstp Fis Dest 0.4339
0.4390 0.4390 0.0000 NaN NaN 0.0000 NaN 0.0116 NaN

Fis

```{r}
# Fis per locus
lwed_basicStats$Fis
simp_basicStats$Fis

# mean Fis
apply(lwed_basicStats$Fis, MARGIN = 2, FUN = mean, na.rm = T) # -0.0013
apply(simp_basicStats$Fis, MARGIN = 2, FUN = mean, na.rm = T) # 0.020525
```

Pairwise Fst

```{r}
lwed_fst <- genet.dist(lwed_genind, method = "WC84")
```

Is mean Hobs significantly lower than mean Hexp?

```{r}
lwed_genSum <- summary(lwed_genind)
names(lwed_genSum)

bartlett.test(list(lwed_genSum$Hexp, lwed_genSum$Hobs))
t.test(lwed_genSum$Hexp, lwed_genSum$Hobs, paired = T, var.equal = T, alternative = "greater")
```

# 6 PID, PIDsibs

## 6.1 Calculations

```{r}
lwed_pidPerm <- PopGenUtils::pid_permute(obj = lwed_genind, nrep = 1000)

simp_pidPerm <- PopGenUtils::pid_permute(obj = simp_genind, nrep = 1000)
```

## 5.2 Analysis

```{r}
# LWED
lwed_pidPerm_data <- lwed_pidPerm$median_values

## PID meets 0.0001 threshold at 11 loci
lwed_pid.thresh <- as.numeric(lwed_pidPerm_data[which(lwed_pidPerm_data$PID<0.0001, arr.ind=TRUE)[1],][[1]])

## PIDsibs meets 0.0001 threshold at 20 loci
lwed_pidSibs.thresh <- as.numeric(lwed_pidPerm_data[which(lwed_pidPerm_data$PIDsibs<0.0001, arr.ind=TRUE)[1],][[1]])

# SIMP
simp_pidPerm_data <- simp_pidPerm$median_values

## PID meets 0.0001 threshold at 11 loci
simp_pid.thresh <- as.numeric(simp_pidPerm_data[which(simp_pidPerm_data$PID<0.0001, arr.ind=TRUE)[1],][[1]])

## PIDsibs meets 0.0001 threshold at 21 loci
simp_pidSibs.thresh <- as.numeric(simp_pidPerm_data[which(simp_pidPerm_data$PIDsibs<0.0001, arr.ind=TRUE)[1],][[1]])
```

## 5.3 Plots

```{r}
pidPerm_data_forFig <- lwed_pidPerm$results %>%
  mutate(species = "LWED") %>%
  rbind(., simp_pidPerm$results %>% mutate(species = "SIMP"))

pidThreshLines_forFig <- data.frame(species = c("LWED", "SIMP"),
                                    vline = c(lwed_pid.thresh,
                                              simp_pid.thresh))
pidSibThreshLines_forFig <- data.frame(species = c("LWED", "SIMP"),
                                    vline = c(lwed_pidSibs.thresh,
                                              simp_pidSibs.thresh))

pidPerm_fig <- ggplot(pidPerm_data_forFig,
                      aes(y = value,
                          x = loci,
                          color = statistic)) +
  geom_boxplot() +
  scale_colour_Publication() +
  theme_Publication() +
  
  scale_x_discrete(limits = as.character(1:25)) +
  geom_vline(data = pidThreshLines_forFig,
             aes(xintercept = vline),
                 color = "#386cb0") +
  geom_vline(data = pidSibThreshLines_forFig,
             aes(xintercept = vline),
             color = "#fdb462") +
  
  labs(x = "Number of loci",
       y = "Probability of identity") +
  facet_grid(rows = vars(species))

pidPerm_fig

  xlab("Number of loci")
```

# 6 CKMRsim

## 6.1 Background

From the package website: 
"This package implements Monte Carlo methods (including efficient importance sampling approaches) for assessing the false positive and false negative rates expected when using a particular set of genetic markers for pairwise relationship inference. It also provides functions implemented in C++ for computing likelihood ratios for different relationships between all pairs of individuals in a data set."

Resources: - CKMRsim-example-1
<https://eriqande.github.io/CKMRsim/articles/CKMRsim-example-1.html> -
Shedd et al. GitHub
<https://github.com/krshedd/Relative-fitness-of-Pink-Salmon/blob/main/analysis/8_Hogan_Stockdale_13_16_MS_CKMRSIM.Rmd>

## 6.2 Packages

```{r}
remotes::install_github("eriqande/CKMRsim")
library(CKMRsim)
library(tidyverse)
# the next step tests to see if mendel was already installed.
# if not, it installs it
if(system.file("bin", package = "CKMRsim") == "") {
  install_mendel(Dir = system.file(package = "CKMRsim"))
}
```

## 6.3 Format genos

I'm using the LWED and SIMP genos that I filtered earlier since these
are the data I'm using for FRANz.

------------------------------------------------------------------------

Long-format genos should have four columns: Indiv, Locus, gene_copy, and
Allele.

-   Alleles are named with characters (even if they are numbers, they
    must be coerced to characters)
-   The gene_copy column contains either a 1 or a 2 in every row,
    telling us which copy of the gene (in a diploid) is which allele
-   Missing data in the Allele column is given by NA

**LWED**

```{r}
lwed_genos_forCKMR_temp <- lwed_genos_hf %>%
  filter(pop != "dumpop") %>%
  select(-pop) %>%
  mutate(across(everything(), ~ str_c(str_sub(., 1, 1), ",", str_sub(., 2, 2))))

#lwed_genos_forCKMR_temp <- lwed_genos %>%
#  select(-c(animalID, sex, birthYear_est, pop, captureYear)) %>%
#  column_to_rownames("sampleID")

lwed_genos_forCKMR <- names(lwed_genos_forCKMR_temp) %>%
  # split loci columns
  map_dfc(~ lwed_genos_forCKMR_temp %>%
            select(all_of(.x)) %>%
            separate(.x,
                     into = paste0(.x, c(".1", ".2")),
                     sep = ",")
          ) %>%
  # missing data must be coded as NA
  #mutate(across(everything(), ~ gsub("0", NA, .))) %>%
  rownames_to_column("Indiv") %>%
  # make long-format
  pivot_longer(
    cols = -Indiv, 
    names_to = c("Locus", "gene_copy"), 
    names_sep = "\\.", 
    values_to = "Allele"
  )
```

**SIMP**

```{r}
simp_genos_forCKMR_temp <- simp_genos %>%
  select(-c(animalID, sex, birthYear_est, pop, captureYear)) %>%
  column_to_rownames("sampleID")

simp_genos_forCKMR <- names(simp_genos_forCKMR_temp) %>%
  map_dfc(~ simp_genos_forCKMR_temp %>%
            select(all_of(.x)) %>%
            separate(.x,
                     into = paste0(.x, c(".1", ".2")),
                     sep = ",")
          ) %>%
  # missing data must be coded as NA
  mutate(across(everything(), ~ gsub("0", NA, .))) %>%
  rownames_to_column("Indiv") %>%
  pivot_longer(
    cols = -Indiv, 
    names_to = c("Locus", "gene_copy"), 
    names_sep = "\\.", 
    values_to = "Allele"
  )
```

## 6.4 Allele frequency

Allele frequency input format:

-   **Chrom** should be a character or integer denoting which chromosome
    the marker is on. (For example 1 or X or Omy12)
-   **Locus** gives a character vector with the names of the
    markers/loci. Please don't use spaces in the marker names!
-   **Pos** gives the genome coordinates of the marker. This needs to be
    a number (double or integer)
-   **Allele** gives the name of each allele at each locus. This must be
    a character vector. So, in our example, we will coerce the numbers
    we have for each locus into a character vector. Please do not use
    spaces in allele names.
-   **Freq** is the frequency of each allele in the population. These
    should sum to 1.0 over each locus.
-   The remaining columns, **LocIdx** and **AlleIdx** are integer
    indices that get assigned to each locus and to each allele within
    each index. These columns get filled by using the reindex_markers()
    function.

**LWED**

```{r}
lwed_locusNames <- unique(lwed_genos_forCKMR$Locus)

lwed_afreqs_ready <- lwed_genos_forCKMR %>%
  count(Locus, Allele) %>%  
  group_by(Locus) %>%
  mutate(
    Freq = n / sum(n),
    #Chrom = "Unk",
    #Pos = as.integer(factor(Locus, levels = lwed_locusNames))
  ) %>%
  
  merge(., lociRef[, c("locus", "chr_num", "snpPos_inChr")], by.x = "Locus", by.y = "locus") %>%
  dplyr::rename("Chrom" = "chr_num",
                "Pos" = "snpPos_inChr") %>%
  
  ungroup() %>%
  select(Chrom, Pos, Locus, Allele, Freq) %>%
  arrange(Pos, desc(Freq)) %>%
  mutate(AlleIdx = NA,
         LocIdx = NA) %>%
  # NOTE - is very impt to remove NAs from allele frequencies
  filter(!is.na(Allele)) %>%
  # pass to reindex_markers to give allele-freq df for CKRMsim
  reindex_markers()
```

**SIMP**

```{r}
simp_locusNames <- unique(simp_genos_forCKMR$Locus)

simp_afreqs_ready <- simp_genos_forCKMR %>%
  count(Locus, Allele) %>%  
  group_by(Locus) %>%
  mutate(
    Freq = n / sum(n),
    #Chrom = "Unk",
    #Pos = as.integer(factor(Locus, levels = lwed_locusNames))
  ) %>%
  
  merge(., lociRef[, c("locus", "chr_num", "snpPos_inChr")], by.x = "Locus", by.y = "locus") %>%
  dplyr::rename("Chrom" = "chr_num",
                "Pos" = "snpPos_inChr") %>%
  
  ungroup() %>%
  select(Chrom, Pos, Locus, Allele, Freq) %>%
  arrange(Pos, desc(Freq)) %>%
  mutate(AlleIdx = NA,
         LocIdx = NA) %>%
  # NOTE - is very impt to remove NAs from allele frequencies
  filter(!is.na(Allele)) %>%
  # pass to reindex_markers to give allele-freq df for CKRMsim
  reindex_markers()
```

## 6.5 Create a CKMR object (create_ckmr)

-   **D** : the tibble of allele frequencies that has been run through
    reindex_markers().
-   **kappa_matrix** : A matrix that describes the pairwise
    relationships that you will be wanting to jointly simulate genotypes
    and likelihoods for. Each row is named by what you want to call the
    relationship and there are three columns which give, respectively,
    the probability that a pair with such a relationship share 0, 1, or
    2 genes identical-by-descent. The CKMRsim package comes with a
    matrix called kappas that has this information for 12 relationships:
    -   **MZ** : monozgotic twins (or "self"). This can be used to
        figure out how much power you have for identifying the same
        individual, sampled twice.
    -   **PO** : parent-offspring.
    -   **FS** : full siblings.
    -   **HS** : half siblings.
    -   **GP** : grandparent - grandoffspring.
    -   **AN** : aunt-neice (same as uncle-nephew or any such avuncular
        relationship)
    -   **DFC** : double first cousins.
    -   **FC** : first cousins.
    -   **HC** : half cousins.
    -   **U** : unrelated
-   **ge_mod_assumed** a function that describes the genotyping error model that will be applied to the simulated data when computing the likelihoods of the genotypes
-   **ge_mod_true** a function that describes the genotyping error model that will actually be used to simulate the genotype data. Being able to separately specify these two models (assumed and true) allows the user to investigate the effects of misspecification of the genotyping error model.
-   **ge_mod_assumed_pars_list** a list of named parameters for the assumed genotyping error model (or, leave blank to use the defaults)
-   **ge_mod_true_pars_list** a list of named parameters for the true genotyping error model (or, leave blank to use the defaults)

Genotyping error model used here:
-   **ge_model_TGIE** true-genotype-independent error; appropriate for integer-coded data (though also works for ATCG); The main goal of it is to ensure that genotyping errors don’t create zero-probability situations. It is not intended to model the actual genotyping error process, but it is mathematically tractable in a lot of situations, and it is useful in cases where little is known about the genotyping error process. 

**LWED**

```{r}
lwed_ckmr <- create_ckmr(
  D = lwed_afreqs_ready,
  kappa_matrix = kappas[c("PO", "FS", "HS", "U"), ],
  ge_mod_assumed = ge_model_TGIE,
  ge_mod_true = ge_model_TGIE,
  ge_mod_assumed_pars_list = list(epsilon = 0.01),
  ge_mod_true_pars_list = list(epsilon = 0.01)
)
lwed_ckmr
```

**SIMP**

```{r}
simp_ckmr <- create_ckmr(
  D = simp_afreqs_ready,
  kappa_matrix = kappas[c("PO", "FS", "HS", "U"), ],
  ge_mod_assumed = ge_model_TGIE,
  ge_mod_true = ge_model_TGIE,
  ge_mod_assumed_pars_list = list(epsilon = 0.01),
  ge_mod_true_pars_list = list(epsilon = 0.01)
)
simp_ckmr
```

## 6.6 Simulations & log-probabilities

simulate_Qij() -- This function simulates genotypes from different
relationships, and then for each simulated genotype pair it also
calculates the log probability of the pair of genotypes conditional on
the pair being of one or several relationships. This function has four
main inputs that we discuss here (the others allow the addition of
missing data and physical linkage, and are discussed in other
vignettes).

-   **C** : the ckmr object to use for simulation and probabilty
    calculation.
-   **sim_relats** : the set of true relationships you want to simulate
    genotypes from.
-   **calc_relats** : the set of assumed relationships you wish to
    compute genotype probabilities for, from the simulated data.
-   **reps** : for each relationship in sim_relats, the number of
    genotype pairs to simulate. This is, by default 10,000.

PO = parent-offspring FS = full sib HS = half sib HAN = half aunt-niece
(or uncle/niece) U = unrelated

### Run simulations

**LWED**

```{r}
# This simulates a large number of pairwise genotype probabilites
# at each locus
lwed_Qs <- simulate_Qij(lwed_ckmr,
                        calc_relats = c("PO", "FS", "HS", "U"),
                        sim_relats = c("PO", "FS", "HS", "U")
                        )
lwed_Qs
```

**SIMP**

```{r}
simp_Qs <- simulate_Qij(simp_ckmr,
                        calc_relats = c("PO", "FS", "HS", "U"),
                        sim_relats = c("PO", "FS", "HS", "U")
                        )
simp_Qs
```

### Extract logls

extract_logls() function lets us get simulated log-likelihood ratios out
of the Qij object we created above and plot a histogram or a density
plot of the distributions. This is helpful for developing intuition
about things and understanding what is going on.

In the following, we extract those genotype probabilities in different
ways to calculate a variety of different log-likelihood ratios for
different relationships.

**LWED**

```{r}
# log likelihood ratios for the hypothesis of PO vs Unrelated
lwed_PO_U_logls <- extract_logls(lwed_Qs,
                                 numer = c(PO = 1),
                                 denom = c(U = 1)
                                 ) %>%
  mutate(true_relat_pub = case_when(true_relat == "FS" ~ "Full Sibling",
                                    true_relat == "HS" ~ "Half Sibling",
                                    true_relat == "PO" ~ "Parent-Offspring",
                                    true_relat == "U" ~ "Unrelated")) %>% 
  mutate(true_relat_pub = factor(x = true_relat_pub, levels = c("Parent-Offspring", "Full Sibling", "Half Sibling", "Unrelated")))

# FS vs. U
lwed_FS_U_logls <- extract_logls(lwed_Qs,
                            numer = c(FS = 1),
                            denom = c(U = 1))
```

**SIMP**

```{r}
# log likelihood ratios for the hypothesis of PO vs Unrelated
simp_PO_U_logls <- extract_logls(simp_Qs,
                                 numer = c(PO = 1),
                                 denom = c(U = 1)
                                 ) %>%
  mutate(true_relat_pub = case_when(true_relat == "FS" ~ "Full Sibling",
                                    true_relat == "HS" ~ "Half Sibling",
                                    true_relat == "PO" ~ "Parent-Offspring",
                                    true_relat == "U" ~ "Unrelated")) %>% 
  mutate(true_relat_pub = factor(x = true_relat_pub, levels = c("Parent-Offspring", "Full Sibling", "Half Sibling", "Unrelated")))

# FS vs. U
simp_FS_U_logls <- extract_logls(simp_Qs,
                            numer = c(FS = 1),
                            denom = c(U = 1))
```

### Plots

Plot the distribution of those logl ratios for each of the different
true relationships --

**LWED**

```{r}
# all comparisons
ckmrSim_data_forFig <- lwed_PO_U_logls %>%
  mutate(species = "LWED") %>%
  rbind(., simp_PO_U_logls %>% mutate(species = "SIMP"))

ckmrSim_fig <- ggplot(ckmrSim_data_forFig,
                      aes(x = logl_ratio,
                          fill = true_relat_pub)) +
  geom_density(alpha = 0.25) +
  theme_bw(base_size = 14) +
  #scale_x_continuous(limits = c(-60, 30), breaks = seq(-60, 30, by = 10)) +
  #scale_y_continuous(limits = c(0, 0.06), breaks = seq(0, 0.6, by = 0.2)) +
  theme(legend.position = c(0.15, 0.7),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        legend.key.size = unit(1, "line"),
        panel.grid = element_blank()) + 
  labs(x = "Log likelihood ratio", y = "Density", fill = "True Relationship") +
  facet_grid(rows = vars(species))

ckmrSim_fig


# just to PO vs. U pairs
ggplot(lwed_PO_U_logls %>% filter(true_relat %in% c("PO", "U")),
            aes(x = logl_ratio, fill = true_relat_pub)) +
  geom_density(alpha = 0.25) +
  theme_bw(base_size = 14) +
  #scale_x_continuous(limits = c(-60, 30), breaks = seq(-60, 30, by = 10)) +
  #scale_y_continuous(limits = c(0, 0.06), breaks = seq(0, 0.6, by = 0.2)) +
  theme(legend.position = c(0.15, 0.7),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        legend.key.size = unit(1, "line"),
        panel.grid = element_blank()) + 
  labs(title = "LWED", x = "Log likelihood ratio", y = "Density", fill = "True Relationship")
```

**SIMP**

```{r}
# all comparisons
ggplot(simp_PO_U_logls, aes(x = logl_ratio, fill = true_relat_pub)) +
  geom_density(alpha = 0.25) +
  theme_bw(base_size = 14) +
  #scale_x_continuous(limits = c(-60, 30), breaks = seq(-60, 30, by = 10)) +
  #scale_y_continuous(limits = c(0, 0.06), breaks = seq(0, 0.6, by = 0.2)) +
  theme(legend.position = c(0.15, 0.7),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        legend.key.size = unit(1, "line"),
        panel.grid = element_blank()) + 
  labs(title = "SIMP", x = "Log likelihood ratio", y = "Density", fill = "True Relationship")

# just to PO vs. U pairs
ggplot(simp_PO_U_logls %>% filter(true_relat %in% c("PO", "U")),
            aes(x = logl_ratio, fill = true_relat)) +
  geom_density(alpha = 0.25) +
  theme_bw(base_size = 14) +
  #scale_x_continuous(limits = c(-60, 30), breaks = seq(-60, 30, by = 10)) +
  #scale_y_continuous(limits = c(0, 0.06), breaks = seq(0, 0.6, by = 0.2)) +
  theme(legend.position = c(0.15, 0.7),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        legend.key.size = unit(1, "line"),
        panel.grid = element_blank()) + 
  labs(title = "SIMP", x = "Log likelihood ratio", y = "Density", fill = "True Relationship")
```

### Look at linked?

doesn't look all that terribly different I guess? gonna skip it though

```{r}
# also look at linked version (since we have the chrom info and such anyway)
lwed_Qs_link <- simulate_Qij(lwed_ckmr,
                        calc_relats = c("PO", "FS", "HS", "U"),
                        sim_relats = c("PO", "FS", "HS", "U"),
                        unlinked = FALSE,
                        pedigree_list = pedigrees)
lwed_Qs_link

data("pedigrees")
pedigrees$PO

lwed_Qs_link %>%
  extract_logls(numer = c(PO = 1), denom = c(U = 1)) %>%
  ggplot(aes(x = logl_ratio, fill = true_relat)) +
  geom_density(alpha = 0.25) +
  ggtitle("PO/U Logl Ratio")
```

## False neg/pos rates

### Run mc_sample_simple()

mc_sample_simple() lets you estimate false positive rates and false
negative rates from the simulated values in an object of class Qij. The
function is configured so that it will automatically compute both
regular or "vanilla" Monte Carlo estimates of these probabilities, and
also importance sampling (IS) Monte Carlo estimates, which are
particularly good for estimating very small probabilities.

**estimate false-pos rates when true relationship is unrelated but we're looking for PO pairs (uses importance sampling by default)**

```{r}
# LWED - using importance sampling by default (vs. "vanilla" Monte Carlo)
lwed_PO_is <- mc_sample_simple(lwed_Qs,
                               nu = "PO",
                               de = "U")
lwed_PO_is

# SIMP
simp_PO_is <- mc_sample_simple(simp_Qs,
                               nu = "PO",
                               de = "U")
simp_PO_is
```

lwed_PO_is shows false positive rates (FPR) at \~0.01 and smaller when
the false negative rate is 0.01 and greater

simp_PO_is shows false positive rates (FPR) at \~0.02 and smaller when
the false negative rate is 0.01 and greater

**find optimal FPR**

Anderson's recommendation for being confident about not erroneously
identifying unrelated individuals as related pairs is to require that
the FPR be about 10 to 100 times smaller than the reciprocal of the
number of comparisons--

For FRANz_run1, I'm not including any pedigree info so FRANz will be
comparing every individual to every other individual. The number of
pairs being compared can thus be calculated as follows:

```{r}
countComparisons <- function(n) {
  totalComparisons = (n*(n-1))/2
  return(totalComparisons)
}

nLWED <- nrow(lwed_genos) # 72
nSIMP <- nrow(simp_genos) # 55

lwed_compCount <- countComparisons(nLWED) # 2556 LWED
simp_compCount <- countComparisons(nSIMP) # 1485 SIMP

# now calculate max FPR to shoot for--
lwed_fprGoal <- 0.1*lwed_compCount^(-1) # 0.00003912363
simp_fprGoal <- 0.1*simp_compCount^(-1) # 0.00006734007
```

Let's look back at our FNR/FPR estimates--

```{r}
# LWED
lwed_PO_is_test <- mc_sample_simple(lwed_Qs,
                               nu = "PO",
                               de = "U",
                               lambda_stars = seq(-2, 16, by = 0.1))
lwed_PO_is_test

# logl ratio that gives largest FPR smaller than fprGoal = 8.1
lwed_PO_is_test1_optLOD <- lwed_PO_is_test %>%
  filter(FPR > lwed_fprGoal) %>%
  arrange(FPR) %>%
  dplyr::slice(1)
lwed_PO_is_test1_optLOD
lwed_optLOD_test1 <- lwed_PO_is_test1_optLOD$Lambda_star

# SIMP
simp_PO_is_test <- mc_sample_simple(simp_Qs,
                               nu = "PO",
                               de = "U",
                               lambda_stars = seq(-2, 16, by = 0.1))
simp_PO_is_test

# logl ratio that gives largest FPR smaller than fprGoal = 7.5
simp_PO_is_test1_optLOD <- simp_PO_is_test %>%
  filter(FPR > simp_fprGoal) %>%
  arrange(FPR) %>%
  dplyr::slice(1)
simp_PO_is_test1_optLOD
simp_optLOD_test1 <- simp_PO_is_test1_optLOD$Lambda_star
```

The optimal logl ratio cutoffs for LWED = 8.1 and SIMP = 7.5 -- both,
however, come with rather high FNR values (0.529 and 0.591,
respectively). So these logl cutoffs would give us decent confidence in
our assignments while having a higher chance of ditching true PO pairs.

------------------------------------------------------------------------

Alternatively, we could choose a logl cutoff that optimizes the
trade-off between false negative and false positive errors by
identifying the logl ratio (LOD) that maximizes the product of the two
(following McPhee et al. 2014;
<https://github.com/mvmcphee/Auke_sockeye_F1_RP/blob/main/scripts/SAUKE_F1_Rscript_01_CKMRsim.R>)

```{r}
# LWED
lwed_PO_is_test2 <- mc_sample_simple(lwed_Qs,
                                 nu = "PO",
                                 de = "U",
                                 lambda_stars = seq(-2, 16, by = 0.1))
lwed_PO_is_test2

ggplot(data = lwed_PO_is_test2) +
  (aes(x = Lambda_star, y = (FNR*FPR))) +
  geom_point() +
  scale_x_continuous(limits = c(-2, 16), breaks = seq(-2, 16, by = 1)) +
  theme_Publication()

# value that maximizes FNR*FPR = 3 (fnr 0.0537; fpr 0.00268)
lwed_PO_is_test2_optLOD <- lwed_PO_is_test2 %>%
  mutate(fnrFPR = FNR * FPR) %>%
  relocate(fnrFPR) %>%
  arrange(desc(fnrFPR)) %>%
  dplyr::slice(1)
lwed_PO_is_test2_optLOD
lwed_optLOD_test2 <- lwed_PO_is_test2_optLOD$Lambda_star

# SIMP
simp_PO_is_test2 <- mc_sample_simple(simp_Qs,
                                 nu = "PO",
                                 de = "U",
                                 lambda_stars = seq(-2, 16, by = 0.1))
simp_PO_is_test2

ggplot(data = simp_PO_is_test2) +
  (aes(x = Lambda_star, y = (FNR*FPR))) +
  geom_point() +
  scale_x_continuous(limits = c(-2, 16), breaks = seq(-2, 16, by = 1)) +
  theme_Publication()

# value that maximizes FNR*FPR = 2.5 (fnr 0.0631; fpr 0.00517)
simp_PO_is_test2_optLOD <- simp_PO_is_test2 %>%
  mutate(fnrFPR = FNR * FPR) %>%
  relocate(fnrFPR) %>%
  arrange(desc(fnrFPR)) %>%
  dplyr::slice(1)
simp_PO_is_test2_optLOD
simp_optLOD_test2 <- simp_PO_is_test2_optLOD$Lambda_star
```

## Pairwise comparisons

Just curious what this will come up with vs. franz

```{r}
lwed_matchers <- find_close_matching_genotypes(lwed_genos_forCKMR,
                                               lwed_ckmr,
                                               max_mismatch = 6)

test <- create_integer_genotype_matrix(lwed_genos_forCKMR, lwed_afreqs_ready)

unique(lwed_afreqs_ready$Locus) %in% unique(lwed_genos_forCKMR$Locus)


lwed_candidate_parents <- lwed_genos_forCKMR %>%
  merge(., sampleRef[, c("sampleID", "birthYear_est")], by.x = "Indiv", by.y = "sampleID", all.x = T) %>%
  filter(birthYear_est != 2019) %>%
  select(-birthYear_est)

lwed_candidate_offspring <- lwed_genos_forCKMR %>%
  merge(., sampleRef[, c("sampleID", "birthYear_est")], by.x = "Indiv", by.y = "sampleID", all.x = T) %>%
  filter(birthYear_est == 2019) %>%
  select(-birthYear_est)

# use juvs from 2019; all others = candidate parents
lwed_po_pairwise_logls <- pairwise_kin_logl_ratios(
  D1 = lwed_candidate_parents,
  D2 = lwed_candidate_offspring,
  CK = lwed_ckmr,
  numer = "PO",
  denom = "U")
```


# 5 Summary stats

Print basic info

```{r}
lwed_gen
```

Print number of alleles per locus

```{r}
table(lwed_gen$loc.fac)
```

Print sample size for each site (NA)

```{r}
summary(lwed_gen$pop)
```

Print mean allelic richness per site across all loci (NA)

```{r}
allelic.richness(genind2hierfstat(lwed_gen))$Ar %>%
  apply(MARGIN = 2, FUN = mean) %>%
  round(digits = 3)
```

INBREEDING COEFFICIENT (Fis)

```{r}

```

# X Nf, Nm

## Some background

-   Jolly-Seber (JS) model - focused on estimating abundance parameters
    (e.g., pop growth, recruitment, and abundance)
    -   explicit definitions of process by which unmarked animals are
        newly captured and marked; assumptions about process allows est
        of recruitment and pop sizes
    -   assumed that unmarked indivs in pop have same prob of capture as
        marked indiv in pop (i.e., newly captured unmarked animals are a
        random sample of all unmarked animals in pop)
-   Cormack-Jolly-Seber (CJS) models - focused on estimating survival
    rates (but not abundance)
    -   no assumptions made about how newly marked animals are obtained
    -   subsequent process of recovering marked animals in CJS is
        conditional upon animal being released alive at first encounter;
        survival and catchability refer only to those marked animals

Based on Iijima (2020), I want:

-   **capture-recapture model for open population**, where an "open
    population" is one in which the number of individuals can change via
    natural mortality, birth, and migration during the study period -
    may also benefit from **robust design** where multiple surveys are
    conducted under a constant condition
-   1st hierarchy of sampling in which variables can change across
    sampling periods
-   2nd hierarchy of sampling in which things should remain relatively
    stable

And based on Sandercock & Murray (2020), I may also want:

-   a multistate model, in which detections are coded as dynamic
    categorical states that potentially change b/t consecutive occasions

**Resources:** - James Paterson has a
blog(<https://jamesepaterson.github.io/jamespatersonblog/2020-07-26_jolly_seber_models.html>)
with a lot of really great info on how to use mark & recapture data

## About the model

We can estimate *N* for FRANz by estimating abundance via the POPAN
formulation (Schwarz & Arnason 1996) of the Jolly-Seber mark-recapture
model. Note that Jolly-Seber models make the following assumptions (from
Schwarz & Arnason 2021 in Program MARK book):

1)  indivs retain their tags throughout experiment
2)  tags are read properly
3)  sampling is instantaneous
4)  survival probabilities are same for all indivs (marked and unmarked)
    b/t each pair of sampling occasions (homogeneous survival)
5)  catchability is same for all indivs (marked and unmarked) at each
    sampling event (homogeneous catchability) ((most crucial assumption
    for JS models))
6)  study area is constant - if study area changes over time, then pop
    size may change w/changing size of study area

The POPAN formulation modifies the parameterization of JS slightly by
postulating 1) the existence of a *super-population* containing all of
the indivs that would ever be born to the population and 2) parameter
b_i representing the probability that an indiv from the hypothetical
super-population would enter the population b/t occasion i and i + 1.

## Create capture histories

Just using 2009-2019 data to align w/geno data

```{r}
capHist <- capData %>%
  # filter to 2009-2019 only
  arrange(rowID) %>%
  filter(as.numeric(rowID) < 614) %>%
  
  select(animalID, captureDate) %>%
  filter(animalID != "UNK") %>%
  mutate(
    captureYear = as.numeric(str_sub(captureDate, 1, 4))
  ) %>%
  select(-captureDate) %>%
  mutate(
    detect = 1
  ) %>%
  
  # format as capture history (notes below are from James Paterson blog)
  
  # remove duplicates, which may occur when individuals are caught multiple times in an event
  # For example, your event may be a year and an individual may be caught multiple times in a year.
  distinct() %>%
  
  # spread out data. The fill = 0 adds rows for combinations of id and event where individuals were not observerd
  spread(captureYear, detect, fill = 0) %>% 
  
  # For every individual....
  group_by(animalID) %>%
  # Paste together 0's and 1's
  # Unite is similar to paste. Here we are pasting the strings together from the second column (first capture event)
  # to the last capture event ("tail(names(.),1)").
  # we don't want any characters separating 0's and 1's, so we use: sep = ""
  unite("ch", 2:tail(names(.),1), sep = "") %>%
  
  # add sex (as factor)
  merge(., capData[, c("animalID", "sex", "species")], by = "animalID") %>%
  distinct() %>%
  mutate(
    sex = as.factor(sex)
  )

# species/sex subsets
capHist_lwedF <- capHist %>%
  filter(species == "LWED") %>%
  filter(sex == "F")
capHist_lwedM <- capHist %>%
  filter(species == "LWED") %>%
  filter(sex == "M")

capHist_simpF <- capHist %>%
  filter(species == "SIMP") %>%
  filter(sex == "F")
capHist_simpM <- capHist %>%
  filter(species == "SIMP") %>%
  filter(sex == "M")
```

## Run model

**Load 'marked'**

Using package 'marked' (make sure RMark is detached first! too many
overlapping function names)

```{r}
#detach("package:RMark", unload=TRUE)
library(marked)
```

**1. Process data**

```{r}
# lwed
lwedF.js.proc <- process.data(capHist_lwedF,
                              model = "JS")
lwedM.js.proc <- process.data(capHist_lwedM,
                              model = "JS")

# simp
simpF.js.proc <- process.data(capHist_simpF,
                              model = "JS")
simpM.js.proc <- process.data(capHist_simpM,
                              model = "JS")
```

**2. Make design data**

```{r}
lwedF.js.ddl <- make.design.data(lwedF.js.proc)
lwedM.js.ddl <- make.design.data(lwedM.js.proc)

simpF.js.ddl <- make.design.data(simpF.js.proc)
simpM.js.ddl <- make.design.data(simpM.js.proc)
```

**3. Fit models**

```{r}
fit.js.models <- function(procData, designData) {
  # Phi formulas
  Phi.dot <- list(formula=~1)
  Phi.time <- list(formula=~time)
  # p formulas
  p.dot <- list(formula=~1)
  # pent formulas. pent estimates MUST SUM to 1 (for each group).
  # This is constained using a Multinomial Logit link
  pent.time <- list(formula=~time)
  pent.dot <- list(formula=~1)
  # Nsuper formulas. Don't confuse "N" from model with predicted population size
  N.dot <- list(formula=~1)
  cml <- create.model.list(c("Phi","p", "pent", "N"))
  results <- crm.wrapper(cml,
                         data = procData,
                         ddl = designData,
                         external = FALSE,
                         accumulate = FALSE,
                         hessian = TRUE)
  
  return(results)
}
```

**3. Run function**

```{r}
# run function
lwedF.js.models <- fit.js.models(lwedF.js.proc, lwedF.js.ddl)
lwedM.js.models <- fit.js.models(lwedM.js.proc, lwedM.js.ddl)

simpF.js.models <- fit.js.models(simpF.js.proc, simpF.js.ddl)
simpM.js.models <- fit.js.models(simpM.js.proc, simpM.js.ddl)

# view models
lwedF.js.models
lwedM.js.models

simpF.js.models
simpM.js.models
```

**4. Estimate real parameters**

We can look at the top model estimates:

```{r}
# pull top model
lwedF.js.models[[1]]
lwedM.js.models[[1]]

simpF.js.models[[1]]
simpM.js.models[[1]]
```

But these estimates \^\^ are not on probability scale (or in individuals
for N) (e.g. Phi, p on logit scale, pent on mlogit scale) - so we need
to use the *predict* function to estimate the real parameters:

```{r}
# predict real values
lwedF.js.predicted <- predict(lwedF.js.models[[1]])
lwedM.js.predicted <- predict(lwedM.js.models[[1]])

simpF.js.predicted <- predict(simpF.js.models[[1]])
simpM.js.predicted <- predict(simpM.js.models[[1]])

# look at predictions of real parameters
lwedF.js.predicted
lwedM.js.predicted

simpF.js.predicted
simpM.js.predicted

# what these parameters are saying (just lwedF for an example):
lwedF.js.predicted$Phi$estimate # 0.64 survival b/t capture events
lwedF.js.predicted$p$estimate # 0.84 detection prob
lwedF.js.predicted$pent # 0.09 prob of entry for each capture event
lwedF.js.predicted$N$estimate # ~ 5 unmarked indiv
```

## Estimate pop size

(from Paterson blog): There is no direct estimate of population size in
the model. The estimate of "N" in the model output is for the number of
unmarked individuals in the superpopulation.

To estimate population size, we can derive it using the model estimates:

```         
N_t+1 = (N_t * phi_t) + (N_super * pent_t)
```

In words, this equation says that the **population size** is the
**previous population size** times the **survival rate** (to calculate
how many individuals survive) plus the **number of new individuals**
from births and immigration.

To get the inital population size, we estimate pent_1 by the constraint:

```         
pent_1 = ` - SUM(pent_2..t)
```

Abundance (N) is derived from the estimated parameters We will estimate
population size at each time by making a dataframe of estimates and
calculating N We will use the predicted estimates from the
top-performing model (in this case: "dipper.js.predicted")

```{r}
# number of capture events
n_capEvents <- nchar("00011000000")

# number of survival estimates
nrow(lwedF.js.predicted$pent)

# number of captured indivs
lwedF_nCap <- nrow(capData_2009to2019_firstEntry[capData_2009to2019_firstEntry$species == "LWED" & capData_2009to2019_firstEntry$sex == "F",])
lwedM_nCap <- nrow(capData_2009to2019_firstEntry[capData_2009to2019_firstEntry$species == "LWED" & capData_2009to2019_firstEntry$sex == "M",])

simpF_nCap <- nrow(capData_2009to2019_firstEntry[capData_2009to2019_firstEntry$species == "SIMP" & capData_2009to2019_firstEntry$sex == "F",])
simpM_nCap <- nrow(capData_2009to2019_firstEntry[capData_2009to2019_firstEntry$species == "SIMP" & capData_2009to2019_firstEntry$sex == "M",])

lwedF_N.derived <- data.frame(
  # 11 capture events
  occ = c(1:11),
  # 10 survival estimates all the same
  Phi = c(rep(lwedF.js.predicted$Phi$estimate, 10), NA),
  # Nsuper estimate + number of marked animals
  Nsuper = rep(lwedF.js.predicted$N$estimate + lwedF_nCap, n_capEvents),
  # sum of all pent must be 1
  pent = c(1-sum(lwedF.js.predicted$pent$estimate),
           lwedF.js.predicted$pent$estimate))

# Set-up empty vector for calculating N
lwedF_N.derived$N <- NA

# The inital population size (N[1]) = Nsuper * (1 - sum(all other pent estimates))
# This is because of the link function for estimating pent.
# The sum of all pent parameters MUST equal 1 (therefore, one less must be estimated)
lwedF_N.derived$N[1] <- (lwedF_N.derived$Nsuper[1] * lwedF_N.derived$pent[1])

# Subsequent population sizes are estimated by calculating surviving individuals (N[t-1] * Phi[t]), and
# Adding new births (Nsuper * pent[t])
for(i in 2:nrow(lwedF_N.derived)){
  lwedF_N.derived$N[i] <- (lwedF_N.derived$N[i-1]*lwedF_N.derived$Phi[i-1]) + (lwedF_N.derived$Nsuper[i] * lwedF_N.derived$pent[i])
}

# Look at what we did
lwedF_N.derived
```

\^\^I'm pretty sure what this is giving is the number of indivs PER YEAR
vs. Nsuper = number of indivs across ALL YEARS in the pop

We have now derived the population size (N) using the estimates form our
Jolly-Seber model. But, how do we estimate standard error and confidence
intervals?

```{r}
# and get estimates of unmarked individuals
lwedF_js_unmarkEst <- round(lwedF.js.predicted$N$estimate)
lwedM_js_unmarkEst <- round(lwedM.js.predicted$N$estimate)

simpF_js_unmarkEst <- round(simpF.js.predicted$N$estimate)
simpM_js_unmarkEst <- round(simpM.js.predicted$N$estimate)
```

## Assign Nsuper

Using output from JS models for estimates of unmarked females & males
for each species added to capData numbers:

```{r}
# number of captured indivs
lwed_n_capF <- nrow(capData_2009to2019_firstEntry[capData_2009to2019_firstEntry$species == "LWED" & capData_2009to2019_firstEntry$sex == "F",])
lwed_n_capM <- nrow(capData_2009to2019_firstEntry[capData_2009to2019_firstEntry$species == "LWED" & capData_2009to2019_firstEntry$sex == "M",])

simp_n_capF <- nrow(capData_2009to2019_firstEntry[capData_2009to2019_firstEntry$species == "SIMP" & capData_2009to2019_firstEntry$sex == "F",])
simp_n_capM <- nrow(capData_2009to2019_firstEntry[capData_2009to2019_firstEntry$species == "SIMP" & capData_2009to2019_firstEntry$sex == "M",])

lwed_n_capF # 68
lwed_n_capM # 77

simp_n_capF # 48
simp_n_capM # 54

# calculate super-population totals
lwed_Nf <- lwed_n_capF +
  lwedF_js_unmarkEst
lwed_Nm <- lwed_n_capM +
  lwedM_js_unmarkEst

simp_Nf <- simp_n_capF +
  simpF_js_unmarkEst
simp_Nm <- simp_n_capM +
  simpM_js_unmarkEst

lwed_Nf # 73
lwed_Nm # 82

simp_Nf # 52
simp_Nm # 60
```

# FRANz

Following Shedd et al GitHub
1_RRS_Hogan_13_15.Rmd<https://github.com/krshedd/Relative-fitness-of-Pink-Salmon/blob/main/analysis/1_RRS_Hogan_13_15.Rmd>

## Create input files

**Subset genos to samples with \>= 70% genotyping success**

### Prep files

**LWED**

```{r}
lwed_genos_franz_temp <- lwed_genos %>%
  column_to_rownames("sampleID") %>%
  select(-c(animalID, sex, birthYear_est, pop, captureYear))

lwed_genos_franz <- names(lwed_genos_franz_temp) %>%
  map_dfc(~ lwed_genos_franz_temp %>%
            select(all_of(.x)) %>%
            separate(.x,
                     into = paste0(.x, c("a", "b")),
                     sep = ",")
          ) %>%
  
  # add sampleID_franz, sex, & animalID (animalID is just for merging birthYear)
  rownames_to_column("sampleID") %>%
  merge(., sampleRef[, c("sampleID", "sampleID_franz", "animalID", "sex")], by = "sampleID") %>%
  relocate(c(sampleID_franz, sex)) %>%
  
  # add birthYear
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  dplyr::rename("birthYear" = "birthYear_est") %>%
  relocate(birthYear, .before = "sex") %>%
  
  # add deathYear
  merge(., deathAssignments[, c("animalID", "deathYear_est")], by = "animalID", all.x = T) %>%
  dplyr::rename("deathYear" = "deathYear_est") %>%
  relocate(deathYear, .before = "sex") %>%
  
  # replace allele letters with numbers (required by FRANz)
  mutate_at(vars(starts_with(c("INDID", "LWED", "SIMP"))), ~ str_replace(., "A", "4")) %>%
  mutate_at(vars(starts_with(c("INDID", "LWED", "SIMP"))), ~ str_replace(., "T", "7")) %>%
  mutate_at(vars(starts_with(c("INDID", "LWED", "SIMP"))), ~ str_replace(., "C", "3")) %>%
  mutate_at(vars(starts_with(c("INDID", "LWED", "SIMP"))), ~ str_replace(., "G", "6")) %>%
  arrange(sampleID) %>%
  select(-animalID, -sampleID)

# export
write.csv(lwed_genos_franz, "./DISSERTATION/ch2_demography/00_data/lwed_genos_franz.csv", row.names = F)
```

**SIMP**

```{r}
simp_genos_franz_temp <- simp_genos %>%
  column_to_rownames("sampleID") %>%
  select(-c(animalID, sex, birthYear_est, pop, captureYear))

simp_genos_franz <- names(simp_genos_franz_temp) %>%
  map_dfc(~ simp_genos_franz_temp %>%
            select(all_of(.x)) %>%
            separate(.x,
                     into = paste0(.x, c("a", "b")),
                     sep = ",")
          ) %>%
  
  # add sampleID_franz, sex, & animalID (animalID is just for merging birthYear)
  rownames_to_column("sampleID") %>%
  merge(., sampleRef[, c("sampleID", "sampleID_franz", "animalID", "sex")], by = "sampleID") %>%
  relocate(c(sampleID_franz, sex)) %>%
  
  # add birthYear
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  dplyr::rename("birthYear" = "birthYear_est") %>%
  relocate(birthYear, .before = "sex") %>%
  
  # add deathYear
  merge(., deathAssignments[, c("animalID", "deathYear_est")], by = "animalID", all.x = T) %>%
  dplyr::rename("deathYear" = "deathYear_est") %>%
  relocate(deathYear, .before = "sex") %>%
  
  # replace allele letters with numbers (required by FRANz)
  mutate_at(vars(starts_with(c("INDID", "LWED", "SIMP"))), ~ str_replace(., "A", "4")) %>%
  mutate_at(vars(starts_with(c("INDID", "LWED", "SIMP"))), ~ str_replace(., "T", "7")) %>%
  mutate_at(vars(starts_with(c("INDID", "LWED", "SIMP"))), ~ str_replace(., "C", "3")) %>%
  mutate_at(vars(starts_with(c("INDID", "LWED", "SIMP"))), ~ str_replace(., "G", "6")) %>%
  arrange(sampleID) %>%
  select(-animalID, -sampleID)

# export
write.csv(simp_genos_franz, "./DISSERTATION/ch2_demography/00_data/simp_genos_franz.csv", row.names = F)
```

### .csv to .dat

FRANz provides a perl script (csv.pl) to convert .csv files to .dat
files. The manual says that you can also go to a GUI at
<http://legacy.bioinf.uni-leipzig.de/Software/FRANz/CSV_Import.html>,
but I haven't gotten it to work (it just loads forever).

FRANz has examples of how to use csv.pl in their "man" file; I've edited
their example slightly so that the output automatically creates a new
file.

NOTE that column IDs start with 0.

How to put output into file:
<https://askubuntu.com/questions/420981/how-do-i-save-terminal-output-to-a-file>

**NOTE** - use csv_modified.pl; line 164 has an error in the original
script -- original has "\$death_col = $data->[$death_col];", but should
be "\$death = $data->[$death_col];"

```{r}
system2("perl",
        args="./project_scripts/franz/csv_modified.pl --in ./DISSERTATION/ch2_demography/00_data/lwed_genos_franz.csv --alleles_per_col 1 --has_header --missing_allele 'NA' --birth_col 1 --death_col 2 --sex_col 3 --data_col 4 > ./DISSERTATION/ch2_demography/00_data/lwed_genos_franz.dat")

system2("perl",
        args="./project_scripts/franz/csv_modified.pl --in ./DISSERTATION/ch2_demography/00_data/simp_genos_franz.csv --alleles_per_col 1 --has_header --missing_allele 'NA' --birth_col 1 --death_col 2 --sex_col 3 --data_col 4 > ./DISSERTATION/ch2_demography/00_data/simp_genos_franz.dat")
```

## Sample counts

Quick overview of who all is included:

LWED 1 F 38 (out of Nf = 73) 2 M 34 (out of Nm = 82)

SIMP 1 F 27 (out of Nf = 52) 2 M 28 (out of Nm = 60)

```{r}
lwed_genos_franz %>%
  group_by(sex) %>%
  summarise(count = n())

sum(!is.na(lwed_genos_franz$birthYear)) # 29
sum(is.na(lwed_genos_franz$birthYear)) # 43


simp_genos_franz %>%
  group_by(sex) %>%
  summarise(count = n())

sum(!is.na(simp_genos_franz$birthYear)) # 28
sum(is.na(simp_genos_franz$birthYear)) # 27
```

## Assign Nf & Nm

From FRANz manual: *N* is the number of candidate female (*Nf*) and male
(*Nm*) parents in the population, equal to the sum of the average number
of sampled (*n*) and unsampled (*N-n*) breeding females and males in the
population (respectively). If unset, then estimated jointly with the
pedigree. For parentage inference N=Nf=Nm (NOT Nf+Nm), but one can also
specify Nf and Nm instead of N if these numbers differ. If N isnot
known, use Nmax instead.

The FRANz manual suggests that if a good estimate of Nf/Nm is possible,
specifying these variables is preferable to Nfmax/Nmmax (the maximum
number of candidate female/male parents in the population). As such, I'm
using the sex-specific abundance estimates calculated in
ch2_demography.Rmd (currently in ch2_relatedness.Rmd tho, need to move
it) based on capData records.

```         
lwed_Nf = 73
lwed_Nm = 82

simp_Nf = 52
simp_Nm = 60
```

## franz_run1

### Run script

```{bash}
# lwed
cd /home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/lwed/franz_run1

FRANz --femrepro 2:30 --malerepro 2:30 --Nf 73 --Nm 82 --fullsibtest --fullsibparental --updatefreqs --poutformat 2 ./../../../00_data/lwed_genos_franz.dat

# simp
cd ./../../simp/franz_run1

FRANz --femrepro 2:30 --malerepro 2:30 --Nf 52 --Nm 60 --fullsibtest --fullsibparental --updatefreqs --poutformat 2 ./../../../00_data/simp_genos_franz.dat
```

FRANz parameters are defined as follows: --femrepro and --malerepro
specify the age ranges in which females and males can reproduce

--Nf and --Nm specify the number of candidate female and male parents in
the population, which is the sum of the average number of sampled (n)
and unsampled (N-n) breeding females/males in the population. The FRANz
manual suggests that if a good estimate of Nf/Nm is possible, specifying
these variables is preferable to Nfmax/Nmmax (the maximum number of
candidate female/male parents in the population)

--fullsibtest specifies that FRANz should run the fullsib heuristic (as
described in Riester et al. 2009)

--fullsibparental specifies that FRANz should also detect fullsibs in
the parent generation

--updatefreqs specifies that FRANz should update allele frequencies
using MCMC sampling

--poutformat 2 specifies that parentage output files should include all
with positive LOD (vs. just the most likely parentages)

**NOTE** that FRANz automatically sets --mintyped loci to (1+loci)/2;
this also defines the min number of common typed loci for a pair of
indivs. Other defaults include:

-   typingerror = 0.01

### Assess results

#### Cumulative exclusion probability

LWED: Cumulative exclusion probability when 1 to 7 fullsibs are
genotyped First Parent : 0.9971977 0.9998257 0.9999910 0.9999988
0.9999994 0.9999995 0.9999995 Second Parent : 0.9999621 0.9999996
1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 Parent Pair :
0.9999999 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000

SIMP: Cumulative exclusion probability when 1 to 7 fullsibs are
genotyped First Parent : 0.9925770 0.9992520 0.9999363 0.9999884
0.9999937 0.9999941 0.9999941 Second Parent : 0.9998635 0.9999972
0.9999999 1.0000000 1.0000000 1.0000000 1.0000000 Parent Pair :
0.9999994 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000

#### PO assignments

FRANz colnames are not my favorite - set new ones:

```{r}
colnames_parentage <- c("offspring",
                        "lociTyped_offspring",
                        "parent1",
                        "lociTyped_parent1",
                        "parent2",
                        "lociTyped_parent2",
                        "LOD",
                        "posterior",
                        "commonLociTyped",
                        "mismatches",
                        "n_f",
                        "n_m",
                        "pairLOD_parent1",
                        "pairLOD_parent2",
                        "posterior_parent1",
                        "posterior_parent2",
                        "parentage_mlPedigree")
```

**PO assignments**

```{r}
lwed_po_run1_file <- read_csv("./DISSERTATION/ch2_demography/02_results/lwed/franz_run1/parentage.csv") %>%
  separate('Posterior Parent 2', c("pp2", "mlPed"), sep = ",") %>%
  `colnames<-`(colnames_parentage) %>%
  mutate(
    rowID = row_number(),
    poType = case_when(
      !is.na(parent1) & !is.na(parent2) ~ "triple",
      !is.na(parent1) & is.na(parent2) ~ "dyad",
      is.na(parent1) & !is.na(parent2) ~ "dyad",
      .default = NA
      ),
    poType = case_when(
      !is.na(parentage_mlPedigree) ~ str_c(poType, "_ml"),
      .default = poType
      )
    ) %>%
  relocate(c(rowID, poType))

simp_po_run1_file <- read_csv("./DISSERTATION/ch2_demography/02_results/simp/franz_run1/parentage.csv") %>%
  separate('Posterior Parent 2', c("pp2", "mlPed"), sep = ",") %>%
  `colnames<-`(colnames_parentage) %>%
  mutate(franzRun = "run1") %>%
  mutate(
    rowID = row_number(),
    poType = case_when(
      !is.na(parent1) & !is.na(parent2) ~ "triple",
      !is.na(parent1) & is.na(parent2) ~ "dyad",
      is.na(parent1) & !is.na(parent2) ~ "dyad",
      .default = NA
      ),
    poType = case_when(
      !is.na(parentage_mlPedigree) ~ str_c(poType, "_ml"),
      .default = poType
      )
    ) %>%
  relocate(c(rowID, poType))
```

**Take a peek at parentage posterior probabilities**

Definitely a lot on the low side, but this makes sense since I opted to
include all pairs w/a positive LOD score in the output (vs. most likely
PO pairs)

```{r}
lwed_po_run1_file %>%
  filter(!is.na(parent1)) %>%
  ggplot(aes(x = posterior)) +
  geom_histogram(breaks = seq(0, 1, 0.01)) +
  ggtitle("Histogram of FRANz posterior probabilities for parentage assignments") +
  theme_bw()

simp_po_run1_file %>%
  filter(!is.na(parent1)) %>%
  ggplot(aes(x = posterior)) +
  geom_histogram(breaks = seq(0, 1, 0.01)) +
  ggtitle("Histogram of FRANz posterior probabilities for parentage assignments") +
  theme_bw()
```

**PO checks**

```{r}
# reload genos
lwed_genos_franz <- read.csv("./DISSERTATION/ch2_demography/00_data/lwed_genos_franz.csv")
simp_genos_franz <- read.csv("./DISSERTATION/ch2_demography/00_data/simp_genos_franz.csv")

# LWED
lwed_po_run1 <- lwed_po_run1_file %>%
  # use optLOD_test1 to minimize false-positives
  filter(LOD > lwed_optLOD_test1) %>%
  # add v conservative posterior cutoff to increase prob of accurate assignments
  filter(posterior > 0.9) %>%
  select(rowID, poType, offspring, parent1, parent2) %>%
  pivot_longer(-c(rowID, poType, offspring),
               names_to = "parentID",
               values_to = "parent") %>%
  na.omit() %>%
  
  # add birthYear and sex
  merge(., lwed_genos_franz[, c("sampleID_franz", "birthYear", "sex")], by.x = "parent", by.y = "sampleID_franz", all.x = T) %>%
  merge(., lwed_genos_franz[, c("sampleID_franz", "birthYear", "sex")], by.x = "offspring", by.y = "sampleID_franz", all.x = T, suffixes = c("_par", "_off")) %>%
  
  # add groups
  mutate(
    animalID_par = gsub(".*_([0-9]+)$", "\\1", parent),
    animalID_off = gsub(".*_([0-9]+)$", "\\1", offspring)
    ) %>%
  
  mutate(
    temp = as.numeric(birthYear_off) - 1
    ) %>%
  merge(., capData_2009to2019[, c("animalID", "captureYear", "groupName")], by.x = c("animalID_par", "temp"), by.y = c("animalID", "captureYear"), all.x = T) %>%
  select(-temp) %>%
  
  merge(., capData_2009to2019[, c("animalID", "captureYear", "groupName")], by.x = c("animalID_off", "birthYear_off"), by.y = c("animalID", "captureYear"), all.x = T, suffixes = c("_par", "_off")) %>%
  
  # same groupName?
  mutate(
    groupMatch = groupName_par == groupName_off
  ) %>%
  
  # add parity for F
  merge(., parityAssigments_firstParous[, c("animalID", "parityYear")], by.x = "animalID_par", by.y = "animalID", all.x = T) %>%
  mutate(
    diff_birth.parity = as.numeric(birthYear_off) - as.numeric(parityYear)
  ) %>%
  
  relocate(parentID, poType, parent, offspring, animalID_par, animalID_off, sex_par, sex_off, diff_birth.parity, groupMatch, birthYear_par, parityYear, birthYear_off, groupName_par, groupName_off)

temp <- lwed_po_run1_file %>%
  filter(LOD > lwed_optLOD_test1)

# SIMP
simp_po_run1 <- simp_po_run1_file %>%
  # use optLOD_test1 to minimize false-positives
  filter(LOD > simp_optLOD_test1) %>%
  # add v conservative posterior cutoff to increase prob of accurate assignments
  filter(posterior > 0.9) %>%
  select(offspring, parent1, parent2) %>%
  pivot_longer(-offspring,
               names_to = "parentID",
               values_to = "parent") %>%
  select(-parentID) %>%
  na.omit() %>%
  
  # add birthYear and sex
  merge(., simp_genos_franz[, c("sampleID_franz", "birthYear", "sex")], by.x = "parent", by.y = "sampleID_franz", all.x = T) %>%
  merge(., simp_genos_franz[, c("sampleID_franz", "birthYear", "sex")], by.x = "offspring", by.y = "sampleID_franz", all.x = T, suffixes = c("_par", "_off")) %>%
  
  # add groups
  mutate(
    animalID_par = gsub(".*_([0-9]+)$", "\\1", parent),
    animalID_off = gsub(".*_([0-9]+)$", "\\1", offspring)
    ) %>%
  
  mutate(
    temp = as.numeric(birthYear_off) - 1
    ) %>%
  merge(., capData_2009to2019[, c("animalID", "captureYear", "groupName")], by.x = c("animalID_par", "temp"), by.y = c("animalID", "captureYear"), all.x = T) %>%
  select(-temp) %>%
  
  merge(., capData_2009to2019[, c("animalID", "captureYear", "groupName")], by.x = c("animalID_off", "birthYear_off"), by.y = c("animalID", "captureYear"), all.x = T, suffixes = c("_par", "_off")) %>%
  
  # same groupName?
  mutate(
    groupMatch = groupName_par == groupName_off
  ) %>%
  
  # add parity for F
  merge(., parityAssigments_firstParous[, c("animalID", "parityYear")], by.x = "animalID_par", by.y = "animalID", all.x = T) %>%
  mutate(
    diff_birth.parity = as.numeric(birthYear_off) - as.numeric(parityYear)
  ) %>%
  
  relocate(parent, offspring, animalID_par, animalID_off, sex_par, sex_off, diff_birth.parity, groupMatch, birthYear_par, parityYear, birthYear_off, groupName_par, groupName_off)
```

**PO pedigree.dat**

Just filtering by groupMatch == T; filtering by diff_birth.parity gives
too few I think

LWED: F = 5, M = 5 SIMP: F = 3, M = 1

```{r}
lwed_po_run1_forPed <- lwed_po_run1 %>%
  filter(groupMatch == TRUE) %>%
  mutate(franzPed = str_c(parent, offspring))

simp_po_run1_forPed <- simp_po_run1 %>%
  filter(groupMatch == TRUE) %>%
  mutate(franzPed = str_c(parent, offspring))

# overview of parent assignment numbers for pedigree.dat
lwed_po_run1_forPed %>%
  group_by(sex_par) %>%
  summarise(count = n())

simp_po_run1_forPed %>%
  group_by(sex_par) %>%
  summarise(count = n())
```

Reformat and export as .dat files

```{r}
nrow(lwed_genos_franz) # 72 lwed samples
nrow(simp_genos_franz) # 55 simp samples

lwed_ped_forRun2 <- c(lwed_genos_franz$sampleID_franz,
                      lwed_po_run1_forPed$franzPed) %>%
  as.data.frame() %>%
  dplyr::rename("72" = ".")

simp_ped_forRun2 <- c(simp_genos_franz$sampleID_franz,
                      simp_po_run1_forPed$franzPed) %>%
  as.data.frame() %>%
  dplyr::rename("55" = ".")

# export
write.table(lwed_ped_forRun2, file = "./DISSERTATION/ch2_demography/00_data/lwed_poPed_forRun2.dat", quote = F, row.names = F)

write.table(simp_ped_forRun2, file = "./DISSERTATION/ch2_demography/00_data/simp_poPed_forRun2.dat", quote = F, row.names = F)
```

#### SIB assignments

```{r}
lwed_sibs_run1 <- read_franzSibs("./DISSERTATION/ch2_demography/02_results/lwed/franz_run1/siblings.txt") %>%
  merge(., twinList[, c("sampleID_franz", "twinSet")], by.x = "sample1", by.y = "sampleID_franz", all.x = T) %>%
  merge(., twinList[, c("sampleID_franz", "twinSet")], by.x = "sample2", by.y = "sampleID_franz", all.x = T, suffixes = c("_1", "_2")) %>%
  mutate(
    twinSetMatch = twinSet_1 == twinSet_2
  ) %>%
  relocate(sample1)


simp_sibs_run1 <- read_franzSibs("./DISSERTATION/ch2_demography/02_results/simp/franz_run1/siblings.txt") %>%
  merge(., twinList[, c("sampleID_franz", "twinSet")], by.x = "sample1", by.y = "sampleID_franz", all.x = T) %>%
  merge(., twinList[, c("sampleID_franz", "twinSet")], by.x = "sample2", by.y = "sampleID_franz", all.x = T, suffixes = c("_1", "_2")) %>%
  mutate(
    twinSetMatch = twinSet_1 == twinSet_2
  ) %>%
  relocate(sample1)
```

## franz_run2

### Run script

```{bash}
# lwed
cd /home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/lwed/franz_run2

FRANz --femrepro 2:30 --malerepro 2:30 --Nf 73 --Nm 82 --pedigreein ./../../../00_data/lwed_poPed_forRun2.dat --fullsibtest --fullsibparental --updatefreqs --poutformat 2 ./../../../00_data/lwed_genos_franz.dat

# simp
cd ./../../simp/franz_run2

FRANz --femrepro 2:30 --malerepro 2:30 --Nf 52 --Nm 60 --pedigreein ./../../../00_data/simp_poPed_forRun2.dat --fullsibtest --fullsibparental --updatefreqs --poutformat 2 ./../../../00_data/simp_genos_franz.dat
```

### Assess results

#### PO assignments

**PO assignments**

```{r}
lwed_po_run2_file <- read_csv("./DISSERTATION/ch2_demography/02_results/lwed/franz_run2/parentage.csv") %>%
  separate('Posterior Parent 2', c("pp2", "mlPed"), sep = ",") %>%
  `colnames<-`(colnames_parentage) %>%
  mutate(franzRun = "run2")

simp_po_run2_file <- read_csv("./DISSERTATION/ch2_demography/02_results/simp/franz_run2/parentage.csv") %>%
  separate('Posterior Parent 2', c("pp2", "mlPed"), sep = ",") %>%
  `colnames<-`(colnames_parentage) %>%
  mutate(franzRun = "run2")
```

**PO checks**

```{r}
# LWED
lwed_po_run2 <- lwed_po_run2_file %>%
  # remove NA assignments
  filter(!is.na(parent1)) %>%
  # filter by optimum CKMRsim LOD score for LWED - use test 2 results (optimal for FNRxFPR)
  filter(LOD > lwed_optLOD_test2) %>%
  #filter(posterior > 0.9) %>%
  select(offspring, parent1, parent2, LOD, posterior) %>%
  
  pivot_longer(-c(offspring, LOD, posterior),
               names_to = "parentID",
               values_to = "parent") %>%
  select(-parentID) %>%
  na.omit() %>%
  
  # add birthYear and sex
  merge(., lwed_genos_franz[, c("sampleID_franz", "birthYear", "sex")], by.x = "parent", by.y = "sampleID_franz", all.x = T) %>%
  merge(., lwed_genos_franz[, c("sampleID_franz", "birthYear", "sex")], by.x = "offspring", by.y = "sampleID_franz", all.x = T, suffixes = c("_par", "_off")) %>%
  
  # add groups
  mutate(
    animalID_par = gsub(".*_([0-9]+)$", "\\1", parent),
    animalID_off = gsub(".*_([0-9]+)$", "\\1", offspring)
    ) %>%
  
  mutate(
    temp = as.numeric(birthYear_off) - 1
    ) %>%
  merge(., capData_2009to2019[, c("animalID", "captureYear", "groupName")], by.x = c("animalID_par", "temp"), by.y = c("animalID", "captureYear"), all.x = T) %>%
  select(-temp) %>%
  
  merge(., capData_2009to2019[, c("animalID", "captureYear", "groupName")], by.x = c("animalID_off", "birthYear_off"), by.y = c("animalID", "captureYear"), all.x = T, suffixes = c("_par", "_off")) %>%
  
  # same groupName?
  mutate(
    groupMatch = groupName_par == groupName_off
  ) %>%
  
  # add parity for F
  merge(., parityAssigments_firstParous[, c("animalID", "parityYear")], by.x = "animalID_par", by.y = "animalID", all.x = T) %>%
  mutate(
    diff_birth.parity = as.numeric(birthYear_off) - as.numeric(parityYear)
  ) %>%
  
  # check birthYears when available
  mutate(
    diff_birthOff.birthPar = as.numeric(birthYear_off) - as.numeric(birthYear_par)
  ) %>%
  
  relocate(parent, offspring, LOD, posterior, animalID_par, animalID_off, sex_par, sex_off, diff_birth.parity, diff_birthOff.birthPar, groupMatch, birthYear_par, parityYear, birthYear_off, groupName_par, groupName_off) %>%
  arrange(offspring, parent) %>%
  # subset to dam/sire with highest posterior for each offspring
  group_by(offspring, sex_par) %>%
  slice_max(posterior) %>%
  ungroup()


# SIMP
simp_po_run2 <- simp_po_run2_file %>%
  # remove NA assignments
  filter(!is.na(parent1)) %>%
  # filter by optimum CKMRsim LOD score for LWED - use test 2 results (optimal for FNRxFPR)
  filter(LOD > simp_optLOD_test2) %>%
  #filter(posterior > 0.9) %>%
  select(offspring, parent1, parent2, LOD, posterior) %>%
  
  pivot_longer(-c(offspring, LOD, posterior),
               names_to = "parentID",
               values_to = "parent") %>%
  select(-parentID) %>%
  na.omit() %>%
  
  # add birthYear and sex
  merge(., lwed_genos_franz[, c("sampleID_franz", "birthYear", "sex")], by.x = "parent", by.y = "sampleID_franz", all.x = T) %>%
  merge(., lwed_genos_franz[, c("sampleID_franz", "birthYear", "sex")], by.x = "offspring", by.y = "sampleID_franz", all.x = T, suffixes = c("_par", "_off")) %>%
  
  # add groups
  mutate(
    animalID_par = gsub(".*_([0-9]+)$", "\\1", parent),
    animalID_off = gsub(".*_([0-9]+)$", "\\1", offspring)
    ) %>%
  
  mutate(
    temp = as.numeric(birthYear_off) - 1
    ) %>%
  merge(., capData_2009to2019[, c("animalID", "captureYear", "groupName")], by.x = c("animalID_par", "temp"), by.y = c("animalID", "captureYear"), all.x = T) %>%
  select(-temp) %>%
  
  merge(., capData_2009to2019[, c("animalID", "captureYear", "groupName")], by.x = c("animalID_off", "birthYear_off"), by.y = c("animalID", "captureYear"), all.x = T, suffixes = c("_par", "_off")) %>%
  
  # same groupName?
  mutate(
    groupMatch = groupName_par == groupName_off
  ) %>%
  
  # add parity for F
  merge(., parityAssigments_firstParous[, c("animalID", "parityYear")], by.x = "animalID_par", by.y = "animalID", all.x = T) %>%
  mutate(
    diff_birth.parity = as.numeric(birthYear_off) - as.numeric(parityYear)
  ) %>%
  
  # check birthYears when available
  mutate(
    diff_birthOff.birthPar = as.numeric(birthYear_off) - as.numeric(birthYear_par)
  ) %>%
  
  relocate(parent, offspring, LOD, posterior, animalID_par, animalID_off, sex_par, sex_off, diff_birth.parity, diff_birthOff.birthPar, groupMatch, birthYear_par, parityYear, birthYear_off, groupName_par, groupName_off) %>%
  arrange(offspring, parent) %>%
  # subset to dam/sire with highest posterior for each offspring
  group_by(offspring, sex_par) %>%
  slice_max(posterior) %>%
  ungroup()
```

```{r}
# number of parents assigned to each offspring
temp <- lwed_po_run2 %>%
  group_by(offspring) %>%
  summarise(count = n()) %>%
  as.data.frame() %>%
  mutate(count = str_c("p", count))
table(temp$count)

temp2 <- simp_po_run2 %>%
  group_by(offspring) %>%
  summarise(count = n()) %>%
  as.data.frame() %>%
  mutate(count = str_c("p", count))
table(temp2$count)

# rep skew stuff
lwed_po_run2 %>%
  filter(sex_par == "F") %>%
  group_by(parent) %>%
  summarise(count = n())

lwed_po_run2 %>%
  filter(sex_par == "M") %>%
  group_by(parent) %>%
  summarise(count = n())


simp_po_run2 %>%
  filter(sex_par == "F") %>%
  group_by(parent) %>%
  summarise(count = n())

simp_po_run2 %>%
  filter(sex_par == "M") %>%
  group_by(parent) %>%
  summarise(count = n())
```

#### SIB assignments

```{r}
lwed_sibs_run2 <- read_franzSibs("./DISSERTATION/ch2_demography/02_results/lwed/franz_run2/siblings.txt") %>%
  merge(., twinList[, c("sampleID_franz", "twinSet")], by.x = "sample1", by.y = "sampleID_franz", all.x = T) %>%
  merge(., twinList[, c("sampleID_franz", "twinSet")], by.x = "sample2", by.y = "sampleID_franz", all.x = T, suffixes = c("_1", "_2")) %>%
  mutate(
    twinSetMatch = twinSet_1 == twinSet_2
  ) %>%
  relocate(sample1)


simp_sibs_run2 <- read_franzSibs("./DISSERTATION/ch2_demography/02_results/simp/franz_run2/siblings.txt") %>%
  merge(., twinList[, c("sampleID_franz", "twinSet")], by.x = "sample1", by.y = "sampleID_franz", all.x = T) %>%
  merge(., twinList[, c("sampleID_franz", "twinSet")], by.x = "sample2", by.y = "sampleID_franz", all.x = T, suffixes = c("_1", "_2")) %>%
  mutate(
    twinSetMatch = twinSet_1 == twinSet_2
  ) %>%
  relocate(sample1)
```

# Interbirth intervals

```{r}

```

# Sex-biased dispersal

## Overview

I'm assessing sex-biased dispersal using the sexbias.test from hierfstat, which is based on the test statistics outlined by Goudet et al. 2002

```{r}
library(hierfstat)
```

## Prep data

To do so, first I need to create data subsets for each year of the study, saying who was in what group each year. Since these analyses are for sex-biased dispersal, I'm limiting the data to non-juvs only. 

**LWED**

```{r}
# first find the indivs we need
lwed_popData_perYear_adultsOnly <- get_popData_byYear(
  capData = capData_2009to2019,
  whichSpecies = "LWED",
  whichYears = 2009:2019,
  whichAnimalIDs = "with_hairSamples",
  md_genoData = md,
  birthData = birthData[, c("animalID", "birthDate_est", "birthYear_est")],
  adultsOnly = T)

lwed_popData_perYear_adultsOnly[["2015"]]

# now get the geno data for each subset
## format genos for hierfstat
lwed_genos_hf <- genind2hierfstat(lwed_genind)

## get geno data for adults present in each year
lwed_genos_forHf <- get_genos_perYear_forHierfstat(
  lwed_genos_hf,
  lwed_popData_perYear_adultsOnly,
  sampleRef = sampleRef)
```

**LWED**

```{r}
# first find the indivs we need
simp_popData_perYear_adultsOnly <- get_popData_byYear(
  capData = capData_2009to2019,
  whichSpecies = "SIMP",
  whichYears = 2011:2019,
  whichAnimalIDs = "with_hairSamples",
  md_genoData = md,
  birthData = birthData[, c("animalID", "birthDate_est", "birthYear_est")],
  adultsOnly = T)

simp_popData_perYear_adultsOnly[["2014"]]

# now get the geno data for each subset
## format genos for hierfstat
simp_genos_hf <- genind2hierfstat(simp_genind)

## get geno data for adults present in each year
simp_genos_forHf <- get_genos_perYear_forHierfstat(
  simp_genos_hf,
  simp_popData_perYear_adultsOnly,
  sampleRef = sampleRef)
```

## Create multi_sexbias.test function

Want a function to calculate all test statistics for sexbias.test for each year in study--

mAIc - dispersing sex value should be lower; (-) = F dispersal
vAIc - dispering sex value should be higher; (-) = M dispersal
FST - dispersing sex value should be lower; (-) = F dispersal
FIS - dispersing sex value should be higher; (-) = M dispersal

```{r}
# NOTE that FIS and FST require nperm to be specified
multi_sexbias.test <- function(genoData_list, nperm = NULL, alternative = c("two.sided", "less", "greater")) {
  
  # initialize df
  results <- data.frame(
    year = rep(2009:2019, each = 4),
    test = rep(c("mAIc", "vAIc", "FIS", "FST"), 11),
    statistic = NA,
    p.value = NA
  )
  
  # Initializes the progress bar
  n_iter <- length(genoData_list)
  pb <- txtProgressBar(min = 0,      # Min value of the progress bar
                       max = n_iter, # Max value of the progress bar
                       style = 3,    # pb style (style = 3 gives a moving progress bar)
                       width = 50,   # Width of the progress bar
                       char = "=")   # Character used to create the bar
  
  # Initialize an index for progress tracking
  index <- 0
  
  # run all tests for each year
  for (y in names(genoData_list)) {
    
    # increment index for progress bar
    index <- index + 1
    
    # run each test; use "try" to account for any errors thrown
    maic <- try(sexbias.test(genoData_list[[as.character(y)]]$genoData,
                           genoData_list[[as.character(y)]]$sexData,
                           nperm = nperm,
                           test = "mAIc",
                           alternative = "two.sided"),
                  silent = TRUE)
    
    vaic <- try(sexbias.test(genoData_list[[as.character(y)]]$genoData,
                           genoData_list[[as.character(y)]]$sexData,
                           nperm = nperm,
                           test = "vAIc",
                           alternative = "two.sided"),
                  silent = TRUE)
    
    fis <- try(sexbias.test(genoData_list[[as.character(y)]]$genoData,
                           genoData_list[[as.character(y)]]$sexData,
                           nperm = nperm,
                           test = "FIS",
                           alternative = "two.sided"),
                  silent = TRUE)
    
    fst <- try(sexbias.test(genoData_list[[as.character(y)]]$genoData,
                           genoData_list[[as.character(y)]]$sexData,
                           nperm = nperm,
                           test = "FST",
                           alternative = "two.sided"),
                  silent = TRUE)
    
    # compile results
    if (class(maic) == "try-error") {
      df1 <- data.frame(test = "mAIc",
                        statistic = NA,
                        p.value = NA)
    } else {
      df1 <- data.frame(test = "mAIc",
                        statistic = maic$statistic,
                        p.value = maic$p.value)
    }
    if (class(vaic) == "try-error") {
      df2 <- data.frame(test = "vAIc",
                        statistic = NA,
                        p.value = NA)
    } else {
      df2 <- data.frame(test = "vAIc",
                        statistic = vaic$statistic,
                        p.value = vaic$p.value)
    }
    if (class(fis) == "try-error") {
      df3 <- data.frame(test = "FIS",
                        statistic = NA,
                        p.value = NA)
    } else {
      df3 <- data.frame(test = "FIS",
                        statistic = fis$statistic,
                        p.value = fis$p.value)
    }
    if (class(fst) == "try-error") {
      df4 <- data.frame(test = "FST",
                        statistic = NA,
                        p.value = NA)
    } else {
      df4 <- data.frame(test = "FST",
                        statistic = fst$statistic,
                        p.value = fst$p.value)
    }
    
    compiled <- rbind(df1, df2, df3, df4)
    
    # append data for each "y" to results
    results[results$year == as.numeric(y) & results$test %in% compiled$test, c("statistic", "p.value")] <- 
      compiled[, c("statistic", "p.value")]
    
    # set progress bar to current state
    setTxtProgressBar(pb, index)
  }
  
  close(pb)  # Close the progress bar when done
  
  # indicate whether results suggest F or M dispersal + significance
  results <- results %>%
    mutate(p.value = round(p.value, digits = 6)) %>%
    mutate(
      sexBias = case_when(
        test == "mAIc" & statistic < 0 ~ "F",
        test == "mAIc" & statistic > 0 ~ "M",
        
        test == "vAIc" & statistic > 0 ~ "F",
        test == "vAIc" & statistic < 0 ~ "M",
        
        test == "FIS" & statistic < 0 ~ "F",
        test == "FIS" & statistic > 0 ~ "M",
        
        test == "FST" & statistic > 0 ~ "F",
        test == "FST" & statistic < 0 ~ "M",
        
        .default = NA
      ),
      signif = case_when(
        !is.na(sexBias) & p.value < 0.05 ~ "*",
        .default = NA
        )
    )
  
  return(results)
}
```

## Run test 

Now we can try the hierfstat sexbias.test

```{r}
# lwed
lwed_sexbias.testResults <- multi_sexbias.test(lwed_genos_forHf, nperm = 1000, alternative = "two.sided")

# simp
simp_sexbias.testResults <- multi_sexbias.test(simp_genos_forHf, nperm = 1000, alternative = "two.sided")

lwed_sexbias.testResults
simp_sexbias.testResults
```

## metafor (skip for now)

```{r}
# Example mAIc statistics and p-values for each year
mAIc_values <- c(sexbiasTest.2010$statistic, 
                 sexbiasTest.2012$statistic, 
                 sexbiasTest.2013$statistic,
                 sexbiasTest.2014$statistic,
                 sexbiasTest.2015$statistic,
                 sexbiasTest.2016$statistic,
                 sexbiasTest.2017$statistic,
                 sexbiasTest.2018$statistic,
                 sexbiasTest.2019$statistic)

pvals <- c(sexbiasTest.2010$p.value,
           sexbiasTest.2012$p.value,
           sexbiasTest.2013$p.value,
           sexbiasTest.2014$p.value,
           sexbiasTest.2015$p.value,
           sexbiasTest.2016$p.value,
           sexbiasTest.2017$p.value,
           sexbiasTest.2018$p.value,
           sexbiasTest.2019$p.value)

# Calculate the z-values based on the p-values
z_values <- qnorm(1 - pvals / 2)

# Derive the standard errors
SE_values <- mAIc_values / z_values

# Display the standard errors
SE_values

library(metafor)

# Random-effects model with mAIc statistics and derived SEs
res <- rma(yi = mAIc_values, sei = SE_values, method = "REML")

# View the overall estimate
summary(res)
```

## Tables

**need to make table w/both lwed and simp results**

```{r}
table_genoDispersal <- merge(lwed_sexbias.testResults, simp_sexbias.testResults, by = c("year", "test")) %>%
  mutate_at(vars(starts_with(c("stat", "p."))), ~round(., 2)) %>%
  mutate(sexBias.x = str_c(sexBias.x, signif.x),
         sexBias.y = str_c(sexBias.y, signif.y)) %>%
  select(!starts_with("signif")) %>%
  gt() %>%
  tab_spanner(
    label = "Saddleback tamarins",
    columns = c(statistic.x, p.value.x, sexBias.x)
  ) %>%
  tab_spanner(
    label = "Emperor tamarins",
    columns = c(statistic.y, p.value.y, sexBias.y)
  ) %>%
  sub_missing(columns = everything(),
              rows = everything(),
              missing_text = "---") %>%
  # lwed
  tab_style(
    style = list(cell_fill(color = "#ECD89DFF"),
                 cell_text(weight = "bold")),
    locations = list(cells_body(columns = sexBias.x,
                                rows = str_detect(sexBias.x, "F\\*")))
  ) %>%
  tab_style(
    style = list(cell_fill(color = "#ADB7C0FF"),
                 cell_text(weight = "bold")),
    locations = list(cells_body(columns = sexBias.x,
                                rows = str_detect(sexBias.x, "M\\*")))
  ) %>%
  # simp
  tab_style(
    style = list(cell_fill(color = "#ECD89DFF"),
                 cell_text(weight = "bold")),
    locations = list(cells_body(columns = sexBias.y,
                                rows = str_detect(sexBias.y, "F\\*")))
  ) %>%
  tab_style(
    style = list(cell_fill(color = "#ADB7C0FF"),
                 cell_text(weight = "bold")),
    locations = list(cells_body(columns = sexBias.y,
                                rows = str_detect(sexBias.y, "M\\*")))
  )
  
table_genoDispersal
```

EXPORT

```{r}
table_genoDispersal %>%
  gtsave("./DISSERTATION/ch2_demography/02_results/00_tablesFigures/table_genoDispersal.png")
```



# Plots

Want to make a Cleveland dot plot

```{r}
lwed_clevFig <- presenceMatrix %>%
  filter(species == "LWED") %>%
  mutate(temp = captureYear_last - captureYear_first) %>%
  filter(temp > 0) %>%
  arrange(desc(temp)) %>%
  mutate(animalID = factor(animalID, animalID)) %>%
  ggplot() +
  geom_segment(aes(x = 0,
                   xend = temp,
                   y = animalID,
                   yend = animalID,
                   color = sex)) +
  labs(x = "", y = "") +
  theme_bw() +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
lwed_clevFig
```

# Mark-recapture

**NEED TO REMEMBER** to account for 1) animalID 87 (SIMP) died during
captures in 2012, so should be removed from dataset so as not to biase
survival estimates, and 2) - "marked" package documentation says that
can include field "freq" in capture history, which if negative
represents loss on capture at the final capture occasion. If freq is
missing, a value of 1 is assumed for all records.

## Capture overview

### Capture periods

**By year**

```{r}
# capPeriods_byYear
capStarts_byYear <- capData_2009to2023 %>%
  select(captureYear, captureDate) %>%
  group_by(captureYear) %>%
  slice_min(captureDate) %>%
  ungroup() %>%
  distinct()
capEnds_byYear <- capData_2009to2023 %>%
  select(captureYear, captureDate) %>%
  group_by(captureYear) %>%
  slice_max(captureDate) %>%
  ungroup() %>%
  distinct()

capPeriods_byYear <- merge(capStarts_byYear, capEnds_byYear, by = "captureYear") %>%
  dplyr::rename("capPeriod_start" = "captureDate.x",
                "capPeriod_end" = "captureDate.y") %>%
  # assign capID
  mutate(capID = row_number())
```

**By group**

```{r}
# capPeriods_byGroup
capStarts_byGroup <- capData_2009to2023 %>%
  select(groupName, captureYear, captureDate) %>%
  group_by(groupName, captureYear) %>%
  slice_min(captureDate) %>%
  ungroup() %>%
  distinct()
capEnds_byGroup <- capData_2009to2023 %>%
  select(groupName, captureYear, captureDate) %>%
  group_by(groupName, captureYear) %>%
  slice_max(captureDate) %>%
  ungroup() %>%
  distinct()

capPeriods_byGroup <- merge(capStarts_byGroup, capEnds_byGroup, by = c("groupName", "captureYear")) %>%
  dplyr::rename("capPeriod_start" = "captureDate.x",
                "capPeriod_end" = "captureDate.y") %>%
  filter(groupName != "wui") %>% # dunno what that is
  # assign capID
  group_by(groupName) %>%
  mutate(capID = row_number()) %>%
  ungroup()
```

**by individual**

FROM 2009 TO 2019 ONLY!!

```{r}
length(unique(capData_2009to2019$animalID)) # 247 indivs captured

# capPeriods_byGroup
capStarts_byIndiv <- capData_2009to2019 %>%
  select(animalID, captureDate) %>%
  group_by(animalID) %>%
  slice_min(captureDate) %>%
  ungroup() %>%
  distinct()
capEnds_byIndiv <- capData_2009to2019 %>%
  select(animalID, captureDate) %>%
  group_by(animalID) %>%
  slice_max(captureDate) %>%
  ungroup() %>%
  distinct()

capPeriods_byIndiv <- merge(capStarts_byIndiv, capEnds_byIndiv, by = "animalID") %>%
  dplyr::rename("capPeriod_start" = "captureDate.x",
                "capPeriod_end" = "captureDate.y") %>%
  filter(animalID != "UNK")
```

### Tables

**by group**

Summary of captures for each year (a la Thorley et al. 2023)

```{r}
lwed_capSummary_byGroup <- get_capData_summary(capData_2009to2019, "LWED")

simp_capSummary_byGroup <- get_capData_summary(capData_2009to2019, "SIMP")

lwedSIMP_capSummary_byGroup <- rbind(lwed_capSummary_byGroup, simp_capSummary_byGroup) %>%
  mutate(
    species = case_when(
      species == "LWED" ~ "Saddleback tamarins",
      species == "SIMP" ~ "Emperor tamarins"
    )
  )
```

```{r}
capSummary_table <- lwedSIMP_capSummary_byGroup %>%
  gt(groupname_col = "species",
     rowname_col = "captureYear") %>%
  cols_label(
    captureYear = md("**captureYear**"),
    species = md("**species**"),
    capPeriod_start = md("**periodStart**"),
    capPeriod_end = md("**periodEnd**"),
    capPeriod_days = md("**periodDays**"),
    nGroups = md("**nGroups**"),
    nF = md("**nFemales**"),
    nM = md("**nMales**"),
    nTotal = md("**nTotal**"),
    nRecap = md("**nRecap**"),
    nNew = md("**nNew**"),
    propRecap = md("**propRecap**"),
    propNew = md("**propNew**")
  ) %>%
  fmt(
    columns = everything(),
    rows = 12:13,
    fns = function(x) ifelse(x == "0", "—", NA)
  ) %>%
  sub_missing(columns = everything(),
              rows = 12:13)

capSummary_table %>%
  gtsave("./DISSERTATION/ch2_demography/02_results/00_tablesFigures/table_capSummary.png", vwidth = 1500, vheight = 1000)
```

**by indiv**

```{r}

```

### Plots

Cleveland plot showing capture history for LWED and SIMP social groups
from 2009 to 2019

```{r}
# keep all cap records
capOverview_continuous <- capData_2009to2019 %>%
  select(captureDate, captureYear, species, groupName, animalID) %>%
  distinct()

# only keep one per year
capOverview_discrete <- capData_2009to2019 %>%
  select(captureYear, species, groupName, animalID) %>%
  distinct() %>%
  # add first year captured
  arrange(species, groupName, captureYear) %>%
  group_by(groupName) %>%
  mutate(firstCapture = min(captureYear)) %>%
  ungroup() %>%
  # add number of indv captured each event
  group_by(species, captureYear, groupName, firstCapture) %>%
  summarise(nCaptured = n()) %>%
  # add capID
  group_by(species, groupName) %>%
  mutate(capID = row_number()) %>%
  ungroup() %>%
  arrange(species, groupName) %>%
  # add nextCapture
  group_by(groupName) %>%
  mutate(nextCapture = lead(captureYear)) %>%
  #filter(!is.na(nextCapture)) %>%
  ungroup() %>%
  relocate(species, groupName, firstCapture, captureYear, nextCapture, capID, nCaptured) %>%
  # remove UNK group name & Loners
  filter(!groupName %in% c("UNK", "Loners"))
```

```{r}
ggplot(capOverview_discrete) +
  geom_segment(aes(x = captureYear,
                   xend = nextCapture,
                   y = groupName,
                   yend = groupName,
                   color = as.factor(capID))) +
  geom_point(aes(x = captureYear, y = groupName, color = as.factor(capID), size = nCaptured)) +
  scale_x_continuous(breaks = 2009:2019) +
  facet_grid(rows = vars(species), scales = "free_y") +
  theme_bw()
```

## Model 1: Age-specific survival (CJS)

### capHist

**LWED**

```{r}
# 1) create capHist
m1_lwed_capHist <- capHist_2009to2019 %>%
  filter(species == "LWED") %>%
  select(-species) %>%
  # filter to indivs born during study period
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID") %>%
  # recode any caps prior to normalized birthYear to 0
  mutate(
    temp = birthYear_est - 2009,
    ch = case_when(
      !is.na(temp) ~ `substr<-`(ch, temp, temp, "0"),
      .default = ch
      )
  ) %>%
  # now trim to 2010-2019 (since normalized birthYears start in 2010)
  mutate(ch = str_sub(ch, 2, -1)) %>%
  # remove any all-zero records
  filter(ch != "0000000000") %>%
  # recode grouping vars as factor
  mutate(sex = as.factor(sex)) %>%
  arrange(desc(ch)) %>%
  select(ch, sex)

table(m1_lwed_capHist$sex)
#  F  M 
# 26 44 

# 2) get time intervals b/t sampling periods
m1_lwed_capIntervals <- get_capData_summary(capData_2009to2019, "LWED") %>%
  # only 2010-2019 to account for birthYear start
  filter(captureYear %in% 2010:2019) %>%
  # ditch interval for first year
  mutate(
    capInterval_days = case_when(
      captureYear == min(captureYear) ~ NA,
      .default = capInterval_days
    )
  ) %>%
  select(capInterval_days) %>%
  # normalized interval
  mutate(intNorm = round(capInterval_days / 360, 2)) %>%
  select(intNorm) %>%
  na.omit() %>%
  pull()
m1_lwed_capIntervals
# 0.80 1.20 1.07 0.96 1.03 0.95 1.02 1.04 0.98

# 3) get capDuration for each year
m1_lwed_capDuration <- lwed_capSummary_byGroup %>%
  select(captureYear, capDuration_days)
m1_lwed_capDuration
```

**SIMP**

```{r}
# 1) create capHist
m1_simp_capHist <- capHist_2009to2019 %>%
  filter(species == "SIMP") %>%
  select(-species) %>%
  # filter to indivs born during study period
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID") %>%
  # recode any caps prior to normalized birthYear to 0
  mutate(
    temp = birthYear_est - 2009,
    ch = case_when(
      !is.na(temp) ~ `substr<-`(ch, temp, temp, "0"),
      .default = ch
      )
  ) %>%
  # now trim to 2011-2019 (since normalized birthYears start in 2011)
  mutate(ch = str_sub(ch, 3, -1)) %>%
  # remove any all-zero records
  filter(ch != "000000000") %>%
  # recode grouping vars as factor
  mutate(sex = as.factor(sex)) %>%
  arrange(desc(ch)) %>%
  select(ch, sex)

table(m1_simp_capHist$sex)
#  F  M 
# 26 26 

# 2) get time intervals b/t sampling periods (throws NAs for SIMP just b/c not captured in 2009/2010)
m1_simp_capIntervals <- get_capData_summary(capData_2009to2019, "SIMP") %>%
  # only 2010-2019 to account for birthYear start
  filter(captureYear %in% 2011:2019) %>%
  # ditch interval for first year
  mutate(
    capInterval_days = case_when(
      captureYear == min(captureYear) ~ NA,
      .default = capInterval_days
    )
  ) %>%
  select(capInterval_days) %>%
  # normalized interval
  mutate(intNorm = round(capInterval_days / 360, 2)) %>%
  select(intNorm) %>%
  na.omit() %>%
  pull()
m1_simp_capIntervals
# 1.16 1.09 1.00 1.02 1.02 0.96 1.02 1.03

# 3) get capDuration for each year
m1_simp_capDuration <- simp_capSummary_byGroup %>%
  select(captureYear, capDuration_days) %>%
  filter(captureYear %in% 2011:2019)
m1_simp_capDuration
```

**Quick overview of birth dates vs. years --**

```{r}
birthAssignments %>%
  filter(species == "LWED") %>%
  group_by(birthYear_est) %>%
  summarise(count = n()) %>%
  ggplot(aes(x = as.factor(birthYear_est), y = count)) +
  geom_bar(stat = "identity")

birthAssignments %>%
  filter(species == "SIMP") %>%
  group_by(birthYear_est) %>%
  summarise(count = n()) %>%
  ggplot(aes(x = as.factor(birthYear_est), y = count)) +
  geom_bar(stat = "identity")
```

### GOF tests

#### Background

Following James Paterson blog (mostly..ish)

-   **Test 1** = the omnibus or overall test. Overall, is there evidence
    that animals have equal capture probabilities and equal survival?
    Tells us if there's a problem, but not where (which events) or why
    (which assumption is violated).

-   **Test 2:** Does recapture depend on when an animal was first
    marked? Tests the equal catchability assumption. There are two
    components: Test2.CT and Test2.CL.

    -   **Test 2.CT** tests whether there is a difference in p at t+1
        between those captured and not captured at t when animals are
        known to be alive because they are recaptured later in the
        study. (tests for trap dependence)
    -   **Test2.CL** tests if there is a difference in the expected time
        of next recapture between individuals captured and not captured
        at t when animals are known to be alive.

-   **Test 3:** Does marking affect survival? Tests the equal survival
    assumption. There are two components to Test 3 (Test3.SR and
    Test3.SM).

    -   **Test3.SR:** Does marking affect survival? Do individuals with
        previous marks have different survival rates than first-time
        captures? (tests transience)
    -   **Test3.SM:** For animals seen again, does when they are
        recaptured depend on whether they were marked on or before time
        t?

#### Run tests

Need to run GOF tests with R2ucare - RMark uses the program RELEASE for GOF tests, which is for windows only

**set up packages**

```{r}
library(R2ucare)
```

**Prep data**

Reformat data into matrix for R2ucare + create separate groups for F/M

LWED:
```{r}
# set up matrix for r2ucare
detach("package:RMark", unload=TRUE) # too many conflicting w/marked pckg
library(marked)

m1_lwed.proc <- marked::process.data(
  m1_lwed_capHist,
  model = "CJS",
  begin.time = 2010,
  groups = "sex",
  time.intervals = m1_lwed_capIntervals
  )

m1_lwed.hist <- matrix(as.numeric(unlist(strsplit(as.character(m1_lwed.proc$data$ch), ","))),
                   nrow = length(m1_lwed.proc$data$ch),
                   byrow = T)

m1_lwed.freq <- m1_lwed.proc$data$freq

# split dataset into F/M
m1_lwed.group <- m1_lwed.proc$data$sex
mask <- (m1_lwed.group == 'F')
m1_lwedF.hist <- m1_lwed.hist[mask,]
m1_lwedF.freq <- m1_lwed.freq[mask]
mask <- (m1_lwed.group == 'M')
m1_lwedM.hist <- m1_lwed.hist[mask,]
m1_lwedM.freq <- m1_lwed.freq[mask]

detach("package:marked", unload=TRUE)
library(RMark)
```

SIMP:
```{r}
# set up matrix for r2ucare
detach("package:RMark", unload=TRUE) # too many conflicting w/marked pckg
library(marked)

m1_simp.proc <- marked::process.data(
  m1_simp_capHist,
  model = "CJS",
  begin.time = 2011,
  groups = "sex",
  time.intervals = m1_simp_capIntervals
  )

m1_simp.hist <- matrix(as.numeric(unlist(strsplit(as.character(m1_simp.proc$data$ch), ","))),
                   nrow = length(m1_simp.proc$data$ch),
                   byrow = T)

m1_simp.freq <- m1_simp.proc$data$freq

# split dataset into F/M
m1_simp.group <- m1_simp.proc$data$sex
mask <- (m1_simp.group == 'F')
m1_simpF.hist <- m1_simp.hist[mask,]
m1_simpF.freq <- m1_simp.freq[mask]
mask <- (m1_simp.group == 'M')
m1_simpM.hist <- m1_simp.hist[mask,]
m1_simpM.freq <- m1_simp.freq[mask]

detach("package:marked", unload=TRUE)
library(RMark)
```

**GOF tests**

GOF tests suggest that global model is likely a good fit; proceed to CJS model testing (as per Gimenez et al. 2018 flow chart)
LWED:
```{r}
# test1 - fullset
m1_lwed_test1 <- overall_CJS(m1_lwed.hist, m1_lwed.freq)
m1_lwed_test1 ## p = 0.894 >> fit CJS model

# test1 - by group
m1_lwedF_test1 <- overall_CJS(m1_lwedF.hist, m1_lwedF.freq)
m1_lwedM_test1 <- overall_CJS(m1_lwedM.hist, m1_lwedM.freq)

m1_lwedF_test1 ## p = 0.998 >> fit CJS model
m1_lwedM_test1 ## p = 0.567 >> fit CJS model
```

SIMP:
```{r}
# test1 - fullset
m1_simp_test1 <- overall_CJS(m1_simp.hist, m1_simp.freq)
m1_simp_test1 ## p = 0.96 >> fit CJS model

# test1 - by group
m1_simpF_test1 <- overall_CJS(m1_simpF.hist, m1_simpF.freq)
m1_simpM_test1 <- overall_CJS(m1_simpM.hist, m1_simpM.freq)

m1_simpF_test1 ## p = 1 >> fit CJS model
m1_simpM_test1 ## p = 0.999 >> fit CJS model
```

#### Table 

ignore for now; did this when was trying out GOF tests by sex-group

```{r}
table_m1_lwed_gof <- data.frame(
  chi2 = c(m1_lwedF_test1$chi2, m1_lwedM_test1$chi2),
  df = c(m1_lwedF_test1$degree_of_freedom, m1_lwedM_test1$degree_of_freedom),
  pValue = c(m1_lwedF_test1$p_value, m1_lwedM_test1$p_value)
)
table_m1_lwed_gof

table_m1_lwed_gof %>%
  gt() %>%
  cols_label(
    chi2 = md("**Pearson's Chi2**"),
    df = md("**Degrees of freedom**"),
    pValue = md("**p-value**")
  )
```

### c-hat

**chi2 / df**

C-hat is ~0.61; when c-hat < 1, general practice is to leave it at 1

LWED:
```{r}
# fullset
m1_lwed.chat <- m1_lwed_test1$chi2 / m1_lwed_test1$degree_of_freedom
m1_lwed.chat # 0.5343333

# Overall chat for lwed (male test stat + female test stat) / (male df + female df)
m1_lwedF_tStat <- m1_lwedF_test1$chi2
m1_lwedM_tStat <- m1_lwedM_test1$chi2

m1_lwedF_dF <- m1_lwedF_test1$degree_of_freedom
m1_lwedM_dF <- m1_lwedM_test1$degree_of_freedom

m1_lwed.chat <- (m1_lwedF_tStat + m1_lwedM_tStat) / (m1_lwedF_dF + m1_lwedM_dF)

m1_lwed.chat # 0.5932353
```

SIMP:
```{r}
# fullset
m1_simp.chat <- m1_simp_test1$chi2 / m1_simp_test1$degree_of_freedom
m1_simp.chat # 0.4982778

# Overall chat for simp (male test stat + female test stat) / (male df + female df)
m1_simpF_tStat <- m1_simpF_test1$chi2
m1_simpM_tStat <- m1_simpM_test1$chi2

m1_simpF_dF <- m1_simpF_test1$degree_of_freedom
m1_simpM_dF <- m1_simpM_test1$degree_of_freedom

m1_simp.chat <- (m1_simpF_tStat + m1_simpM_tStat) / (m1_simpF_dF + m1_simpM_dF)

m1_simp.chat # 0.1374286
```

**median c-hat** (nope. I give up on this one.)

```{r}
library(AICcmodavg)

m1.basic_lwed.proc <- process.data(
  m1_lwed_capHist_forMARK,
  model = "CJS",
  begin.time = 2009,
  #groups = c("sex", "ageClass1"),
  time.intervals = m1_lwed_capIntervals
  )

m1.basic_lwed.ddl <- make.design.data(m1.basic_lwed.proc)

m1_lwed.model <- mark(m1.basic_lwed.proc, m1.basic_lwed.ddl,
                      model.parameters = )

# export to mark for other c-hat estimators
m1_lwed_capHist_forMARK <- m1_lwed_capHist %>%
  select(ch)



# if returns NULL, everything worked fine (as per Cooch & White 2024 C-97)
export.MARK(m1_lwed.proc.MARK,
            project.name = "./DISSERTATION/ch2_demography/02_results/01_mark/m1_lwed",
            replace = TRUE)
```

Then in command line--

```{bash}
cd bin

wine mark i=/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/m1_lwed.inp o=/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/m1_lwed_output.txt r=/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/m1_lwed_residuals.txt v=/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/m1_lwed_variance_cov.txt batch nocolor


/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/m1_lwed.inp
```

### RMark

```{r}
detach("package:marked", unload=TRUE)
library(RMark)
```

#### LWED

**Prep data**

```{r}
# 1) create capture histories (already done above)
#m1_lwed_capHist

# 1) process data
m1_lwed.cjs.proc <- process.data(
  m1_lwed_capHist,
  begin.time = 2010,
  model = "CJS",
  groups = "sex",
  time.intervals = m1_lwed_capIntervals
  )

# 2) design data
## 2a) initial design data
m1_lwed.cjs.ddl <- make.design.data(m1_lwed.cjs.proc)

## 2b) add ageClass
library(combinat)
### start subadult at ages (1 year in study):
min(m1_lwed_capIntervals) # 0.8
max(m1_lwed_capIntervals) # 1.2
### end subadult at ages (3 years in study):
subad <- combinat::combn(m1_lwed_capIntervals, m = 3, fun = sum) %>%
  as.data.frame() %>%
  dplyr::rename("combo" = ".") %>%
  arrange(combo)
min(subad$combo) # 2.71
max(subad$combo) # 3.31
### adjust phi in ddl
m1_lwed.cjs.ddl <- add.design.data(m1_lwed.cjs.proc,
                                   m1_lwed.cjs.ddl,
                                   parameter = "Phi",
                                   type = "age",
                                   bins = c(0,0.5,2.7,15),
                                   name = "ageClass")
### adjust p in ddl
m1_lwed.cjs.ddl <- add.design.data(m1_lwed.cjs.proc,
                                   m1_lwed.cjs.ddl,
                                   parameter = "p",
                                   type = "age",
                                   bins = c(0,0.5,2.7,15),
                                   name = "ageClass")

## 2c) add effort covariate
m1_lwed_newTimes <- as.character(unique(c(m1_lwed.cjs.ddl$Phi$time, m1_lwed.cjs.ddl$p$time)))

m1_lwed_covGrps <- data.frame(
  time = m1_lwed_newTimes,
  nGrps = lwed_capSummary_byGroup[lwed_capSummary_byGroup$captureYear %in% 2010:2019, "nGroups"]
)

m1_lwed.cjs.ddl$p <- merge_design.covariates(m1_lwed.cjs.ddl$p,
                                             m1_lwed_covGrps)

m1_lwed.cjs.ddl$Phi
m1_lwed.cjs.ddl$p
```

**Optimal model for p**

```{r}
# 1) build fxn to create models
m1.p_fit.cjs.models <- function(dataProc, dataDesign) {
  
  # Apparent survival (Phi) formula
  Phi.dot <- list(formula=~1) # best model from above
  
  # Detection probability (p) formula
  p.dot <- list(formula=~1) # constant detection
  p.ageClass <- list(formula=~ageClass) # differs across ages
  p.nGrps <- list(formula=~nGrps)
  p.sex <- list(formula=~ageClass) # differs between males and females
  p.time <- list(formula=~time) # differs between discrete times
  
  p.ageClass_nGrps <- list(formula=~ageClass+nGrps)
  p.ageClass_sex <- list(formula=~ageClass+sex)
  p.ageClass_time <- list(formula=~ageClass+time)
  p.nGrps_sex <- list(formula=~nGrps+sex)
  p.nGrps_time <- list(formula=~nGrps+time)
  p.sex_time <- list(formula=~sex+time)
  
  p.ageClass.nGrps <- list(formula=~ageClass*nGrps)
  p.ageClass.sex <- list(formula=~ageClass*sex)
  p.ageClass.time <- list(formula=~ageClass*time)
  p.nGrps.sex <- list(formula=~nGrps*sex)
  p.nGrps.time <- list(formula=~nGrps*time)
  p.sex.time <- list(formula=~sex*time)
  
  # Construct all combinations and put into one model table
  cml <- RMark::create.model.list(c("CJS")) # makes all possible combinations of those parameter formulas
  
  # run & return list of models
  results <- mark.wrapper(cml,
                          data = dataProc,
                          ddl = dataDesign,
                          external = FALSE,
                          accumulate = TRUE,
                          hessian = TRUE)
  
  return(results)
  
}

# run the models
m1.p_lwed.cjs.models <- m1.p_fit.cjs.models(m1_lwed.cjs.proc,
                                            m1_lwed.cjs.ddl)

View(m1.p_lwed.cjs.models$model.table)

# can search output files for things like "numerical convergence suspect"; unsure how to check convergence otherwise, this is all I could find in the package documentation
search.output.files(rmark_m1_lwed.cjs.models, "convergence") # NULL; apparently all converged?
search.output.files(rmark_m1_lwed.cjs.models, "WARNING") # get a number of warnings about "At least a pair of the encounter histories are duplicates" and "Numerical underflow occurred during optimization of this model"
```

**Optimal model for Phi**

```{r}
# 1) build fxn to create models
m1.phi_fit.cjs.models <- function(dataProc, dataDesign) {
  
  # Apparent survival (Phi) formula
  Phi.dot <- list(formula=~1) # constant detection
  Phi.ageClass <- list(formula=~ageClass) # differs across ages
  Phi.nGrps <- list(formula=~nGrps)
  Phi.sex <- list(formula=~ageClass) # differs between males and females
  Phi.time <- list(formula=~time) # differs between discrete times
  
  Phi.ageClass_nGrps <- list(formula=~ageClass+nGrps)
  Phi.ageClass_sex <- list(formula=~ageClass+sex)
  Phi.ageClass_time <- list(formula=~ageClass+time)
  Phi.nGrps_sex <- list(formula=~nGrps+sex)
  Phi.nGrps_time <- list(formula=~nGrps+time)
  Phi.sex_time <- list(formula=~sex+time)
  
  Phi.ageClass.nGrps <- list(formula=~ageClass*nGrps)
  Phi.ageClass.sex <- list(formula=~ageClass*sex)
  Phi.ageClass.time <- list(formula=~ageClass*time)
  Phi.nGrps.sex <- list(formula=~nGrps*sex)
  Phi.nGrps.time <- list(formula=~nGrps*time)
  Phi.sex.time <- list(formula=~sex*time)
  
  # Detection probability (p) formula (based on optimal from above)
  p.nGrps_sex <- list(formula=~nGrps+sex)
  
  # Construct all combinations and put into one model table
  cml <- RMark::create.model.list(c("CJS")) # makes all possible combinations of those parameter formulas
  
  # run & return list of models
  results <- mark.wrapper(cml,
                          data = dataProc,
                          ddl = dataDesign,
                          external = FALSE,
                          accumulate = TRUE,
                          hessian = TRUE)
  
  return(results)
  
}

# run the models
m1.phi_lwed.cjs.models <- m1.phi_fit.cjs.models(m1_lwed.cjs.proc,
                                                m1_lwed.cjs.ddl)

View(m1.phi_lwed.cjs.models$model.table)

# can search output files for things like "numerical convergence suspect"; unsure how to check convergence otherwise, this is all I could find in the package documentation
search.output.files(rmark_m1_lwed.cjs.models, "convergence") # NULL; apparently all converged?
search.output.files(rmark_m1_lwed.cjs.models, "WARNING") # get a number of warnings about "At least a pair of the encounter histories are duplicates" and "Numerical underflow occurred during optimization of this model"
```

#### SIMP

**Prep data**

```{r}
# 1) create capture histories (already done above)
#m1_simp_capHist

# 1) process data
m1_simp.cjs.proc <- process.data(
  m1_simp_capHist,
  begin.time = 2011,
  model = "CJS",
  groups = "sex",
  time.intervals = m1_simp_capIntervals
  )

# 2) design data
## 2a) initial design data
m1_simp.cjs.ddl <- make.design.data(m1_simp.cjs.proc)

## 2b) add ageClass
library(combinat)
### start subadult at ages (1 year in study):
min(m1_simp_capIntervals) # 0.96
max(m1_simp_capIntervals) # 1.16
### end subadult at ages (3 years in study):
subad <- combinat::combn(m1_simp_capIntervals, m = 3, fun = sum) %>%
  as.data.frame() %>%
  dplyr::rename("combo" = ".") %>%
  arrange(combo)
min(subad$combo) # 2.98
max(subad$combo) # 3.28
### adjust phi in ddl (lwed bins should still work here)
m1_simp.cjs.ddl <- add.design.data(m1_simp.cjs.proc,
                                   m1_simp.cjs.ddl,
                                   parameter = "Phi",
                                   type = "age",
                                   bins = c(0,0.5,2.7,15),
                                   name = "ageClass")
### adjust p in ddl (lwed bins should still work here)
m1_simp.cjs.ddl <- add.design.data(m1_simp.cjs.proc,
                                   m1_simp.cjs.ddl,
                                   parameter = "p",
                                   type = "age",
                                   bins = c(0,0.5,2.7,15),
                                   name = "ageClass")

## 2c) add effort covariate
m1_simp_newTimes <- as.character(unique(c(m1_simp.cjs.ddl$Phi$time, m1_simp.cjs.ddl$p$time)))

m1_simp_covGrps <- data.frame(
  time = m1_simp_newTimes,
  nGrps = simp_capSummary_byGroup[simp_capSummary_byGroup$captureYear %in% 2011:2019, "nGroups"]
)

m1_simp.cjs.ddl$p <- merge_design.covariates(m1_simp.cjs.ddl$p,
                                             m1_simp_covGrps)

m1_simp.cjs.ddl$Phi
m1_simp.cjs.ddl$p
```

**Optimal model for p**

```{r}
# function is the same as above for LWED

# run the models
m1.p_simp.cjs.models <- m1.p_fit.cjs.models(m1_simp.cjs.proc,
                                            m1_simp.cjs.ddl)

View(m1.p_simp.cjs.models$model.table)

# can search output files for things like "numerical convergence suspect"; unsure how to check convergence otherwise, this is all I could find in the package documentation
search.output.files(m1.p_simp.cjs.models, "convergence") # NULL; apparently all converged?
search.output.files(m1.p_simp.cjs.models, "WARNING") # get a number of warnings about "At least a pair of the encounter histories are duplicates" and "Numerical underflow occurred during optimization of this model"
```

**Optimal model for Phi**

```{r}
# optimal p for simp same as lwed (p(nGrps + sex)), so can use fxn from above

# run the models
m1.phi_simp.cjs.models <- m1.phi_fit.cjs.models(m1_simp.cjs.proc,
                                                m1_simp.cjs.ddl)

View(m1.phi_simp.cjs.models$model.table)

# can search output files for things like "numerical convergence suspect"; unsure how to check convergence otherwise, this is all I could find in the package documentation
search.output.files(m1.phi_simp.cjs.models, "convergence") # NULL; apparently all converged?
search.output.files(m1.phi_simp.cjs.models, "WARNING") # get a number of warnings about "At least a pair of the encounter histories are duplicates" and "Numerical underflow occurred during optimization of this model"
```

deviance = diff b/t null deviance and model deviance

numerical underflow: "when the result of an arithmetic operation is so small that it cannot be stored in its intended destination format without suffering a rounding error that is larger than usual." (ieee arithmetic)

I don't understand why I'm getting the duplicate error if I set accumulate to TRUE...

"Why not trust the values computed by MARK? The ability of MARK to count the number of parameters correctly is impaired when using design matrices and it will often not count parameters that are estimable but are at a boundary (0 or 1 for 𝜑 or 𝑝) which can happen easily with sparse data sets (the technical details of how MARK counts parameters are presented in Chapter 4). Overly complex models that have numerous parameters that are at boundaries can appear to be the best model because the parameters are counted improperly. It is more conservative to assume that all parameters are estimable." (Cooch & White, C-36)
-- wtf??

#### Tables

**LWED**

```{r}
table_m1_lwed.cjs.models <- m1.phi_lwed.cjs.models$model.table %>%
  select(-Phi, -p, -AICc) %>%
  mutate(rank = row_number(),
         DeltaAICc = round(DeltaAICc, 2),
         weight = round(weight, 2),
         Deviance = round(Deviance, 2)) %>%
  relocate(rank) %>%
  gt() %>%
  cols_label(
    rank = md("**Rank**"),
    model = md("**Model**"),
    npar = md("**K**"),
    DeltaAICc = md("**DeltaAICc**"),
    weight = md("**Weight**"),
    Deviance = md("**Deviance**")
  ) %>%
  cols_align(
    align = "left",
    columns = everything()
  )
table_m1_lwed.cjs.models

table_m1_lwed.cjs.models %>%
  gtsave("./DISSERTATION/ch2_demography/02_results/00_tablesFigures/table_m1_lwed.cjs.models.png", vwidth = 1500, vheight = 1000)
```

**SIMP**

```{r}
table_m1_simp.cjs.models <- m1.phi_simp.cjs.models$model.table %>%
  select(-Phi, -p, -AICc) %>%
  mutate(rank = row_number(),
         DeltaAICc = round(DeltaAICc, 2),
         weight = round(weight, 2),
         Deviance = round(Deviance, 2)) %>%
  relocate(rank) %>%
  gt() %>%
  cols_label(
    rank = md("**Rank**"),
    model = md("**Model**"),
    npar = md("**K**"),
    DeltaAICc = md("**DeltaAICc**"),
    weight = md("**Weight**"),
    Deviance = md("**Deviance**")
  ) %>%
  cols_align(
    align = "left",
    columns = everything()
  )
table_m1_simp.cjs.models

table_m1_simp.cjs.models %>%
  gtsave("./DISSERTATION/ch2_demography/02_results/00_tablesFigures/table_m1_simp.cjs.models.png", vwidth = 1500, vheight = 1000)
```


### c-hat again

blahhh I give up

```{r}
m1_lwed_topMod <- mark(
  m1_lwed.cjs.proc,
  m1_lwed.cjs.ddl,
  model.parameters = list(Phi = list(formula=~sex+time),
                          p = list(formula=~nGrps+sex))
  )

summary(m1_lwed_topMod)

m1_lwed_resid.dev <- m1_lwed_topMod$results$deviance
m1_lwed_resid.df <- m1_lwed_topMod$results$deviance.df

library(AICcmodavg)
m1_lwed_chat1 <- c_hat(???)
```

## Model 2: Dispersal

Following Thorley et al. https://github.com/JThor1990/DMR_GroupSizeEffects/blob/main/R%20scripts/Thorley_GroupsizeeffectsinDMR_v_natalphilopatry.R

### Create input df

Need to create multistate version of capture histories

**NOTE:** animalID 27 started in AR6, went to O.Sky for a couple years, then went back to AR6 -- recode animalID 27's entries for 2017, 2018, and 2019 as "2" (confirmedDispersal)

**Prep ghost records**

Keep to 2 states (1 = confirmed natal group, 2 = dispersed/disappeared/dead) -- I've included statecodes though w/more precision if want to try other states at some point

```{r}
# list of known dispersers
knownDispersers <- capData_2009to2019_first.lastEntry %>%
  filter(groupMatch == "no")

# create "ghost" capture records for indivs immediately following last known capture
m2_capHist_ghostRecords <- capData_2009to2019[, c("animalID", "captureDate", "captureYear", "groupName")] %>%
  # filter to those w/birthYear
  filter(animalID %in% birthAssignments$animalID) %>%
  # extract last known captureDate
  group_by(animalID) %>%
  slice_max(captureDate) %>%
  ungroup() %>%
  # assign group capID for last known capture; use to calculate group capID for ghost year
  merge(capPeriods_byGroup[, c("groupName", "captureYear", "capID")], by = c("groupName", "captureYear"), all.x = T) %>%
  mutate(capID_ghostYear = capID + 1) %>%
  # based on capID for ghost year, assign captureDate_ghostYear (using starting capDate)
  merge(capPeriods_byGroup[, c("groupName", "capID", "capPeriod_start")], by.x = c("groupName", "capID_ghostYear"), by.y = c("groupName", "capID"), all.x = T) %>%
  select(-starts_with("capID")) %>%
  # if group not captured in ghostYear, assign captureDate_ghostYear as start of next capture year's capPeriod
  merge(., capPeriods_byYear[, c("captureYear", "capID")], by = "captureYear") %>%
  mutate(capID_ghostYear = case_when(
    capID == 11 ~ 11,
    .default = capID + 1)) %>%
  # check indivs w/known deathYear_est
  left_join(deathAssignments, by = "animalID") %>%
  mutate(
    capID_ghostYear = case_when(
      captureYear == deathYear_est ~ capID,
      .default = capID_ghostYear
      )
    ) %>%
  # assign captureDate_capYear to ghost year records
  merge(., capPeriods_byYear[, c("capID", "capPeriod_start", "capPeriod_end")], by.x = "capID_ghostYear", by.y = "capID", all.x = T) %>%
  mutate(
    captureDate_capYear = case_when(
      # if indiv has deathYear_est, set to capPeriod_end for that year's cap season
      !is.na(deathYear_est) ~ capPeriod_end,
      # if group last cap is 2019, set to ending date of 2019 cap season
      as.numeric(str_sub(captureDate, 1, 4)) == 2019 ~ capPeriod_end,
      # if group last cap isn't 2019 & not captured the next year, set to starting capture date of next cap season
      is.na(capPeriod_start.x) ~ capPeriod_start.y,
      # if group last cap before 2019 & not captured again til after 2019, set to starting date of 2019 cap season
      as.numeric(str_sub(captureDate, 1, 4)) < 2019 &
        as.numeric(str_sub(capPeriod_start.x, 1, 4)) > 2019 ~ capPeriod_start.y,
      .default = capPeriod_start.x
      ),
    captureDate_capYear = case_when(
      # if captureDate_capYear (ghostYear) == captureDate (last year), add a day to captureDate_capYear
      as.Date(captureDate_capYear) == as.Date(captureDate) ~ as.Date(captureDate_capYear) + 1,
      .default = as.Date(captureDate_capYear)
    ),
    # switch back to character data type
    captureDate_capYear = as.character(captureDate_capYear),
    captureDate = as.character(captureDate)
  ) %>%
  # assign states/statecodes based on last cap date & last group vs. natal group
  mutate(
    statecode = case_when(
      # if has deathYear_est, set to knownDeath
      !is.na(deathYear_est) ~ "knownDeath",
      
      # if ghost capDate is 2019 (last capSeason) but was confirmed dispersed in a prior year, set to rightCensor_priorDispersal
      as.numeric(str_sub(captureDate_capYear, 1, 4)) == 2019 & animalID %in% knownDispersers$animalID ~ "rightCensor_priorDispersal",
      # if ghost capDate is 2019 (last capSeason) & NOT confirmed dispersed in a prior year, set to rightCensor_priorNatal
      as.numeric(str_sub(captureDate_capYear, 1, 4)) == 2019 & !animalID %in% knownDispersers$animalID ~ "rightCensor_priorNatal",
      
      # if ghost capDate < 2019 & confirmed dispersed in a prior year, set to disappeared_priorDispersal
      as.numeric(str_sub(captureDate_capYear, 1, 4)) < 2019 & animalID %in% knownDispersers$animalID ~ "disappeared_priorDispersal",
      # if ghost capDate < 2019 & NOT confirmed dispersed in a prior year, set to disappeared_priorNatal
      as.numeric(str_sub(captureDate_capYear, 1, 4)) < 2019 & !animalID %in% knownDispersers$animalID ~ "disappeared_priorNatal",
      .default = NA
    ),
    state = case_when(
      statecode == "knownDeath" ~ 2,
      statecode == "rightCensor_priorDispersal" ~ 2,
      statecode == "rightCensor_priorNatal" ~ 99,
      statecode == "disappeared_priorDispersal" ~ 2,
      statecode == "disappeared_priorNatal" ~ 2,
      .default = NA
    )
  ) %>%
  select(animalID, captureDate_capYear, statecode, state) %>%
  distinct()
```

**Create full input df**

```{r}
# fullset
m2_capHist <- capData_2009to2019[, c("animalID", "captureDate")] %>%
  dplyr::rename("captureDate_capYear" = "captureDate") %>%
  mutate(statecode = NA,
         state = NA) %>%
  rbind(., m2_capHist_ghostRecords) %>%
  # keep only those w/birthYear_est
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID") %>%
  arrange(animalID, captureDate_capYear) %>%
  # add first captureDates
  merge(., capPeriods_byIndiv[, c("animalID", "capPeriod_start")], by = "animalID") %>%
  dplyr::rename("captureDate_birthYear" = "capPeriod_start") %>%
  # add species/sex info
  merge(., capData_2009to2019[, c("animalID", "species", "sex")],
        by = "animalID",
        all.x = T) %>%
  distinct() %>%
  # add groupName for birthYear
  merge(., capData_2009to2019[, c("animalID", "captureDate", "groupName")],
        by.x = c("animalID", "captureDate_birthYear"),
        by.y = c("animalID", "captureDate"),
        all.x = T) %>%
  # add groupName for capYear
  merge(., capData_2009to2019[, c("animalID", "captureDate", "groupName")],
        by.x = c("animalID", "captureDate_capYear"),
        by.y = c("animalID", "captureDate"),
        all.x = T,
        suffixes = c("_birthYear", "_capYear")) %>%
  # add cap period for that year
  mutate(captureYear = str_sub(captureDate_capYear, 1, 4)) %>%
  merge(., capPeriods_byYear, by = "captureYear", all.x = T) %>%
  # calc times & states
  mutate(
    Time.days = as.numeric(as.Date(captureDate_capYear) - as.Date(captureDate_birthYear)),
    Time.years = Time.days / 365,
    statecode = case_when(
      !is.na(statecode) ~ statecode, # keep statecodes from ghostRecords
      is.na(groupName_capYear) ~ "disappeared",
      groupName_capYear == groupName_birthYear ~ "natalGroup", # still in natal grp
      groupName_capYear != groupName_birthYear ~ "knownDispersal", # confirmed dispersed
      .default = "disappeared" # not seen again; dispersed/disappeared
    ),
    state = case_when(
      !is.na(state) ~ state, # keep states from ghostRecords
      statecode == "natalGroup" ~ 1,
      statecode == "knownDispersal" ~ 2,
      statecode == "disappeared" ~ 2,
      .default = NA
    ),
    # right-censor indivs still in natal group in 2019
    censor = case_when(
      state == 99 ~ 99,
      .default = NA
    )
  ) %>%
  # organize a bit
  select(species, animalID, groupName_capYear, captureDate_capYear, capPeriod_start, capPeriod_end, sex, captureDate_birthYear, censor, Time.days, Time.years, statecode, state) %>%
  dplyr::rename("groupName" = "groupName_capYear",
                "captureDate" = "captureDate_capYear",
                "captureDate_firstCap" = "captureDate_birthYear") %>%
  # recode animalID 27 (returned to natal grp after dispersing)
  mutate(captureYear = str_sub(captureDate, 1, 4)) %>%
  mutate(
    statecode = case_when(
      animalID == 27 & captureYear %in% 2017:2019 ~ "knownDispersal",
      .default = statecode
      ),
    state = case_when(
      animalID == 27 & captureYear %in% 2017:2019 ~ 2,
      .default = state
      )
    ) %>%
  # ensure proper order for indivs captured on last day of last cap season
  arrange(species, sex, animalID, state)

# species subsets
m2_lwed_capHist <- m2_capHist %>%
  filter(species == "LWED") %>%
  select(-species) %>%
  arrange(animalID, captureDate)

m2_simp_capHist <- m2_capHist %>%
  filter(species == "SIMP") %>%
  select(-species) %>%
  arrange(animalID, captureDate)
```

### General metrics

Confirmed dispersal for 8 LWED, 5 SIMP - disappeared/dead for 62 LWED and 47 SIMP; if we only include those captured the immediately prior (so we know the exact year of dispersal), have 7 LWED and 4 SIMP

Don't have a ton to say much about F vs. M for known dispersers, but made a table anyway

```{r}
# confirmed dispersal for 8 LWED, 5 SIMP
capPeriods_byIndiv %>%
  merge(., capData_2009to2019[, c("animalID", "captureDate", "groupName")], by.x = c("animalID", "capPeriod_start"), by.y = c("animalID", "captureDate")) %>%
  merge(., capData_2009to2019[, c("animalID", "captureDate", "groupName", "species")], by.x = c("animalID", "capPeriod_end"), by.y = c("animalID", "captureDate"), suffixes = c("_start", "_end")) %>%
  mutate(groupMatch = groupName_start == groupName_end) %>%
  # adjust for animalID 27 who returned to natal grp after dispersing
  mutate(groupMatch = case_when(
    animalID == 27 ~ FALSE,
    .default = groupMatch
  )) %>%
  relocate(capPeriod_start, .before = capPeriod_end) %>%
  # filter to those in m2_capHist
  filter(animalID %in% m2_capHist$animalID) %>%
  group_by(species, groupMatch) %>%
  summarise(count = n()) %>%
  as.data.frame()

# at what age are known dispersers in their new group?
m2_knownDispersers <- m2_capHist %>%
  filter(statecode == "knownDispersal") %>%
  select(species, animalID, sex, captureDate_firstCap, captureDate, captureYear, Time.days, Time.years) %>%
  group_by(animalID) %>%
  slice_min(as.numeric(Time.days)) %>%
  ungroup() %>%
  arrange(species, sex) %>%
  # filter to those captured in year prior
  mutate(
    captured_yearPrior = case_when(
      str_c(animalID, as.numeric(captureYear)-1) %in% str_c(capData_2009to2019$animalID, capData_2009to2019$captureYear) ~ T,
      .default = F
    )
  ) %>%
  filter(captured_yearPrior == T)

table_m2_knownDispersers <- m2_knownDispersers %>%
  group_by(species, sex) %>%
  summarise(
    n = n(),
    mean_TSM = round(mean(Time.years), 2),
    min_TSM = round(min(Time.years), 2),
    max_TSM = round(max(Time.years), 2)
  ) %>%
  as.data.frame() %>%
  gt()
table_m2_knownDispersers

gtsave(table_m2_knownDispersers, "./DISSERTATION/ch2_demography/02_results/00_tablesFigures/table_m2_knownDispersers.png", vwidth = 1500, vheight = 1000)
```

```{r}
m2_lwed_capHist %>%
  select(animalID, statecode) %>%
  distinct() %>%
  group_by(statecode) %>%
  summarise(
    count = unique(n())
  )

70-8-3 # 59 disappeared for unknown reasons (either died or dispersed to a non-study group)
```

### Model

statecodes include:
-   disappeared_priorDispersal
-   disappeared_priorNatal
-   knownDeath
-   knownDispersal
-   natalGroup
-   rightCensor_priorDispersal
-   rightCensor_priorNatal

**LWED**

```{r}
#detach("package:msmtools", unload=TRUE)
library(msm)
#devtools::install_github("contefranz/msmtools")
#library(msmtools) # can't get it to work properly

lwed_philopatry.df <- m2_lwed_capHist

table(lwed_philopatry.df$statecode)

statetable.msm(state = state,
               subject = animalID,
               data = lwed_philopatry.df)

summary(lwed_philopatry.df$Time.years)

# set up the q matrix for the transitions (assume that individuals can transition from non-breeder to gone or known out of group)
lwed_philopatry.q <- rbind(c(0, 0.5),
                           c(0, 0)) # assuming ~1 year in state 1 before disappearing
# ^^ gives same results for 1 & 0.5, suggesting that it's the true max-likelihood estimate

lwed_philopatry.df$sex <- as.factor(lwed_philopatry.df$sex)

rownames(lwed_philopatry.q) <- colnames(lwed_philopatry.q) <- c("State 1", "State 2")

lwed_philopatry.msm <- msm(state ~ Time.years,
                      subject = animalID,
                      censor = 99,
                      censor.states = c(1,2), # could be either natal or disappeared/dispersed 
                      covariates = ~ sex,
                      data = lwed_philopatry.df,
                      qmatrix = lwed_philopatry.q,
                      na.action = na.fail, 
                      control = list(fnscale = 4000, maxit = 10000))
lwed_philopatry.msm
summary(lwed_philopatry.msm)
hazard.msm(lwed_philopatry.msm) # n.s.
```

On hazard ratios: https://chjackson.github.io/msm/msmcourse/covariates.html#interpretation-of-the-hazard-ratio

Hazard ratios represent how the instantaneous risk of making a particular transition is modified by the covariate. 

Interpretation of hazard analysis (for transition from State 1 to State 2):
-   HR (hazard ratio): for indiv with factor sexM, risk of transitioning from State 1 to State 2 is 82% of the hazard for sexF
-   L (lower 95% CI): lower bound of 95% CI for hazard is 0.43; i.e., true hazard could be as low as 44% of the baseline
-   U (upper 95% CI): uppper bound of 95% CI is 1.56; i.e., true hazard ratio could be as high as 156% (1.56x) the baseline hazard

--    Since hazard ratio (0.82) < 1, suggests that males have a lower risk of transitioning from State 1 to State 2 vs. females (i.e., lower likelihood of dispersal)
--    CI 0.43 to 1.56 crosses 1, meaning effect is not statistically significant since can't confidently say that hazard ratio differs from 1
--    since result is not significant, can't conclude that sex has a clear effect on transition b/t these states

**SIMP**

```{r}
simp_philopatry.df <- m2_simp_capHist

table(simp_philopatry.df$statecode)

statetable.msm(state = state,
               subject = animalID,
               data = simp_philopatry.df)

summary(simp_philopatry.df$Time.years)

# set up the q matrix for the transitions (assume that individuals can transition from non-breeder to gone or known out of group)
simp_philopatry.q <- rbind(c(0, 0.5),
                           c(0, 0)) # assuming ~1 year in state 1 before disappearing
# ^^ gives same results for 1 & 0.5, suggesting that it's the true max-likelihood estimate

simp_philopatry.df$sex <- as.factor(simp_philopatry.df$sex)

rownames(simp_philopatry.q) <- colnames(simp_philopatry.q) <- c("State 1", "State 2")

simp_philopatry.msm <- msm(state ~ Time.years,
                      subject = animalID,
                      censor = 99,
                      censor.states = c(1,2), # could be either natal or disappeared/dispersed 
                      covariates = ~ sex,
                      data = simp_philopatry.df,
                      qmatrix = simp_philopatry.q,
                      na.action = na.fail, 
                      control = list(fnscale = 4000, maxit = 10000))
simp_philopatry.msm
summary(simp_philopatry.msm)
hazard.msm(simp_philopatry.msm) # n.s. (barely though)
```

--    Since hazard ratio (2.22) > 1, suggests that males have a HIGHER risk of transitioning from State 1 to State 2 vs. females (i.e., HIGHER likelihood of dispersal)
--    CI 0.984 to 5.01 crosses 1, meaning effect is not statistically significant since can't confidently say that hazard ratio differs from 1
--    since result is not significant, can't conclude that sex has a clear effect on transition b/t these states

### Plots

#### General plots

**1) Overall results**

```{r}
par(mfrow = c(1,1))
plot.survfit.msm(lwed_philopatry.msm, from = 1, las = 1) # overall
```

**2) Sex-specific results**

Plus-signs = right-censored records

**NOTE** that these plots fit a different curve (red) for each sex, but maintain the general empirical data (blue lines/points). As such, we'll need to extract this separately for females and males from above and combine the plots together (see below)

```{r}
# LWED
par(mfrow = c(1,2))
lwed_survdat.females <- plot.survfit.msm(lwed_philopatry.msm, from = 1, las = 1,
                                         covariates = list(sex = "F"),
                                         interp = "midpoint",
                                         range = c(0,5),
                                         survdata = TRUE) # set survdata to TRUE to get Kaplan Meier survdat dataframe
lwed_survdat.males <- plot.survfit.msm(lwed_philopatry.msm, from = 1, las = 1,
                                       covariates = list(sex = "M"),
                                       interp = "midpoint",
                                       range = c(0,5),
                                       survdata = TRUE) # set survdata to TRUE to get Kaplan Meier survdat dataframe

# SIMP
simp_survdat.females <- plot.survfit.msm(simp_philopatry.msm, from = 1, las = 1,
                                         covariates = list(sex = "F"),
                                         interp = "midpoint",
                                         range = c(0,8),
                                         survdata = TRUE) # set survdata to TRUE to get Kaplan Meier survdat dataframe
simp_survdat.males <- plot.survfit.msm(simp_philopatry.msm, from = 1, las = 1,
                                       covariates = list(sex = "M"),
                                       interp = "midpoint",
                                       range = c(0,8),
                                       survdata = TRUE) # set survdata to TRUE to get Kaplan Meier survdat dataframe
```

#### Prevalence plots

**LWED**

We can view the overall prevalence results in the plot below:

```{r}
# get the prevalences to compare Females to Males
plot.prevalence.msm(
  lwed_philopatry.msm,
  xlab = "Time since first captured, years")
```

To get sex-specific prevalence data, need to run sex-specific prevalence function:

**NOTE** that to obtain sex-specific observed prevalences, we need to provide a vector of the subject identifiers to "subset"

```{r}
# create subject list to specify basis for obs values
m2_female_subjectList <- m2_lwed_capHist %>%
  filter(sex == "F") %>% select(animalID) %>%
  pull()
m2_male_subjectList <- m2_lwed_capHist %>%
  filter(sex == "M") %>% select(animalID) %>%
  pull()

# run prevalence fxn
philopatry.prevalence.msm.females <- msm:::prevalence.msm(
  philopatry.msm,
  ci = "normal",
  subset = m2_female_subjectList,
  covariates = list(sex = "F"))
philopatry.prevalence.msm.males <- msm:::prevalence.msm(
  philopatry.msm,
  ci = "normal",
  subset = m2_male_subjectList,
  covariates = list(sex = "M"))
```

Then reformat results to prep for plotting --

```{r}
#  females - keep values for State.1 only (for natal group prevalence)
femalephilopatry.observed <- philopatry.prevalence.msm.females$`Observed percentages` %>%
  data.frame() %>%
  set_names(c("obsPrevalence", "State.2")) %>% select(-State.2)
femalephilopatry.expected.estimates <- philopatry.prevalence.msm.females$`Expected percentages`$estimates %>%
  data.frame() %>%
  set_names(c("expPrevalence", "State.2")) %>% select(-State.2)
femalephilopatry.expected.lci <- philopatry.prevalence.msm.females$`Expected percentages`$ci[,,1] %>% 
  data.frame() %>%
  set_names(c("l95ci", "State.2")) %>% select(-State.2)
femalephilopatry.expected.uci <- philopatry.prevalence.msm.females$`Expected percentages`$ci[,,2]%>% 
  data.frame() %>%
  set_names(c("u95ci", "State.2")) %>% select(-State.2)

femalephilopatry_forPlot <- cbind(femalephilopatry.observed,
                                  femalephilopatry.expected.estimates,
                                  femalephilopatry.expected.lci, # 95% lci
                                  femalephilopatry.expected.uci) %>% # 95% uci
  rownames_to_column("Time")
  
#  males - keep values for State.1 only (for natal group prevalence)
malephilopatry.observed <- philopatry.prevalence.msm.males$`Observed percentages` %>%
  data.frame() %>%
  set_names(c("obsPrevalence", "State.2")) %>% select(-State.2)
malephilopatry.expected.estimates <- philopatry.prevalence.msm.males$`Expected percentages`$estimates %>%
  data.frame() %>%
  set_names(c("expPrevalence", "State.2")) %>% select(-State.2)
malephilopatry.expected.lci <- philopatry.prevalence.msm.males$`Expected percentages`$ci[,,1] %>% 
  data.frame() %>%
  set_names(c("l95ci", "State.2")) %>% select(-State.2)
malephilopatry.expected.uci <- philopatry.prevalence.msm.males$`Expected percentages`$ci[,,2]%>% 
  data.frame() %>%
  set_names(c("u95ci", "State.2")) %>% select(-State.2)

malephilopatry_forPlot <- cbind(malephilopatry.observed,
                                malephilopatry.expected.estimates,
                                malephilopatry.expected.lci, # 95% lci
                                malephilopatry.expected.uci) %>% # 95% uci
  rownames_to_column("Time") # 95% uci
```

Now we can make the plot (saved as m2_natalPhilopatry.png):

```{r}
# --> plots, predicted philopatry of males and females with CI
par(mfrow = c(1,1))
plot(expectedprevalence ~ Time, data = subset(femalephilopatry.expected, state == "ingroup"), type = "n", las = 1, bty = "l", ylab= "Probability of presence in natal group (%)", xlab = 'Time since first captured (years)', ylim = c(0, 101), xlim = c(0, 8))
# 95% CI polygons
with(femalephilopatry_forPlot, 
     polygon(c(Time, rev(Time)), c(l95ci, rev(u95ci)), 
             col = adjustcolor("#1F9E89FF", alpha = 0.2), border = NA))
with(malephilopatry_forPlot, 
     polygon(c(Time, rev(Time)), c(l95ci, rev(u95ci)), 
             col = adjustcolor("black", alpha = 0.1), border = NA))
# expected values
points(expPrevalence ~ Time, 
       data = femalephilopatry_forPlot, type = "l", col = "#1F9E89FF", lwd = 2)
points(expPrevalence ~ Time, 
       data = malephilopatry_forPlot, type = "l", col = "black", lwd = 2)

# observed data... but need the Kaplan Meier empirical data
#points(obsPrevalence ~ Time, data = femalephilopatry_forPlot, type = "l", col = "#1F9E89FF", lty = 2, lwd = 0.5) # observed
#points(obsPrevalence ~ Time, data = malephilopatry_forPlot, type = "l", col = "black", lty = 2, lwd = 0.5) # observed

axis(1, at = seq(0, 8, 0.5), labels = NA)
axis(2, at = seq(0, 100, 10), labels = NA)
legend("topright", legend = c("Female", "Male"), lwd = c(2,2), bty = "n", col = c("#1F9E89FF", "black"))
```

**SIMP**

```{r}
# get the prevalences to compare Females to Males
plot.prevalence.msm(
  simp_philopatry.msm,
  xlab = "Time since first captured, years")
```

To get sex-specific prevalence data, need to run sex-specific prevalence function:

**NOTE** that to obtain sex-specific observed prevalences, we need to provide a vector of the subject identifiers to "subset"

```{r}
# create subject list to specify basis for obs values
m2_simpF_subjectList <- m2_simp_capHist %>%
  filter(sex == "F") %>% select(animalID) %>%
  pull()
m2_simpM_subjectList <- m2_simp_capHist %>%
  filter(sex == "M") %>% select(animalID) %>%
  pull()

# run prevalence fxn
philopatry.prevalence.msm.simpF <- msm:::prevalence.msm(
  simp_philopatry.msm,
  ci = "normal",
  subset = m2_simpF_subjectList,
  covariates = list(sex = "F"))
philopatry.prevalence.msm.simpM <- msm:::prevalence.msm(
  simp_philopatry.msm,
  ci = "normal",
  subset = m2_simpM_subjectList,
  covariates = list(sex = "M"))
```

Then reformat results to prep for plotting --

```{r}
#  females - keep values for State.1 only (for natal group prevalence)
simpF.philopatry.observed <- philopatry.prevalence.msm.simpF$`Observed percentages` %>%
  data.frame() %>%
  set_names(c("obsPrevalence", "State.2")) %>% select(-State.2)
simpF.philopatry.expected.estimates <- philopatry.prevalence.msm.simpF$`Expected percentages`$estimates %>%
  data.frame() %>%
  set_names(c("expPrevalence", "State.2")) %>% select(-State.2)
simpF.philopatry.expected.lci <- philopatry.prevalence.msm.simpF$`Expected percentages`$ci[,,1] %>% 
  data.frame() %>%
  set_names(c("l95ci", "State.2")) %>% select(-State.2)
simpF.philopatry.expected.uci <- philopatry.prevalence.msm.simpF$`Expected percentages`$ci[,,2]%>% 
  data.frame() %>%
  set_names(c("u95ci", "State.2")) %>% select(-State.2)

simpF.philopatry_forPlot <- cbind(simpF.philopatry.observed,
                                  simpF.philopatry.expected.estimates,
                                  simpF.philopatry.expected.lci, # 95% lci
                                  simpF.philopatry.expected.uci) %>% # 95% uci
  rownames_to_column("Time")
  
#  males - keep values for State.1 only (for natal group prevalence)
simpM.philopatry.observed <- philopatry.prevalence.msm.simpM$`Observed percentages` %>%
  data.frame() %>%
  set_names(c("obsPrevalence", "State.2")) %>% select(-State.2)
simpM.philopatry.expected.estimates <- philopatry.prevalence.msm.simpM$`Expected percentages`$estimates %>%
  data.frame() %>%
  set_names(c("expPrevalence", "State.2")) %>% select(-State.2)
simpM.philopatry.expected.lci <- philopatry.prevalence.msm.simpM$`Expected percentages`$ci[,,1] %>% 
  data.frame() %>%
  set_names(c("l95ci", "State.2")) %>% select(-State.2)
simpM.philopatry.expected.uci <- philopatry.prevalence.msm.simpM$`Expected percentages`$ci[,,2]%>% 
  data.frame() %>%
  set_names(c("u95ci", "State.2")) %>% select(-State.2)

simpM.philopatry_forPlot <- cbind(simpM.philopatry.observed,
                                simpM.philopatry.expected.estimates,
                                simpM.philopatry.expected.lci, # 95% lci
                                simpM.philopatry.expected.uci) %>% # 95% uci
  rownames_to_column("Time") # 95% uci
```

Now we can make the plot (saved as m2_natalPhilopatry.png):

```{r}
# --> plots, predicted philopatry of males and females with CI
par(mfrow = c(1,1))
plot(expPrevalence ~ Time, data = simpF.philopatry_forPlot, type = "n", las = 1, bty = "l", ylab= "Probability of presence in natal group (%)", xlab = 'Time since first captured (years)', ylim = c(0, 101), xlim = c(0, 8))
# 95% CI polygons
with(simpF.philopatry_forPlot, 
     polygon(c(Time, rev(Time)), c(l95ci, rev(u95ci)), 
             col = adjustcolor("#1F9E89FF", alpha = 0.2), border = NA))
with(simpM.philopatry_forPlot, 
     polygon(c(Time, rev(Time)), c(l95ci, rev(u95ci)), 
             col = adjustcolor("black", alpha = 0.1), border = NA))
# expected values
points(expPrevalence ~ Time, 
       data = simpF.philopatry_forPlot, type = "l", col = "#1F9E89FF", lwd = 2)
points(expPrevalence ~ Time, 
       data = simpM.philopatry_forPlot, type = "l", col = "black", lwd = 2)

# observed data... but need the Kaplan Meier empirical data
#points(obsPrevalence ~ Time, data = femalephilopatry_forPlot, type = "l", col = "#1F9E89FF", lty = 2, lwd = 0.5) # observed
#points(obsPrevalence ~ Time, data = malephilopatry_forPlot, type = "l", col = "black", lty = 2, lwd = 0.5) # observed

axis(1, at = seq(0, 8, 0.5), labels = NA)
axis(2, at = seq(0, 100, 10), labels = NA)
legend("topright", legend = c("Female", "Male"), lwd = c(2,2), bty = "n", col = c("#1F9E89FF", "black"))
```

### Mean sojourn times for females/males in natal groups

The mean sojourn time in a state "r" is the expected length of one period spent in that state.

https://chjackson.github.io/msm/msmcourse/outputs.html#mean-sojourn-time

**LWED**

```{r}
# mean sojourn times for males and females in their natal group
sojourn.msm(lwed_philopatry.msm, covariates = list(sex = "F"))

sojourn.msm(lwed_philopatry.msm, covariates = list(sex = "M"))

# avg age at capture (based on Mini diss info)
birthData %>%
  filter(species == "LWED") %>%
  select(age_watsaDiss_months) %>%
  na.omit() %>%
  summarise(
    avgAge_years = mean(age_watsaDiss_months/12),
    n = n(),
    minAge_months = min(age_watsaDiss_months),
    maxAge_months = max(age_watsaDiss_months)
  )
```

**LWED**

```{r}
# mean sojourn times for males and females in their natal group
sojourn.msm(simp_philopatry.msm, covariates = list(sex = "F"))

sojourn.msm(simp_philopatry.msm, covariates = list(sex = "M"))

# avg age at capture (based on Mini diss info)
birthData %>%
  filter(species == "LWED") %>%
  select(age_watsaDiss_months) %>%
  na.omit() %>%
  summarise(
    avgAge_years = mean(age_watsaDiss_months/12),
    n = n(),
    minAge_months = min(age_watsaDiss_months),
    maxAge_months = max(age_watsaDiss_months)
  )
```

## Model 3: Abundance








# XXXXXXXXXXXXXXXX

# SCRAPS

## SambaR

```{r}
source("/home/rachelvoyt/programs/SambaR-master/SAMBAR_v1.10.txt")
getpackages(mylib = "/home/rachelvoyt/R/x86_64-pc-linux-gnu-library/4.4")
conflicted::conflicts_prefer(base::`%in%`)

devtools::install_github("pievos101/PopGenome")

install.packages("PopGenome")


# Install the necessary Bioconductor packages
install.packages("devtools")
install.packages("BiocManager")
BiocManager::install("SNPRelate")

# Install dartRverse (dartRverse) & core (dartR.base, dartR.data)
install.packages("dartRverse")
library(dartRverse)
dartRverse::dartRverse_install()
library(dartR)

temp2 <- gi2gl(lwed_gen) # supply genind
```

```{r}
lwed_genos <- read.table("./05_tamRun5/03_run5GTscore/fullSet_polyGenResults_singleSNP_0x.txt", header = T, na.strings = "0") %>%
  # subset to lwed hair
  select(md[md$species == "LWED" & md$sampleType == "hair", "sampleID"]) %>%
  # reformat loci & subset to indid only
  `rownames<-`(sub('[_][^_]+$', '', rownames(.))) %>%
  filter(!str_detect(rownames(.), "SEXID|SPECIESID|SIMP")) %>%
  # filter to samples w/decent geno success
  #select(where(~sum(!is.na(.x))/length(.x) >= 0.7)) %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column("sampleID")

lwed_genind <- adegenet::df2genind(X = lwed_genos[,c(2:155)],
                                sep = ",",
                                ind.names = lwed_genos$sampleID,
                                NA.char = "NA",
                                ploidy = 2,
                                type = "codom")

lwed_genlight <- gi2gl(lwed_genind)
setwd("./DISSERTATION/ch2_demography/02_results/")

lwed_sambar <- genlight2sambar(genlight_object = "lwed_genlight", do_confirm = T, major = lwed_genlight$other[[1]], minor = lwed_genlight$other[[2]])

head(snps,5)
```

## COLONY

```{r}
devtools::install_github("jonesor/rcolony")
library(rcolony)

build.colony.input(wd = getwd(), )
```

# STRUCTURE

```{r}
devtools::install_github("nicholasjclark/STRUCTURE.popgen")
```

# msmtools plot attempt

trying to get msmtools survplot to work so I can plot observed + expected values on the same plot but it's throwing a bunch of errors and I give up.

```{r}
test <- philopatry.msm
str(test$data$mf)

test$data$mf$`(subject)` <- as.numeric(test$data$mf$`(subject)`)

survplot(x = test,
         from = 1,
         to = NULL,
         range = c(0,5),
         covariates = list(sex = "F"),
         exacttimes = T,
         km = F, # only works if this is set to F
         out = "none",
         ci = "normal",
         interp = "midpoint",
         ci_km = "none")

dat = as.data.table(test$data$mf[, c("(subject)", "(time)", 
      "(state)")])
setnames(dat, c("subject", "time", "state"))

plot.survfit.msm(philopatry.msm, from = 1, las = 1,
                 covariates = list(sex = "F"),
                 interp = "midpoint",
                 range = c(0,5))
```
