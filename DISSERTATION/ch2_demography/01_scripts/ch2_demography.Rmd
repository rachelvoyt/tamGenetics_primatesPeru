---
title: "tamGenetics_demography"
author: "Rachel Voyt"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1 Overview

This Rmd file contains the analyses used in the demography chapter of my
dissertation. Data used is from tamRun5, hair samples only.

# 2 Packages

```{r}
library(janitor)
library(tidyverse)

# for my custom functions
source("project_scripts/ravo_gtScripts.R")
source("./project_scripts/ravo_ch2Scripts.R")
```

# 3 Data

## 3.1 Capture data

Capture data includes all records of individual captures from 2009-2019.

Use the latest version of capData_byIndiv (from
tamGenetics_paper3_dataOrganization), then 1) filter to first capture
for each animalID 2) filter again to animalIDs in tamRun5

**note** exclude those in capData w/"UNK" animalID; did a lot of digging
in ch2_dataOrganization.Rmd and most likely these entries need to be
ditched

```{r}
capData <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/captureData_byIndividual_v6.csv") %>%
  mutate(
    captureYear = str_sub(captureDate, 1, 4),
    captureYear = as.numeric(captureYear)
  ) %>%
  relocate(captureYear, .after = captureDate)
  # adjust rowID 1 ageClass to "UNK" >> keep as adult for now
  #mutate(
  #  ageClass = case_when(
  #    rowID == 1 ~ "UNK",
  #    .default = ageClass
  #  )
  #)

capData_2009to2019 <- capData %>%
  filter(rowID <= 613)

capData_firstEntry <- capData[match(unique(capData$animalID), capData$animalID),] %>%
  select(rowID, captureDate, captureYear, animalID, ageClass, ageClass_classifier, animalName1, animalName2, groupName, species, sex, notes_MD, notes_RV) %>%
  # remove UNK animalID
  filter(animalID != "UNK")

capData_2009to2019_firstEntry <- capData_firstEntry %>%
  filter(rowID <= 613)
```

## 3.2 Birth/death data

```{r}
birthData <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/birthAssignments_capData_tamRun5_v3.csv") %>%
  # edit for animalID 90 ageClass recode to juvenile
  mutate(
    age_capData = case_when(
      animalID == 90 ~ "juvenile",
      .default = age_capData
    ),
    birthYear_est = case_when(
      animalID == 90 ~ 2010,
      .default = birthYear_est
    )
  )

birthAssignments <- birthData %>%
  select(animalID, birthYear_est, species) %>%
  na.omit() %>%
  distinct() %>%
  arrange(animalID)

deathData <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/deathAssignments_capData_tamRun5_v1.csv")

deathAssignments <- deathData %>%
  select(animalID, deathYear_est) %>%
  na.omit() %>%
  distinct() %>%
  arrange(animalID)
```

## 3.3 Capture histories

Filtered to 2009-2019 only

```{r}
capHist_2009to2023 <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/captureHistories_byIndiv_2009to2023.csv", colClasses = "character")

capHist_2009to2019 <- capHist_2009to2023 %>%
  # filter to 2009-2019 only
  mutate(ch = str_sub(ch, 1, 11)) %>%
  filter(ch != "00000000000")
```

## 3.4 Genetic data

Latest version of md_tamRun5 (from metadataReconciliation.Rmd file);
hair samples only

```{r}
# latest updated version of md_tamRun5 from metadataReconciliation.Rmd
md <- read.csv("./metadataReconciliation/tamRun5_metadata_v5.csv") %>%
  mutate(captureYear = str_sub(captureDate, 1, 4)) %>%
  relocate(captureYear, .after = captureDate)

sampleRef <- read.csv("./project_data/master_sampleInfo.csv")

lociRef <- read.csv("./project_data/master_lociInfo.csv")
```

# 4 Pop/grp overview

## 4.1 General numbers

I just did juveniles vs. non-juveniles here rather than looking at
subadult/adult distinctions -- mostly bc I think the adults vs. subadult
designations are a touch iffy, plus there are some indivs with NA for
ageClass

From 2009-2019:

  species ageClass   F   M Total
1    LWED juvenile  26  44    70
2    LWED   nonJuv  42  33    75
3    SIMP juvenile  26  27    53
4    SIMP   nonJuv  22  27    49
5   Total        - 116 131   247

  species nGroups
1    LWED      15
2    SIMP       9

```{r}
# all indivs captured from 2009 to 2019 by ageClass at first capture:
capData_2009to2019_firstEntry %>%
  mutate(ageClass = case_when(
    is.na(ageClass) ~ "nonJuv",
    ageClass != "juvenile" ~ "nonJuv",
    .default = ageClass
    )) %>%
  group_by(species, ageClass, sex) %>%
  summarise(count = n()) %>%
  pivot_wider(names_from = sex,
              values_from = count) %>%
  adorn_totals() %>%
  mutate(Total = F + M) %>%
  as.data.frame()

# number of groups:
capData_2009to2019_firstEntry %>%
  # remove groupName for lone indivs
  filter(groupName != "Loners") %>%
  group_by(species) %>%
  summarise(nGroups = n_distinct(groupName)) %>%
  as.data.frame()
```

### Group size

I think I need the capData_byGroup info here...

```{r}
temp <- capData_byIndiv %>%
  mutate(
    captureYear = str_sub(captureDate, 1, 4)
  ) %>%
  relocate(captureYear, .after = captureDate) %>%
  select(animalID, species, sex, captureYear, groupName) %>%
  distinct() %>%
  group_by(groupName, captureYear) %>%
  summarise(
    count = n()
  )
```

# 5 Mark-recapture models

**NEED TO REMEMBER** to account for 1) animalID 87 (SIMP) died during
captures in 2012, so should be removed from dataset so as not to biase
survival estimates, and 2) - "marked" package documentation says that
can include field "freq" in capture history, which if negative
represents loss on capture at the final capture occasion. If freq is
missing, a value of 1 is assumed for all records.

## Model 1: Age-specific survival (CJS)

### Data

```{r}
# 1) create capHist
m1_lwed_capHist <- capHist_2009to2019 %>%
  filter(species == "LWED") %>%
  select(-species) %>%
  # filter to indivs born during study period
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID") %>%
  # recode any caps prior to normalized birthYear to 0
  mutate(
    temp = birthYear_est - 2009,
    ch = case_when(
      !is.na(temp) ~ `substr<-`(ch, temp, temp, "0"),
      .default = ch
      )
  ) %>%
  # now trim to 2010-2019 (since normalized birthYears start in 2010)
  mutate(ch = str_sub(ch, 2, -1)) %>%
  # remove any all-zero records
  filter(ch != "0000000000") %>%
  # recode grouping vars as factor
  mutate(sex = as.factor(sex)) %>%
  arrange(desc(ch)) %>%
  select(ch, sex)

table(m1_lwed_capHist$sex)
#  F  M 
# 26 44 

# 2) get time intervals b/t sampling periods
m1_lwed_capIntervals <- get_capData_summary(capData_2009to2019, "LWED") %>%
  # only 2010-2019 to account for birthYear start
  filter(captureYear %in% 2010:2019) %>%
  # ditch interval for first year
  mutate(
    capInterval_days = case_when(
      captureYear == min(captureYear) ~ NA,
      .default = capInterval_days
    )
  ) %>%
  select(capInterval_days) %>%
  # normalized interval
  mutate(intNorm = round(capInterval_days / 360, 2)) %>%
  select(intNorm) %>%
  na.omit() %>%
  pull()
m1_lwed_capIntervals
# 0.80 1.20 1.07 0.96 1.03 0.95 1.02 1.04 0.98

# 3) get capDuration for each year
m1_lwed_capDuration <- lwed_capSummary_byGroup %>%
  select(captureYear, capDuration_days)
m1_lwed_capDuration
```

Quick overview of birth dates vs. years --

```{r}
birthAssignments %>%
  filter(species == "LWED") %>%
  group_by(birthYear_est) %>%
  summarise(count = n()) %>%
  ggplot(aes(x = as.factor(birthYear_est), y = count)) +
  geom_bar(stat = "identity")
```

### GOF tests

#### Background

Following James Paterson blog (mostly..ish)

-   **Test 1** = the omnibus or overall test. Overall, is there evidence
    that animals have equal capture probabilities and equal survival?
    Tells us if there's a problem, but not where (which events) or why
    (which assumption is violated).

-   **Test 2:** Does recapture depend on when an animal was first
    marked? Tests the equal catchability assumption. There are two
    components: Test2.CT and Test2.CL.

    -   **Test 2.CT** tests whether there is a difference in p at t+1
        between those captured and not captured at t when animals are
        known to be alive because they are recaptured later in the
        study. (tests for trap dependence)
    -   **Test2.CL** tests if there is a difference in the expected time
        of next recapture between individuals captured and not captured
        at t when animals are known to be alive.

-   **Test 3:** Does marking affect survival? Tests the equal survival
    assumption. There are two components to Test 3 (Test3.SR and
    Test3.SM).

    -   **Test3.SR:** Does marking affect survival? Do individuals with
        previous marks have different survival rates than first-time
        captures? (tests transience)
    -   **Test3.SM:** For animals seen again, does when they are
        recaptured depend on whether they were marked on or before time
        t?

#### Run tests

Need to run GOF tests with R2ucare - RMark uses the program RELEASE for GOF tests, which is for windows only

**Prep data**

Reformat data into matrix for R2ucare + create separate groups for F/M

```{r}
library(R2ucare)

# set up matrix for r2ucare
detach("package:RMark", unload=TRUE)
library(marked)
m1_lwed.proc <- marked::process.data(
  m1_lwed_capHist,
  model = "CJS",
  begin.time = 2010,
  groups = "sex",
  time.intervals = m1_lwed_capIntervals
  )

m1_lwed.hist <- matrix(as.numeric(unlist(strsplit(as.character(m1_lwed.proc$data$ch), ","))),
                   nrow = length(m1_lwed.proc$data$ch),
                   byrow = T)

m1_lwed.freq <- m1_lwed.proc$data$freq

# split dataset into F/M
m1_lwed.group <- m1_lwed.proc$data$sex
mask <- (m1_lwed.group == 'F')
m1_lwedF.hist <- m1_lwed.hist[mask,]
m1_lwedF.freq <- m1_lwed.freq[mask]
mask <- (m1_lwed.group == 'M')
m1_lwedM.hist <- m1_lwed.hist[mask,]
m1_lwedM.freq <- m1_lwed.freq[mask]

detach("package:marked", unload=TRUE)
library(RMark)
```

**GOF tests**

GOF tests suggest that global model is likely a good fit; proceed to CJS model testing (as per Gimenez et al. 2018 flow chart)

```{r}
# test1 - fullset
m1_lwed_test1 <- overall_CJS(m1_lwed.hist, m1_lwed.freq)
m1_lwed_test1 ## p = 0.894 >> fit CJS model

# test1 - by group
m1_lwedF_test1 <- overall_CJS(m1_lwedF.hist, m1_lwedF.freq)
m1_lwedM_test1 <- overall_CJS(m1_lwedM.hist, m1_lwedM.freq)

m1_lwedF_test1 ## p = 0.998 >> fit CJS model
m1_lwedM_test1 ## p = 0.567 >> fit CJS model
```

#### Table 

ignore for now; did this when was trying out GOF tests by sex-group

```{r}
table_m1_lwed_gof <- data.frame(
  chi2 = c(m1_lwedF_test1$chi2, m1_lwedM_test1$chi2),
  df = c(m1_lwedF_test1$degree_of_freedom, m1_lwedM_test1$degree_of_freedom),
  pValue = c(m1_lwedF_test1$p_value, m1_lwedM_test1$p_value)
)

table_m1_lwed_gof %>%
  gt() %>%
  cols_label(
    chi2 = md("**Pearson's Chi2**"),
    df = md("**Degrees of freedom**"),
    pValue = md("**p-value**")
  )
```

### c-hat

**chi2 / df**

C-hat is ~0.61; when c-hat < 1, general practice is to leave it at 1

```{r}
# fullset
m1_lwed.chat <- m1_lwed_test1$chi2 / m1_lwed_test1$degree_of_freedom
m1_lwed.chat # 0.5343333

# Overall chat for lwed (male test stat + female test stat) / (male df + female df)
m1_lwedF_tStat <- m1_lwedF_test1$chi2
m1_lwedM_tStat <- m1_lwedM_test1$chi2

m1_lwedF_dF <- m1_lwedF_test1$degree_of_freedom
m1_lwedM_dF <- m1_lwedM_test1$degree_of_freedom

m1_lwed.chat <- (m1_lwedF_tStat + m1_lwedM_tStat) / (m1_lwedF_dF + m1_lwedM_dF)

m1_lwed.chat # 0.5932353
```

**median c-hat**

```{r}
library(AICcmodavg)

m1.basic_lwed.proc <- process.data(
  m1_lwed_capHist_forMARK,
  model = "CJS",
  begin.time = 2009,
  #groups = c("sex", "ageClass1"),
  time.intervals = m1_lwed_capIntervals
  )

m1.basic_lwed.ddl <- make.design.data(m1.basic_lwed.proc)

m1_lwed.model <- mark(m1.basic_lwed.proc, m1.basic_lwed.ddl,
                      model.parameters = )

# export to mark for other c-hat estimators
m1_lwed_capHist_forMARK <- m1_lwed_capHist %>%
  select(ch)



# if returns NULL, everything worked fine (as per Cooch & White 2024 C-97)
export.MARK(m1_lwed.proc.MARK,
            project.name = "./DISSERTATION/ch2_demography/02_results/01_mark/m1_lwed",
            replace = TRUE)
```

Then in command line--

```{bash}
cd bin

wine mark i=/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/m1_lwed.inp o=/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/m1_lwed_output.txt r=/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/m1_lwed_residuals.txt v=/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/m1_lwed_variance_cov.txt batch nocolor


/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/DISSERTATION/ch2_demography/02_results/m1_lwed.inp
```

### RMark

**Prep data**

```{r}
#detach("package:marked", unload=TRUE)
library(RMark)

# 1) create capture histories (already done above)
m1_lwed_capHist

# 1) process data
m1_lwed.cjs.proc <- process.data(
  m1_lwed_capHist,
  begin.time = 2010,
  model = "CJS",
  groups = "sex",
  time.intervals = m1_lwed_capIntervals
  )

# 2) design data
m1_lwed.cjs.ddl <- make.design.data(rmark_m1_lwed.cjs.proc)

## add ageClass
library(combinat)
# start subadult at ages (1 year in study):
min(m1_lwed_capIntervals) # 0.8
max(m1_lwed_capIntervals) # 1.2
# end subadult at ages (3 years in study):
subad <- combn(m1_lwed_capIntervals, m = 3, fun = sum) %>%
  as.data.frame() %>%
  dplyr::rename("combo" = ".") %>%
  arrange(combo)
min(subad$combo) # 2.71
max(subad$combo) # 3.31

m1_lwed.cjs.ddl <- add.design.data(rmark_m1_lwed.cjs.proc,
                                   m1_lwed.cjs.ddl,
                                   parameter = "Phi",
                                   type = "age",
                                   bins = c(0,0.5,2.7,15),
                                   name = "ageClass")
m1_lwed.cjs.ddl <- add.design.data(rmark_m1_lwed.cjs.proc,
                                   m1_lwed.cjs.ddl,
                                   parameter = "p",
                                   type = "age",
                                   bins = c(0,0.5,2.7,15),
                                   name = "ageClass")

## add effort covariate
newTimes <- as.character(unique(c(rmark_m1_lwed.cjs.ddl$Phi$time, rmark_m1_lwed.cjs.ddl$p$time)))

m1_lwed_covGrps <- data.frame(
  time = newTimes,
  nGrps = lwed_capSummary_byGroup[lwed_capSummary_byGroup$captureYear %in% 2010:2019, "nGroups"]
)

m1_lwed.cjs.ddl$p <- merge_design.covariates(rmark_m1_lwed.cjs.ddl$p,
                                             m1_lwed_covGrps)

m1_lwed.cjs.ddl$Phi
m1_lwed.cjs.ddl$p
```

**Optimal model for p**

```{r}
# 1) build fxn to create models
m1.p_fit.cjs.models <- function(dataProc, dataDesign) {
  
  # Apparent survival (Phi) formula
  Phi.dot <- list(formula=~1) # best model from above
  
  # Detection probability (p) formula
  p.dot <- list(formula=~1) # constant detection
  p.ageClass <- list(formula=~ageClass) # differs across ages
  p.nGrps <- list(formula=~nGrps)
  p.sex <- list(formula=~ageClass) # differs between males and females
  p.time <- list(formula=~time) # differs between discrete times
  
  p.ageClass_nGrps <- list(formula=~ageClass+nGrps)
  p.ageClass_sex <- list(formula=~ageClass+sex)
  p.ageClass_time <- list(formula=~ageClass+time)
  p.nGrps_sex <- list(formula=~nGrps+sex)
  p.nGrps_time <- list(formula=~nGrps+time)
  p.sex_time <- list(formula=~sex+time)
  
  p.ageClass.nGrps <- list(formula=~ageClass*nGrps)
  p.ageClass.sex <- list(formula=~ageClass*sex)
  p.ageClass.time <- list(formula=~ageClass*time)
  p.nGrps.sex <- list(formula=~nGrps*sex)
  p.nGrps.time <- list(formula=~nGrps*time)
  p.sex.time <- list(formula=~sex*time)
  
  # Construct all combinations and put into one model table
  cml <- RMark::create.model.list(c("CJS")) # makes all possible combinations of those parameter formulas
  
  # run & return list of models
  results <- mark.wrapper(cml,
                          data = dataProc,
                          ddl = dataDesign,
                          external = FALSE,
                          accumulate = TRUE,
                          hessian = TRUE)
  
  return(results)
  
}

# run the models
m1.p_lwed.cjs.models <- m1.p_fit.cjs.models(m1_lwed.cjs.proc,
                                            m1_lwed.cjs.ddl)

View(m1.p_lwed.cjs.models$model.table)

# can search output files for things like "numerical convergence suspect"; unsure how to check convergence otherwise, this is all I could find in the package documentation
search.output.files(rmark_m1_lwed.cjs.models, "convergence") # NULL; apparently all converged?
search.output.files(rmark_m1_lwed.cjs.models, "WARNING") # get a number of warnings about "At least a pair of the encounter histories are duplicates" and "Numerical underflow occurred during optimization of this model"
```

```{r}
# 1) build fxn to create models
m1.phi_fit.cjs.models <- function(dataProc, dataDesign) {
  
  # Apparent survival (Phi) formula
  Phi.dot <- list(formula=~1) # constant detection
  Phi.ageClass <- list(formula=~ageClass) # differs across ages
  Phi.nGrps <- list(formula=~nGrps)
  Phi.sex <- list(formula=~ageClass) # differs between males and females
  Phi.time <- list(formula=~time) # differs between discrete times
  
  Phi.ageClass_nGrps <- list(formula=~ageClass+nGrps)
  Phi.ageClass_sex <- list(formula=~ageClass+sex)
  Phi.ageClass_time <- list(formula=~ageClass+time)
  Phi.nGrps_sex <- list(formula=~nGrps+sex)
  Phi.nGrps_time <- list(formula=~nGrps+time)
  Phi.sex_time <- list(formula=~sex+time)
  
  Phi.ageClass.nGrps <- list(formula=~ageClass*nGrps)
  Phi.ageClass.sex <- list(formula=~ageClass*sex)
  Phi.ageClass.time <- list(formula=~ageClass*time)
  Phi.nGrps.sex <- list(formula=~nGrps*sex)
  Phi.nGrps.time <- list(formula=~nGrps*time)
  Phi.sex.time <- list(formula=~sex*time)
  
  # Detection probability (p) formula
  p.nGrps_sex <- list(formula=~nGrps+sex)
  
  # Construct all combinations and put into one model table
  cml <- RMark::create.model.list(c("CJS")) # makes all possible combinations of those parameter formulas
  
  # run & return list of models
  results <- mark.wrapper(cml,
                          data = dataProc,
                          ddl = dataDesign,
                          external = FALSE,
                          accumulate = TRUE,
                          hessian = TRUE)
  
  return(results)
  
}

# run the models
m1.phi_lwed.cjs.models <- m1.phi_fit.cjs.models(m1_lwed.cjs.proc,
                                                m1_lwed.cjs.ddl)

View(m1.phi_lwed.cjs.models$model.table)

# can search output files for things like "numerical convergence suspect"; unsure how to check convergence otherwise, this is all I could find in the package documentation
search.output.files(rmark_m1_lwed.cjs.models, "convergence") # NULL; apparently all converged?
search.output.files(rmark_m1_lwed.cjs.models, "WARNING") # get a number of warnings about "At least a pair of the encounter histories are duplicates" and "Numerical underflow occurred during optimization of this model"
```

deviance = diff b/t null deviance and model deviance

numerical underflow: "when the result of an arithmetic operation is so small that it cannot be stored in its intended destination format without suffering a rounding error that is larger than usual." (ieee arithmetic)

I don't understand why I'm getting the duplicate error if I set accumulate to TRUE...

"Why not trust the values computed by MARK? The ability of MARK to count the number of parameters correctly is impaired when using design matrices and it will often not count parameters that are estimable but are at a boundary (0 or 1 for ðœ‘ or ð‘) which can happen easily with sparse data sets (the technical details of how MARK counts parameters are presented in Chapter 4). Overly complex models that have numerous parameters that are at boundaries can appear to be the best model because the parameters are counted improperly. It is more conservative to assume that all parameters are estimable." (Cooch & White, C-36)
-- wtf??

#### Table

```{r}
table_m1_lwed.cjs.models <- m1.phi_lwed.cjs.models$model.table %>%
  select(-Phi, -p, -AICc) %>%
  mutate(rank = row_number(),
         DeltaAICc = round(DeltaAICc, 2),
         weight = round(weight, 2),
         Deviance = round(Deviance, 2)) %>%
  relocate(rank) %>%
  gt() %>%
  cols_label(
    rank = md("**Rank**"),
    model = md("**Model**"),
    npar = md("**K**"),
    DeltaAICc = md("**DeltaAICc**"),
    weight = md("**Weight**"),
    Deviance = md("**Deviance**")
  ) %>%
  cols_align(
    align = "left",
    columns = everything()
  )
table_m1_lwed.cjs.models

table_m1_lwed.cjs.models %>%
  gtsave("./DISSERTATION/ch2_demography/02_results/00_tablesFigures/table_m1_lwed.cjs.models.png", vwidth = 1500, vheight = 1000)
```

### c-hat again

blahhh I give up

```{r}
m1_lwed_topMod <- mark(
  m1_lwed.cjs.proc,
  m1_lwed.cjs.ddl,
  model.parameters = list(Phi = list(formula=~sex+time),
                          p = list(formula=~nGrps+sex))
  )

summary(m1_lwed_topMod)

m1_lwed_resid.dev <- m1_lwed_topMod$results$deviance
m1_lwed_resid.df <- m1_lwed_topMod$results$deviance.df

library(AICcmodavg)
m1_lwed_chat1 <- c_hat(???)
```


# XXXX

### marked

Note that CJS default fields include cohort, age, time which are factor variables and Cohort, Age, and Time which are numeric versions of the same fields. The values of these can be altered by values of begin.time, time.intervals and initial.ages set in the call to process.data. 

```{r}
# 1) create capHist (created in GOF tests above)
View(m1_lwed_capHist)

# 2) process data
m1_lwed.cjs.proc <- process.data(data = m1_lwed_capHist,
                                 begin.time = 2010,
                                 model = "CJS",
                                 groups = "sex",
                                 time.intervals = m1_lwed_capIntervals,
                                 accumulate = FALSE)

# 3) make design data
m1_lwed.cjs.ddl <- make.design.data(m1_lwed.cjs.proc)

## add ageClass
#m1_lwed.cjs.ddl$Phi$ageClass <- cut(m1_lwed.cjs.ddl$Phi$Age, breaks = c(0, 0.7, 2, 15), labels = c("Juvenile", "Subadult", "Adult"), right = FALSE)
#m1_lwed.cjs.ddl$p$ageClass <- cut(m1_lwed.cjs.ddl$p$Age, breaks = c(0, 0.8, 1, 15), labels = c("Juvenile", "Subadult", "Adult"), right = FALSE)

m1_lwed.cjs.ddl$Phi
m1_lwed.cjs.ddl$p

# 4) define multi-model fxn
m1_fit.cjs.models <- function(dataProc, dataDesign) {
  
  # Apparent survival (Phi) formula
  Phi.age.sex <- list(formula=~age*sex) # "*" includes main effects + intxn (like other linear models)
  Phi.age.time <- list(formula=~age*time) 
  Phi.sex.time <- list(formula=~sex*time)
  
  Phi.age_sex <- list(formula=~age+sex)
  Phi.age_time <- list(formula=~age+time) 
  Phi.sex_time <- list(formula=~sex+time)
  
  Phi.age <- list(formula=~age) # differs across ages
  Phi.sex <- list(formula=~sex) # differs between males and females
  Phi.time <- list(formula=~time) # differs between discrete times
  Phi.dot <- list(formula=~1) # constant survival
  
  # Detection probability (p) formula
  p.age.sex <- list(formula=~age*sex)
  p.age.time <- list(formula=~age*time)
  p.sex.time <- list(formula=~sex*time)
  
  p.age_sex <- list(formula=~age+sex)
  p.age_time <- list(formula=~age+time)
  p.sex_time <- list(formula=~sex+time)
  
  p.age <- list(formula=~age)
  p.sex <- list(formula=~sex)  # differs between males and females
  p.time <- list(formula=~time)  # one discrete estimate of p per capture event
  p.dot <- list(formula=~1) # constant detection
  
  # Construct all combinations and put into one model table
  cml <- create.model.list(c("Phi","p")) # makes all possible combinations of those parameter formulas
  
  results <- crm.wrapper(cml,
                         data = dataProc,
                         ddl = dataDesign,
                         external = FALSE,
                         accumulate = FALSE,
                         hessian = TRUE)
  
  return(results)
}

# 5) test models
m1_lwed.cjs.models <- m1_fit.cjs.models(m1_lwed.cjs.proc, m1_lwed.cjs.ddl)
View(m1_lwed.cjs.models$model.table)
```

**Adjust for small sample size?**

Burnham and Anderson suggest correcting for small sample size when n/K < 40, where n = sample size and K = number of fitted parameters (including intercept); the ALSO say that you may as well just use the AICc since it becomes equal to AIC at large n anyway - so -- yes.

```{r}
# making my own aicc function for ease of use
get_AICc <- function(aic, k, n) {
  # Check if the sample size is large enough to calculate AICc
  if (n > k + 1) {
    # AICc formula
    aicc <- aic + (2 * k * (k + 1)) / (n - k - 1)
  } else {
    # Return NA if AICc cannot be computed (to avoid division by zero or negative numbers)
    aicc <- NA
    warning("Sample size too small to calculate AICc.")
  }
  return(aicc)
}

m1_lwed.cjs.models_aicc <- m1_lwed.cjs.models

m1_lwed.cjs.models_aicc$model.table <- m1_lwed.cjs.models$model.table %>%
  rowwise() %>%
  mutate(
    AICc = get_AICc(aic = AIC, n = nrow(m1_lwed_capHist), k = npar)
  ) %>%
  ungroup() %>%  # ungroup so calcs aren't done row-wise for DeltaAICc
  mutate(
    DeltaAICc = round(AICc - min(AICc, na.rm = TRUE), 2)  # DeltaAICc = diff from the min AICc
  ) %>%
  # recalculate model weight
  mutate(
    weight_c = exp(-0.5 * DeltaAICc) / sum(exp(-0.5 * DeltaAICc), na.rm = TRUE),
    weight_c = round(weight_c, 2)
  ) %>%
  arrange(AICc) %>%
  mutate(
    rank = row_number()
  ) %>%
  relocate(rank)

View(m1_lwed.cjs.models_aicc$model.table)
```

### Table

```{r}
table_m1_lwed.cjs.models_aicc <- m1_lwed.cjs.models_aicc$model.table %>%
  select(rank, model, npar, DeltaAICc, weight_c, neg2lnl) %>%
  filter(as.numeric(rank) <= 5) %>%
  gt() %>%
  cols_label(
    rank = md("**Rank**"),
    model = md("**Model**"),
    npar = md("**K**"),
    DeltaAICc = md("**DeltaAICc**"),
    weight_c = md("**Weight**"),
    neg2lnl = md("**Deviance**")
  ) %>%
  cols_align(
    align = "left",
    columns = everything()
  )
table_m1_lwed.cjs.models_aicc

table_m1_lwed.cjs.models_aicc %>%
  gtsave("./DISSERTATION/ch2_demography/02_results/00_tablesFigures/table_m1_lwed.cjs.models_aicc.png", vwidth = 1500, vheight = 1000)
```

### Model averaging

The top two models are very similar with regard to AICc and weight_c, suggesting that it might be worthwhile to average them. 



```{r}
head(m1_lwed.cjs.models_aicc$model.table)

library(AICcmodavg)

# Create a list of your candidate models (replace with actual model objects)
modList <- list(m1 = m1_lwed.cjs.models_aicc$Phi.dot.p.sex_time,
                    m2 = m1_lwed.cjs.models_aicc$Phi.sex.p.sex_time)

# Create a vector of model names
modNames <- c("Phi(~1)p(~sex + time)", "Phi(~sex)p(~sex + time)")

# Create a dataframe with the AICc and weights (using your table above)
aicc_table <- m1_lwed.cjs.models_aicc$model.table %>%
  filter(model %in% modNames) %>%
  select(model, AICc, weight_c)

# Perform model averaging for a specific parameter (e.g., survival)
modavg_result <- modavg(cand.set = modList,
                        parm = "Phi",
                        modnames = modNames)

# View the model-averaged estimates
print(modavg_result)


# Example assuming `m1_lwed.cjs.models` holds your model results
# You may need to adjust based on the structure of your models

# Extract AICc values
model_AICc <- sapply(m1_lwed.cjs.models, function(x) x$results$AICc)

# Extract number of parameters
npar <- sapply(m1_lwed.cjs.models, function(x) x$results$npar)

# Extract the model formula (just for tracking purposes)
model_formulas <- sapply(m1_lwed.cjs.models, function(x) x$model$formula)

# Compile into a dataframe for easier manipulation
model_info <- data.frame(
  model = model_formulas,
  AICc = model_AICc,
  npar = npar
)

```

### Plots

```{r}
m1_lwed.cjs.models_aicc$model.table[1,]

m1_lwed_topModel <- m1_lwed.cjs.models_aicc$Phi.dot.p.sex_time

m1_lwed_pred <- predict(m1_lwed_topModel,
                        ddl = m1_lwed.cjs.ddl,
                        se = T)

m1_lwed_pred$Phi
m1_lwed_pred$p


m1_lwed_pred$Phi %>%
  mutate(
    year = case_when(
      time == 2010 ~ 2010,
      time == 2010.8 ~ 2011,
      time == 2012 ~ 2012,
      time == 2013.07 ~ 2013,
      time == 2014.03 ~ 2014,
      time == 2015.06 ~ 2015,
      time == 2016.01 ~ 2016,
      time == 2017.03 ~ 2017,
      time == 2018.07 ~ 2018
    )
  ) %>%
  ggplot(aes(x = as.factor(year), y = estimate, group = sex, color = sex)) +
  geom_point(size = 3, position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = ucl, ymax = lcl), width = 0.1, position = position_dodge(width = 0.5)) +
  coord_cartesian(ylim = c(0,1)) +
  scale_y_continuous(breaks = seq(0,1, by=0.1)) +
  theme_Publication() +
  scale_colour_Publication() +
  theme(legend.position = c(0.01, 0.97),
        legend.justification = "left") +
  labs(title = "Saddleback tamarin survival estimates by year",
       x = "Year",
       y = "Survival probability (phi)")
```





### 1) capHist

```{r}


simp_capHist <- capHist_2009to2019 %>%
  filter(species == "SIMP") %>%
  select(-species) %>%
  merge(., capData_2009to2019[, c("animalID", "groupName", "ageClass", "captureYear")], by = "animalID", all.x = T) %>%
  relocate(animalID, ch, groupName, ageClass, sex, captureYear) %>%
  arrange(as.numeric(animalID), captureYear) %>%
  distinct() %>%
#  mutate(
#    freq = case_when(
#      animalID == "87" ~ (-1),
#      .default = 1
#    )
#  ) %>%
#  relocate(freq, .after = ch) %>%
  # groups must be coded as factors
  ## for making factor levels easier bc I can't figure it out otherwise
  ## also going to bin all non-juv (adults+subAd) together
  mutate(
    ageClass = case_when(
      ageClass == "juvenile" ~ "age1_juv",
      .default = "age2_nonJuv"
    )
  ) %>%
  mutate_at(c("groupName", "ageClass", "sex"), as.factor)
```


### Process data

Prior to analyzing the data, this function initializes several variables
(e.g., number of capture occa- sions, time intervals) that are often
specific to the capture-recapture model being fitted to the data. It
also is used to 1) define groups in the data that represent different
levels of one or morestrata.labels factor covariates (e.g., sex), 2)
define time intervals between capture occasions (if not 1), and 3)
create an age structure for the data, if any.

```{r}
detach("package:RMark", unload=TRUE)

# process.data (must include groups)
lwed.cjs.proc <- lwed_capHist %>%
  select(ch, ageClass, sex) %>%
  process.data(data = .,
               model = "CJS",
               groups = "ageClass",
               age.var = 1,
               initial.ages = c(0,3),
               accumulate = F)

lwed.cjs.ddl <- make.design.data(lwed.cjs.proc)
lwed.cjs.ddl$Phi$ya <- cut(lwed.cjs.ddl$Phi$Age, c(0,1,11), right=FALSE, labels = c("juv","adult"))

# create phony age data
data(dipper)
dipper$ahy <- "Adult"
dipper$ahy[1:100] = "HY"
dipper$ahy=factor(dipper$ahy)

#process data assigning initial ages
dp=process.data(dipper,groups="ahy",initial.age=c(1,0),age.var=1,accumulate=FALSE)
# make design data
ddl=make.design.data(dp)
# create 0, 1+ age variable
ddl$Phi$ya = cut(ddl$Phi$Age, c(0,1,10), right=FALSE, labels = c("HY","AHY"))
# fit model
model=crm(dp,ddl,model.parameters=list(Phi=list(formula=~ya)))
# append design data to design matrix to show model
xx=cbind(ddl$Phi,as.matrix(model$results$model_data$Phi.dm))
head(xx)
tail(xx)
```

### Define multi-model function

\*\*probably don't actually need to include group w/phi (apparent
survival) b/c phi is usually modeled on factors that might directly
impact an indiv's survival prob b/t cap events -- unless I think that
diff groups impact indiv survival, it's not really needed

group IS likely to affect capture probability though

but could include group in both phi and p if grp membership changes
frequently or has biological relevance to survival

```{r}
# fxn to fit multiple models
fit.cjs.models <- function(dataProc, dataDesign) {
  
  # Apparent survival (Phi) formula
  Phi.age.sex.time <- list(formula=~ageClass*sex*time) # Just like in other linear models "*" includes main effects and an interaction
  Phi.age <- list(formula=~ageClass)
  Phi.sex <- list(formula=~sex) # differs between males and females
  Phi.time <- list(formula=~time) # differs between discrete times
  Phi.dot <- list(formula=~1) # constant survival
  
  # Detection probability (p) formula
  #p.grp <- list(formula=~groupName)
  p.age <- list(formula=~ageClass)
  p.sex <- list(formula=~sex)  # differs between males and females
  p.time <- list(formula=~time)  # one discrete estimate of p per capture event
  p.dot <- list(formula=~1) # constant detection
  
  # Construct all combinations and put into one model table
  cml <- create.model.list(c("Phi","p")) # makes all possible combinations of those parameter formulas
  
  results <- crm.wrapper(cml,
                         data = dataProc,
                         ddl = dataDesign,
                         external = FALSE,
                         accumulate = FALSE,
                         hessian = TRUE)
  
  return(results)
}
```

### Run function

```{r}
lwed.cjs.models <- fit.cjs.models(lwed.cjs.proc, lwed.cjs.ddl)

lwed.cjs.model.table <- lwed.cjs.models$model.table

predict(lwed.cjs.models[[1]])

#######
### saving the groupName version that I did b/c it took forever to run--
#lwed.cjs.models_groupNames <- lwed.cjs.models

lwed.cjs.model.table_groupNames <- lwed.cjs.models_groupNames$model.table

predict(lwed.cjs.models_groupNames[[1]])
```

\$Phi ageClass occ estimate se lcl ucl
1 age2_nonJuv 5 0.8474592 0.01196096 0.8225121 0.8694564
2 age1_juv 1 0.6860579 0.04197180 0.5986411 0.7620046

\$p ageClass occ estimate se lcl ucl
1 age2_nonJuv 6 0.8574406 0.01383736 0.8281138 0.8824739
2 age1_juv 2 0.8087834 0.05218191 0.6858513 0.8912384

Prob of offspring surviving b/t capture events = 0.69; prob of catching
offspring during cap event = 0.81



## GOF tests

The R2ucare package can test the CJS assumptions of equal catchability
and equal survival using Tests 1, 2, and 3

-   **Test 1** (omnibus test) is ok if there is no lack-of-fit
-   **Test 2** and **Test 3** are useful for diagnosing *when* (which
    events) and *why* (detection or survival) there's evidence for
    lack-of-fit
    -   Sub-components often lack adequate sample sizes for tests when
        the cap data is sparse (e.g., few recaptures, cap events w/small
        number of animals)

**Note:** These tests are always for time-dependent models, i.e.
"Phi.time.p.time".

**Warning:** to date, no goodness-of-fit test exists for models with
individual covariates (unless you discretize them and use groups),
individual time-varying covariates (unless you treat them as states) or
temporal covariates; therefore, remove these covariates from your
dataset before using it with R2ucare. For groups, just treat groups
separately as in the Dipper example.

### Data

Reformat data into matrix for R2ucare + create separate groups for those
first marked as juveniles vs. adults

```{r}
library(R2ucare) # CARE = CApture REcapture

# re-process to collapse and get freqs
lwed_capHist_proc <- lwed_capHist %>%
  select(ch, ageClass) %>%
  process.data(.)

lwed.hist <- matrix(as.numeric(unlist(strsplit(as.character(lwed_capHist_proc$data$ch), ","))),
                   nrow = length(lwed_capHist_proc$data$ch),
                   byrow = T)
lwed.freq <- lwed_capHist_proc$data$freq
lwed.group <- lwed_capHist_proc$data$ageClass

# split dataset into adults/juvs
mask <- (lwed.group == 'age1_juv')
lwedJuv.hist <- lwed.hist[mask,]
lwedJuv.freq <- lwed.freq[mask]
mask <- (lwed.group == 'age2_nonJuv')
lwedAd.hist <- lwed.hist[mask,]
lwedAd.freq <- lwed.freq[mask]
```

### Testing

Following decision tree in Gimenez et al. 2018 (MS for R2ucare
package)--

#### Full dataset

Results (p-value) suggest that some issue exists that's causing lack of fit

```{r}
lwed_test1 <- overall_CJS(lwed.hist, lwed.freq)
lwed_test1 ## p = 0
```

#### Juveniles

Test 1 for juveniles is NOT significant; Gimenez et al. 2018 decision
tree says to move forward w/fitting CJS model

```{r}
# test1
lwedJuv_test1 <- overall_CJS(lwedJuv.hist, lwedJuv.freq)
lwedJuv_test1 ## p = 0.771 >> fit CJS model
```

#### Adults

-   Test 1 IS significant; check Test 2CT
-   Test 2CT IS significant (indicates trap-dependence); check Test 3SR
    -   Note also that the sign-test value (signed square root of the
        Pearson chi-square statistic) is a directional test of the null
        hypothesis (Pradel et al. 2005) -- when negative (as it is
        here), it indicates an excess of indiv encountered at a given
        occasion among the indivs encountered at the previous occasion
-   Test 3SR IS significant (indicates transient effect); check Test 2CL
    & 3SM
    -   sign-test is negative; I assume it means the same as before? In
        Gimenez et al., they had a positive value, which they said
        happens when there's an excess of never seen again among the
        newly marked
-   Test 2CL does not have enough individuals to run
-   Test 3SM is NOT significant; decision tree recommends fitting model
    for trap-dependence & transience (not overdispersion though)

```{r}
# test1
lwedAd_test1 <- overall_CJS(lwedAd.hist, lwedAd.freq)
lwedAd_test1 ## p = 0 >> test2ct

# test2ct
lwedAd_test2ct <- test2ct(lwedAd.hist, lwedAd.freq)
lwedAd_test2ct ## p = 0.002 >> test3sr
## sign_test = -1.031; neg value means excess of indiv at a given occasion among indivs encountered at the previous occasion

# test3sr 
lwedAd_test3sr <- test3sr(lwedAd.hist, lwedAd.freq)
lwedAd_test3sr ## p = 0.000 >> test2cl & test3sm
## sign_test = -4.723; neg value means excess of indiv at a given occasion among indivs encountered at the previous occasion (I assume it means the same here?? not 100% sure though)

# ---

# test2cl
lwedAd_test2cl <- test2cl(lwedAd.hist, lwedAd.freq)
lwedAd_test2cl ## not enough individuals to test (test_perf = None)

# test3sm
lwedAd_test3sm <- test3sm(lwedAd.hist, lwedAd.freq)
lwedAd_test3sm ## p = 0.581 >> fit CJS model w/trap-dependence & transience
```

From paper: "it is possible to calculate a GOF test for this new model
by removing the two components Test 3.SR and Test 2.CT to the overall
GOF test (Pradel et al., 2005):"

```{r}
# subtract components 3sr and 2ct to the CJS test statistic
stat_new <- overall_CJS(lwedAd.hist, lwedAd.freq)$chi2 -
  (test3sr(lwedAd.hist, lwedAd.freq)$test3sr[[1]] +
     test2ct(lwedAd.hist, lwedAd.freq)$test2ct[[1]])

# calculate degree of freedom associated w/the new test statistic
df_new <- overall_CJS(lwedAd.hist, lwedAd.freq)$degree_of_freedom -
  (test3sr(lwedAd.hist, lwedAd.freq)$test3sr[[2]] +
     test2ct(lwedAd.hist, lwedAd.freq)$test2ct[[2]])

# compute p-value
1 - pchisq(stat_new, df_new) # 0.5809599; new model fits data well
```

### Adjust models

Obtain test for model w/trap-dependence:

```{r}
stat_tp <- lwedF_test1$chi2 - lwedF_test2ct$test2ct["stat"] # overall stat - 2CT stat
df_tp <- lwedF_test1$degree_of_freedom - lwedF_test2ct$test2ct["df"] # overall dof - 2CT dof

# compute p-value for null hypothesis: model with trap-dep fits the data well
pvalue <- 1 - pchisq(stat_tp, df_tp)  
pvalue # 0.0104678 -- so we reject the null; trap-dep does NOT fit data well
```

So that didn't work... maybe try with model w/transience?

```{r}
lwedF_test3sr$test3sr

stat_tp <- lwedF_test1$chi2 - lwedF_test3sr$test3sr["stat"] # overall stat - 2CT stat
df_tp <- lwedF_test1$degree_of_freedom - lwedF_test3sr$test3sr["df"] # overall dof - 2CT dof

# compute p-value for null hypothesis: model with transience fits the data well
pvalue <- 1 - pchisq(stat_tp, df_tp)  
pvalue # 0.03967785  -- reject the null; transience does NOT fit data well
```



## Overdispersion

Paterson blog:
<https://jamesepaterson.github.io/jamespatersonblog/2020-06-30_chat_for_CJS.html>

**c-hat**

```{r}
# Overall chat for lwed (male test stat + female test stat) / (male df + female df)

lwedF_tStat <- lwedF_test1$chi2
lwedM_tStat <- lwedM_test1$chi2

lwedF_dF <- lwedF_test1$degree_of_freedom
lwedM_dF <- lwedM_test1$degree_of_freedom

lwed.chat <- (lwedF_tStat + lwedM_tStat) / (lwedF_dF + lwedM_dF)

lwed.chat # 2.499571
```

A simple guide to interpreting c-hat values:

c-hat \< 1: generally we ignore slight deviations with underdispersion,
c-hat = 1: variance in data is as expected, given the model c-hat \> 1:
there is extra binomial noise in the data. We can adjust model selection
to use QAIC and increase variance around parameter estimates (widens
confidence intervals). c-hat \> 3: generally represents poor fit and
suggests model structure should be adjusted (is there an important part
of the system we haven't modeled?)

**adjust model table w/c-hat**

```{r}
# Adjust our CJS model table to account for chat different than 1 (chat = 1.016095)
# QAIC = (-2lnLik / chat) + 2K
# This favours simpler models as chat gets larger than 1
lwed.cjs.models$model.table$chat <- lwed.chat

lwed.cjs.models$model.table$QAIC <- (lwed.cjs.models$model.table$neg2lnl/lwed.chat) + (2*lwed.cjs.models$model.table$npar)

# Note: this doesn't autmatically update the order of the table! 
# In our case, the order of supported models did not change
# To sort:
lwed.cjs.models$model.table <- lwed.cjs.models$model.table %>%
  arrange(QAIC)

lwed.cjs.models # display models
```

# XXXXXXXXXXX

## Some background

-   Jolly-Seber (JS) model - focused on estimating abundance parameters
    (e.g., pop growth, recruitment, and abundance)
    -   explicit definitions of process by which unmarked animals are
        newly captured and marked; assumptions about process allows est
        of recruitment and pop sizes
    -   assumed that unmarked indivs in pop have same prob of capture as
        marked indiv in pop (i.e., newly captured unmarked animals are a
        random sample of all unmarked animals in pop)
-   Cormack-Jolly-Seber (CJS) models - focused on estimating survival
    rates (but not abundance)
    -   no assumptions made about how newly marked animals are obtained
    -   subsequent process of recovering marked animals in CJS is
        conditional upon animal being released alive at first encounter;
        survival and catchability refer only to those marked animals

Based on Iijima (2020), I want:

-   **capture-recapture model for open population**, where an "open
    population" is one in which the number of individuals can change via
    natural mortality, birth, and migration during the study period -
    may also benefit from **robust design** where multiple surveys are
    conducted under a constant condition
-   1st hierarchy of sampling in which variables can change across
    sampling periods
-   2nd hierarchy of sampling in which things should remain relatively
    stable

And based on Sandercock (2020), I may also want:

-   a multistate model, in which detections are coded as dynamic
    categorical states that potentially change b/t consecutive occasions

## CJS models w/marked

So in package 'marked' there's function "mscjs()" that will compute MLEs
for a Multi-state Cormack-Jolly-Seber open population capture-recapture
model for processed dataframe x with user specified formulas in
parameters that create list of design matrices dml. This function can be
called directly but is most easily called from crm that sets up needed
arguments.

OR-- might want mvmscjs() - fitting fxn for multivariate multistate CJS
with uncertainty models --constructed as a hidden Markov model as
described in Johnson et al. 2015

### data

Using package 'marked' (make sure RMark is detached first! too many
overlapping function names)

```{r}
#detach("package:RMark", unload=TRUE)
library(marked)

capHist_2009to2019 <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/captureHistories_byIndiv_2009to2023.csv", colClasses = "character") %>%
  # filter to 2009-2019 only
  mutate(ch = str_sub(ch, 1, 11)) %>%
  filter(ch != "00000000000")

capHist_lwed <- capHist_2009to2019 %>%
  filter(species == "LWED") %>%
  select(-species) %>%
  mutate(sex = as.factor(sex))

capHist_simp <- capHist_2009to2019 %>%
  filter(species == "SIMP") %>%
  select(-species) %>%
  mutate(sex = as.factor(sex))
```

### analysis

### Run model

**1. Process data**

process.data() is a helper function to process data for the model

```{r}
# lwed
lwed.cjs.proc <- process.data(capHist_lwed,
                              model = "cjs",
                              groups = "sex")

# simp

```

**2. Make design data**

Allows adding variables that depend on time (e.g., seasonal changes,
weather, catastrophic events)

```{r}
lwed.cjs.ddl <- make.design.data(lwed.cjs.proc)

#simpF.js.ddl <- make.design.data(simpF.js.proc)
#simpM.js.ddl <- make.design.data(simpM.js.proc)
```

**3. Create function to fit multiple models**

```{r}
fit.cjs.models <- function(dataProc, dataDesign) {
  
  # Apparent survival (Phi) formula
  Phi.sex.time <- list(formula=~sex*time) # Just like in other linear models "*" includes main effects and an interaction
  Phi.time <- list(formula=~time) # differs between discrete times
  Phi.sex <- list(formula=~sex) # differs between males and females
  Phi.dot <- list(formula=~1) # constant survival
  
  # Detection probability (p) formula
  p.sex <- list(formula=~sex)  # differs between males and females
  p.time <- list(formula=~time)  # one discrete estimate of p per capture event
  p.dot <- list(formula=~1) # constant detection
  
  # Construct all combinations and put into one model table
  cml <- create.model.list(c("Phi","p")) # makes all possibile combinations of those parameter formulas
  
  results <- crm.wrapper(cml,
                         data = dataProc,
                         ddl = dataDesign,
                         external = FALSE,
                         accumulate = FALSE,
                         hessian = TRUE)
  
  return(results)
}
```

**3. Outline formulas for each parameter**

```{r}
Phi.dot <- list(formula=~1)  # ~1 is always a constant (or single estimate)
Phi.sex <- list(formula=~sex) # This formula will have an intercept (for females) and an estimate for the difference between females and males
p.sex <- list(formula=~sex) # Be careful of case-sensitive names. Use the exact group column that was in data
```

**4. Make model**

```{r}
lwed.cjs_m1 <- crm(lwed.cjs.proc,
                   lwed.cjs.ddl,
                   model.parameters = list(Phi = Phi.dot,
                                           p = p.sex),
                   accumulate = F)
lwed.cjs_m1
```

**3. Run function**

```{r}
# run function
lwedF.js.models <- fit.js.models(lwedF.js.proc, lwedF.js.ddl)
lwedM.js.models <- fit.js.models(lwedM.js.proc, lwedM.js.ddl)

simpF.js.models <- fit.js.models(simpF.js.proc, simpF.js.ddl)
simpM.js.models <- fit.js.models(simpM.js.proc, simpM.js.ddl)

# view models
lwedF.js.models
lwedM.js.models

simpF.js.models
simpM.js.models
```

**4. Estimate real parameters**

We can look at the top model estimates:

```{r}
# pull top model
lwedF.js.models[[1]]
lwedM.js.models[[1]]

simpF.js.models[[1]]
simpM.js.models[[1]]
```

But these estimates \^\^ are not on probability scale (or in individuals
for N) (e.g. Phi, p on logit scale, pent on mlogit scale) - so we need
to use the *predict* function to estimate the real parameters:

```{r}
# predict real values
lwedF.js.predicted <- predict(lwedF.js.models[[1]])
lwedM.js.predicted <- predict(lwedM.js.models[[1]])

simpF.js.predicted <- predict(simpF.js.models[[1]])
simpM.js.predicted <- predict(simpM.js.models[[1]])

# look at predictions of real parameters
lwedF.js.predicted
lwedM.js.predicted

simpF.js.predicted
simpM.js.predicted

# what these parameters are saying (just lwedF for an example):
lwedF.js.predicted$Phi$estimate # 0.64 survival b/t capture events
lwedF.js.predicted$p$estimate # 0.84 detection prob
lwedF.js.predicted$pent # 0.09 prob of entry for each capture event
lwedF.js.predicted$N$estimate # ~ 5 unmarked indiv
```

## BaSTA

```{r}
library(BaSTA)
```

### format data

```{r}
# format capHist for basta
capHist_2009to2019_forBasta <- read.csv("./DISSERTATION/ch2_demography/00_data/01_demoData_clean/captureHistories_byIndiv_2009to2023.csv", colClasses = "character") %>%
  # filter LWED to 2009-2019 only; SIMP to 2011-2019
  mutate(
    ch = case_when(
      species == "SIMP" ~ str_sub(ch, 3, 11),
      species == "LWED" ~ str_sub(ch, 1, 11)
    )
  ) %>%
  filter(!ch %in% c("000000000", "00000000000"))

lwed_capHist_basta <- capHist_2009to2019_forBasta %>%
  filter(species == "LWED") %>%
  select(-species) %>%
  splitCH(x = "ch", data = ., prefix = "year") %>%
  select(-ch) %>%
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  merge(., deathAssignments, by = "animalID", all.x = T) %>%
  dplyr::rename("birthYear" = "birthYear_est",
                "deathYear" = "deathYear_est") %>%
  relocate(animalID, birthYear, deathYear) %>%
  relocate(-sex) %>%
  # recode NA to 0
  mutate(
    birthYear = replace_na(birthYear, 0),
    deathYear = replace_na(deathYear, 0)
  )

simp_capHist_basta <- capHist_2009to2019_forBasta %>%
  filter(species == "SIMP") %>%
  select(-species) %>%
  splitCH(x = "ch", data = ., prefix = "year") %>%
  select(-ch) %>%
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  merge(., deathAssignments, by = "animalID", all.x = T) %>%
  dplyr::rename("birthYear" = "birthYear_est",
                "deathYear" = "deathYear_est") %>%
  relocate(animalID, birthYear, deathYear) %>%
  relocate(-sex) %>%
  # recode NA to 0
  mutate(
    birthYear = replace_na(birthYear, 0),
    deathYear = replace_na(deathYear, 0)
  )

# check data - update year of birth to 0 since basta apparently wants that
DataCheck(lwed_capHist_basta, dataType = "CMR", studyStart = 2009, studyEnd = 2019)

DataCheck(simp_capHist_basta, dataType = "CMR", studyStart = 2011, studyEnd = 2019)

# fix data for basta
lwed_fixed_basta <- FixCMRdata(lwed_capHist_basta,
                               studyStart = 2009,
                               studyEnd = 2019,
                               autofix = rep(1, 6))
lwed_data_basta <- lwed_fixed_basta$newData

View(lwed_fixed_basta$newData)

simp_fixed_basta <- FixCMRdata(simp_capHist_basta,
                               studyStart = 2011,
                               studyEnd = 2019,
                               autofix = rep(1, 6))
simp_data_basta <- simp_fixed_basta$newData
```

### run basta

```{r}
source("./DISSERTATION/ch2_demography/01_scripts/00_cmrModels/multibasta.R")
source("./DISSERTATION/ch2_demography/01_scripts/00_cmrModels/plotFancyBasta.R")

View(bastaCMRdat)

lwed_multibasta <- MultiBaSTA(object = bastaCMRdat,
                              studyStart = 51,
                              studyEnd = 70,
                              models = c("EX", "GO", "WE", "LO"),
                              shapes = c("simple", "Makeham", "bathtub"))

ls("package:BaSTA")




lwed_basta_out <- basta(object = lwed_data_basta,
                        dataType = "CMR",
                        
                        studyStart = 2009,
                        studyEnd = 2019,
                       
                        model = "LO",
                        shape = "bathtub",
                       
                        covarsStruct = "prop.haz",
                        
                        nsim = 4,
                        parallel = T,
                        updateJumps = T)

summary(lwed_basta_out, digits = 3)
plot(lwed_basta_out, plot.type = "demorates")

lwed_basta_out$lifeTable

BaSTA::print.basta(lwed_basta_out)
```

**1. capHist**

```{r}
censusMat <- capData_2009to2023 %>%
  select(animalID, captureYear) %>%
  mutate(animalID = as.numeric(animalID)) %>%
  distinct() %>%
  arrange(animalID) %>%
  as.matrix()
head(censusMat)

chMat <- CensusToCaptHist(ID = censusMat[,1], d = censusMat[,2], dformat = "%Y", timeInt = "Y") %>%
  arrange(as.numeric(ID))
head(chMat)
```

**2. birthDeath**

```{r}
birthDeath <- merge(birthAssignments, deathAssignments, by = "animalID", all = T) %>%
  `colnames<-`(c("ID", "Birth", "Death"))
```

**3. covMat**

```{r}
rawCovMat <- md %>%
  select(animalID, sex)

covMat <- MakeCovMat(x = "sex", data = rawCovMat)

BaSTA::c
```

## capHist subsets

Code to create original capHist file is in
ch2_create_captureHistories.Rmd

```{r}
# original capHist imported above
capHist

# species/sex subsets
capHist_lwedF <- capHist %>%
  filter(species == "LWED") %>%
  filter(sex == "F")
capHist_lwedM <- capHist %>%
  filter(species == "LWED") %>%
  filter(sex == "M")

capHist_simpF <- capHist %>%
  filter(species == "SIMP") %>%
  filter(sex == "F")
capHist_simpM <- capHist %>%
  filter(species == "SIMP") %>%
  filter(sex == "M")
```

# XXXXXX

## 4.2 tamRun5 numbers

### Full set

From 2009-2019: - LWED - n = 144 total (out of 145 capData) - n = 69
juveniles (70 capData) - n = 75 non-juvs (75 capData) - SIMP - n = 100
total (103 capData) - n = 52 juveniles (53 capData) - n = 48 non-juvs
(50 capData)

```{r}
# LWED
## n = 144 total LWED individuals from 2009-2019
capData_byIndiv_firstEntry_tamRun5 %>%
  # filter to 2019 and earlier
  filter(rowID <= 613) %>%
  # lwed only
  filter(species == "LWED") %>%
  nrow()

## n = 69 juv LWED
capData_byIndiv_firstEntry_tamRun5 %>%
  # filter to 2019 and earlier
  filter(rowID <= 613) %>%
  # lwed only
  filter(species == "LWED") %>%
  # juvs only
  filter(ageClass == "juvenile") %>%
  # ditch animalID 100/rowID 1 (listed as juv, but found not to be)
  filter(rowID != 1) %>%
  nrow()

## n = 75 non-juv LWED
144-69


# SIMP
## n = 100 total SIMP individuals from 2009-2019
capData_byIndiv_firstEntry_tamRun5 %>%
  # filter to 2019 and earlier
  filter(rowID <= 613) %>%
  # lwed only
  filter(species == "SIMP") %>%
  nrow()

## n = 52 juv SIMP
capData_byIndiv_firstEntry_tamRun5 %>%
  # filter to 2019 and earlier
  filter(rowID <= 613) %>%
  # lwed only
  filter(species == "SIMP") %>%
  # juvs only
  filter(ageClass == "juvenile") %>%
  nrow()

## n = 48 non-juv SIMP
100-52
```

### Hair samples

From 2009-2019: - LWED - n = 135 total (144 all tamRun5; 145 capData) -
n = 62 juveniles (69 all tamRun5; 70 capData) - n = 73 non-juvs (75 all
tamRun5; 75 capData) - SIMP - n = 99 total (100 all tamRun5; 103
capData) - n = 52 juveniles (52 all tamRun5; 53 capData) - n = 47
non-juvs (48 all tamRun5; 50 capData)

```{r}
# n = 234 indivs w/hair samples in tamRun5 total
md_tamRun5_hairSamples %>%
  select(animalID) %>%
  distinct() %>%
  nrow()

# LWED
## n = 135 total LWED individuals from 2009-2019
capData_byIndiv_firstEntry_tamRun5Hair %>%
  # filter to 2019 and earlier
  filter(rowID <= 613) %>%
  # lwed only
  filter(species == "LWED") %>%
  nrow()

## n = 62 juv LWED
capData_byIndiv_firstEntry_tamRun5Hair %>%
  # filter to 2019 and earlier
  filter(rowID <= 613) %>%
  # lwed only
  filter(species == "LWED") %>%
  # juvs only
  filter(ageClass == "juvenile") %>%
  # ditch animalID 100/rowID 1 (listed as juv, but found not to be)
  filter(rowID != 1) %>%
  nrow()

## n = 73 non-juv LWED
135-62


# SIMP
## n = 99 total SIMP individuals from 2009-2019
capData_byIndiv_firstEntry_tamRun5Hair %>%
  # filter to 2019 and earlier
  filter(rowID <= 613) %>%
  # lwed only
  filter(species == "SIMP") %>%
  nrow()

## n = 52 juv SIMP
capData_byIndiv_firstEntry_tamRun5Hair %>%
  # filter to 2019 and earlier
  filter(rowID <= 613) %>%
  # lwed only
  filter(species == "SIMP") %>%
  # juvs only
  filter(ageClass == "juvenile") %>%
  nrow()

## n = 47 non-juv SIMP
99-52
```

# 5 Capture-mark-recapture models

## 5.2 Jolly-Seber models

### prep

Packages:

```{r}
library(marked)
```

For R packaged 'marked' allows adding info like individual sex, so let's
add that to capHist

```{r}
capHist_lwed_sex <- capHist_lwed %>%
  merge(., capData_byIndiv_v5[, c("animalID", "sex")], by = "animalID") %>%
  distinct()

capHist_simp_sex <- capHist_simp %>%
  merge(., capData_byIndiv_v5[, c("animalID", "sex")], by = "animalID") %>%
  distinct()

# sex has to be a factor though
capHist_lwed_sex$sex <- as.factor(capHist_lwed_sex$sex)
capHist_simp_sex$sex <- as.factor(capHist_simp_sex$sex)
```

### lwed

#### run model

Do the thing (following Paterson blog):

```{r}
# Jolly-Seber models (POPAN formulation) are open population models, and 
# can be used to estimate abundance by including two more parameters than the CJS

# Additional parameters:
# Nsuper (or "superpopulation") = total number of individuals available to enter population throughout study
# pent ("probability of entry") =  the rate at which individuals enter the population from Nsuper (via births and immigration)

# WARNING: there is no adequate GOF tests for Jolly-Seber models. 
# One common method: Test equivalent structure of CJS model with R2ucare (previous tutorials).

# This tests *some* assumptions of Phi and p.
# Jolly-Seber models have an additional assumption:
# marked AND unmarked animals have same p (R2ucare doesn't test this)
# This assumption is required to estimate total abundance (sum of marked and unmarked animals in population)

# First, process data (Notice model = "JS", previous version = "CJS"); "collapses data" by distinct rows
capHist_lwed.js.proc <- process.data(capHist_lwed_sex,
                                model = "JS",
                                groups = "sex")

# Second, make design data (from processed data)
capHist_lwed.js.ddl <- make.design.data(capHist_lwed.js.proc)

fit.js.capHist_lwed.models <- function(){
  # Phi formulas
  Phi.dot <- list(formula=~1)
  Phi.time <- list(formula=~time)
  # p formulas
  p.dot <- list(formula=~1)
  # pent formulas. pent estimates MUST SUM to 1 (for each group).
  # This is constained using a Multinomial Logit link
  pent.time <- list(formula=~time)
  pent.sex <- list(formula=~sex)
  pent.dot <- list(formula=~1)
  # Nsuper formulas. Don't confuse "N" from model with predicted population size
  N.sex <- list(formula=~sex)
  N.dot <- list(formula=~1)
  cml <- create.model.list(c("Phi","p", "pent", "N"))
  results <- crm.wrapper(cml,
                         data = capHist_lwed.js.proc,
                         ddl = capHist_lwed.js.ddl,
                         external = FALSE,
                         accumulate = FALSE,
                         hessian = TRUE)
  
  return(results)
}

# Run function
capHist_lwed.js.models <- fit.js.capHist_lwed.models()

# Display model table
capHist_lwed.js.models
```

Notes for interpretation: - \~1 = intercept only model - detection
probability (pt) probability of detecting an indiv at time t if they're
alive - apparent survival (phi_t) - probability of an individual
surviving to the next time step - super population size (N_super) -
total number of indiv available to enter the study - probability of new
indiv from super population entering at time t (through births and
immigration pen_t_t)

The model table suggests that the most supported model has the
following: - Phi(~time)p(~1)pent(~time)N(~1) - Phi(\~time) = ??
survival - p(\~1) = constant detection probability - pent(\~time) = ??
probability of entry - N(\~1) =

```{r}
# Look at estimates of top model (row number on left of model table, or using name)
capHist_lwed.js.models[[1]]  # or dipper.js.models[["Phi.dot.p.dot.pent.dot.N.dot"]] or dipper.js.models$Phi.dot.p.dot.pent.dot.N.dot
```

#### calculate unmarked indivs

**I think this is actually what I need??**

```{r}
# The estimates above are not on probability scale (or in individuals for N)
# (e.g. Phi, p on logit scale, pent on mlogit scale)
# Predict (real) values using top model
capHist_lwed.js.predicted <- predict(capHist_lwed.js.models[[1]]) # [[1]] just calls the model row according to the model table.

# Look at predictions of real parameters
capHist_lwed.js.predicted 
```

Output shows: - survival b/t capture events = 0.69 - detection prob =
0.79 - prob of entry = 0.07 each capture event - number of unmarked
indiv is about 8, making the super populat \~8 + 180 marked indiv = 188

#### calculate pop size

There is no direct estimate of population size in the model. The
estimate of "N" in the model output is for the number of unmarked
individuals in the superpopulation. To estimate population size, we can
derive it using the model estimates.

```{r}
# Abundance (N) is derived from the estimated parameters
# We will estimate population size at each time by making a dataframe of estimates and calculating N
# We will use the predicted estimates from the top-performing model (in this case: "dipper.js.predicted")

# NOTE: the below method will have to be adjusted based on your final model and the number of capture events
N.derived_lwed <- data.frame(occ = c(1:7), # 7 events
                        Phi = c(rep(capHist_lwed.js.predicted$Phi$estimate, 6), NA),   # 6 survival estimates all the same
                        Nsuper = rep(capHist_lwed.js.predicted$N$estimate + nrow(capHist_lwed), 7), # Nsuper estimate + number of marked animals
                        pent = c(1-sum(capHist_lwed.js.predicted$pent$estimate), capHist_lwed.js.predicted$pent$estimate)) # Sum of all pent must be 1

# Set-up empty vector for calculating N
N.derived_lwed$N <- NA

# The inital population size (N[1]) = Nsuper * (1 - sum(all other pent estimates))
# This is because of the link function for estimating pent.
# The sum of all pent parameters MUST equal 1 (therefore, one less must be estimated)
N.derived_lwed$N[1] <- (N.derived_lwed$Nsuper[1] * N.derived_lwed$pent[1])

# Subsequent population sizes are estimated by calculating surviving individuals (N[t-1] * Phi[t]), and
# Adding new births (Nsuper * pent[t])
for(i in 2:nrow(N.derived_lwed)){
  N.derived_lwed$N[i] <- (N.derived_lwed$N[i-1]*N.derived_lwed$Phi[i-1]) + (N.derived_lwed$Nsuper[i] * N.derived_lwed$pent[i])
}

# Look at what we did
N.derived_lwed
```

Add 95% CI w/R package "RMark"

--notes on how to install MARK (required by RMark)
<http://www.phidot.org/software/mark/rmark/linux/> - download file for
linux in the link above - create MARK directory in programs and extract
the file into \~/programs/MARK/ and rename as 'mark' - change directory
to /usr/local/bin/ - create symbolic link using [sudo ln -s
\~/Programs/MARK/mark mark]

```{r}
detach("package:marked", unload=TRUE) # many of the function names are the same. unload `marked`

# install.packages("RMark") # first time only
# For RMark to work, you also need mark.exe installed separately
# http://www.phidot.org/software/mark/downloads/
# this may not be easy on a Mac OS (http://www.phidot.org/software/mark/rmark/linux/)
# RMark calls "mark" to do all the work outside of R
library(RMark)
```

Ok next step

```{r}
# We will use the same data but will just create the same top model (not all the other subsets)
capHist_lwed.rmark.processed <- RMark::process.data(capHist_lwed_sex,
                                              model = "POPAN")

# Formulae for model
Phi.dot <- list(formula=~1)
p.dot <- list(formula=~1)
pent.dot <- list(formula=~1)
N.dot <- list(formula=~1)

# The argument names are similar but a little different (notice "POPAN" instead of "js")
capHist_lwed.rmark <- mark(capHist_lwed_sex,
                           model = "POPAN",
                           model.parameters = list(Phi = Phi.dot,
                                                   p= p.dot,
                                                   pent = pent.dot,
                                                   N = N.dot),
                           realvcv = TRUE)


# The popan.derived function of RMark estimates N 
# (plus estimates SE and 95% CI using the delta method)
capHist_lwed.derived.rmark <- popan.derived(capHist_lwed.rmark.processed,
                                      capHist_lwed.rmark)$N

# Look at results
capHist_lwed.derived.rmark
```

### simp

#### run model

Do the thing (following Paterson blog):

```{r}
# Jolly-Seber models (POPAN formulation) are open population models, and 
# can be used to estimate abundance by including two more parameters than the CJS

# Additional parameters:
# Nsuper (or "superpopulation") = total number of individuals available to enter population throughout study
# pent ("probability of entry") =  the rate at which individuals enter the population from Nsuper (via births and immigration)

# WARNING: there is no adequate GOF tests for Jolly-Seber models. 
# One common method: Test equivalent structure of CJS model with R2ucare (previous tutorials).

# This tests *some* assumptions of Phi and p.
# Jolly-Seber models have an additional assumption:
# marked AND unmarked animals have same p (R2ucare doesn't test this)
# This assumption is required to estimate total abundance (sum of marked and unmarked animals in population)

# First, process data (Notice model = "JS", previous version = "CJS")
capHist_simp.js.proc <- process.data(capHist_simp_sex,
                                model = "JS",
                                groups = "sex")

# Second, make design data (from processed data)
capHist_simp.js.ddl <- make.design.data(capHist_simp.js.proc)

fit.js.capHist_simp.models <- function(){
  # Phi formulas
  Phi.dot <- list(formula=~1)
  Phi.time <- list(formula=~time)
  # p formulas
  p.dot <- list(formula=~1)
  # pent formulas. pent estimates MUST SUM to 1 (for each group).
  # This is constained using a Multinomial Logit link
  pent.time <- list(formula=~time)
  pent.sex <- list(formula=~sex)
  pent.dot <- list(formula=~1)
  # Nsuper formulas. Don't confuse "N" from model with predicted population size
  N.sex <- list(formula=~sex)
  N.dot <- list(formula=~1)
  cml <- create.model.list(c("Phi","p", "pent", "N"))
  results <- crm.wrapper(cml,
                         data = capHist_simp.js.proc,
                         ddl = capHist_simp.js.ddl,
                         external = FALSE,
                         accumulate = FALSE,
                         hessian = TRUE)
  
  return(results)
}

# Run function
capHist_simp.js.models <- fit.js.capHist_simp.models()

# Display model table
capHist_simp.js.models
```

#### calculate unmarked indivs

**I think this is actually what I need??**

```{r}
# The estimates above are not on probability scale (or in individuals for N)
# (e.g. Phi, p on logit scale, pent on mlogit scale)
# Predict (real) values using top model
capHist_simp.js.predicted <- predict(capHist_simp.js.models[[1]]) # [[1]] just calls the model row according to the model table.

# Look at predictions of real parameters
capHist_simp.js.predicted 
```

Output shows: - survival b/t capture events = 0.75 - detection prob =
0.71 - prob of entry = 0.08 each capture event - number of unmarked
indiv is about 8, making the super populat \~8 + 131 marked indiv = 139

**Resources:** - James Pateron blog post on Jolly-Seber models:
<https://jamesepaterson.github.io/jamespatersonblog/2020-07-26_jolly_seber_models.html> -
'marked' vignette
<https://cran.r-project.org/web/packages/marked/vignettes/markedVignette.html>

## 5.3 Cormack-Jolly-Seber

Following ['marked'
vignette](https://cran.r-project.org/web/packages/marked/vignettes/markedVignette.html)

```{r}
library(marked) 
library(ggplot2)

data(dipper)

model=crm(dipper)
model

# compute & store variance-covariance matrix from hessian at final estimates
model=cjs.hessian(model)
model # now able to print SE and 95% CI (set hessian = TRUE in call to crm if want to compute it when model is fitted)
```

You'll never fit only one model to data, so the most efficient approach
is to call process.data and make.design.data separately and pass the
results to crm so they can be used for each fitted model as shown below:

```{r}
dipper.proc=process.data(dipper)

dipper.ddl=make.design.data(dipper.proc)

Phi.sex=list(formula=~sex)

model=crm(dipper.proc,dipper.ddl,model.parameters=list(Phi=Phi.sex),
          accumulate=FALSE)
```

If you fit more than a few models, use crm.wrapper rather than crm. It
fits a set of models and returns a list with a model selection table
that summarizes the fit of all the models. By default, crm.wrapper
stores the model results externally and in the list it only stores the
names of the files containing the models. If you set external=FALSE,
then it will store the model results in the list as shown in the example
below.

```{r}
dipper.proc=process.data(dipper)

dipper.ddl=make.design.data(dipper.proc)

fit.models=function()
  {
  Phi.sex=list(formula=~sex)
  Phi.time=list(formula=~time)
  p.sex=list(formula=~sex)
  p.dot=list(formula=~1)
  cml=create.model.list(c("Phi","p"))
  results=crm.wrapper(cml,data=dipper.proc, ddl=dipper.ddl,
                       external=FALSE,accumulate=FALSE)
  return(results)
}

dipper.models=fit.models()

# model selection table (convergence = 0 means successful convergence)
dipper.models

# extract individual model details
dipper.models[[1]]
```

Now adding some covariates... (weight, flood, and trap dependence (td))

```{r}
data(dipper)

# Add a dummy weight field which are random values from 1 to 10
set.seed(123)
dipper$weight=round(runif(nrow(dipper),0,9),0)+1

# Add Flood covariate
Flood=matrix(rep(c(0,1,1,0,0,0),each=nrow(dipper)),ncol=6)
colnames(Flood)=paste("Flood",1:6,sep="")
dipper=cbind(dipper,Flood)

# Add td covariate, but exclude first release as a capture
# splitCH and process.ch are functions in the marked package
td=splitCH(dipper$ch)
td=td[,1:6]
releaseocc=process.ch(dipper$ch)$first
releaseocc=cbind(1:length(releaseocc),releaseocc)
releaseocc=releaseocc[releaseocc[,2]<nchar(dipper$ch[1]),]
td[releaseocc]=0
colnames(td)=paste("td",2:7,sep="")
dipper=cbind(dipper,td)

# show names
names(dipper)
```

Process data

```{r}
# Process data
dipper.proc=process.data(dipper)

# Create design data with static and time varying covariates
design.Phi=list(static=c("weight"),time.varying=c("Flood"))

design.p=list(static=c("sex"),time.varying=c("td"),
                         age.bins=c(0,1,20))

design.parameters=list(Phi=design.Phi,p=design.p)

ddl=make.design.data(dipper.proc,parameters=design.parameters)

names(ddl$Phi)
names(ddl$p)
```

# 6 Twin pairs

## 6.1 Likely twins

make sure you're using latest version of capData_byIndiv + the first
entry from that

Based on capData, we have n = 35 likely twin pairs in which both have
samples in tamRun5. Of these, n = 25 pairs have both blood and hair
samples (and thus can be used for chimerism analyses). Within this set,
n = 2 sets have three juveniles vs. two.

```{r}
# twinList for all capData
capData_twinList <- capData_byIndiv_firstEntry %>%
  filter(animalID != "UNK") %>%
  filter(ageClass == "juvenile") %>%
  select(c("captureDate", "groupName", "animalID")) %>%
  group_by(captureDate, groupName) %>%
  summarise(twinPairs = toString(sort(unique(animalID)))) %>%
  filter(str_detect(twinPairs, ",")) %>%
  separate_wider_delim(twinPairs, delim = ",", names = c("twin1", "twin2", "twin3"), too_few = "align_start") %>%
  as.data.frame() %>%
#  select(-captureDate) %>%
  distinct() %>%
  arrange(captureDate) %>%
  # remove white spaces
  apply(., 2, function(x) gsub("\\s+", "", x)) %>%
  as.data.frame()

# twinList in tamRun5
capData_twinList_tamRun5 <- capData_twinList %>%
  mutate(
    temp = str_sub(captureDate, 1, 4)
  ) %>%
  filter(!temp %in% c("2021", "2022", "2023")) %>%
  select(-temp) %>%
  mutate(
    twin1_samples = case_when(
      twin1 %in% md_tamRun5_bloodSamples$animalID & twin1 %in% md_tamRun5_hairSamples$animalID ~ "both",
      twin1 %in% md_tamRun5_bloodSamples$animalID & !twin1 %in% md_tamRun5_hairSamples$animalID ~ "bloodOnly",
      !twin1 %in% md_tamRun5_bloodSamples$animalID & twin1 %in% md_tamRun5_hairSamples$animalID ~ "hairOnly",
      .default = NA
    ),
    
    twin2_samples = case_when(
      twin2 %in% md_tamRun5_bloodSamples$animalID & twin2 %in% md_tamRun5_hairSamples$animalID ~ "both",
      capData_twinList_tamRun5$twin2 %in% md_tamRun5_bloodSamples$animalID & !twin2 %in% md_tamRun5_hairSamples$animalID ~ "bloodOnly",
      !twin2 %in% md_tamRun5_bloodSamples$animalID & twin2 %in% md_tamRun5_hairSamples$animalID ~ "hairOnly",
      .default = NA
    ),
    
    twin3_samples = case_when(
      twin3 %in% md_tamRun5_bloodSamples$animalID & twin3 %in% md_tamRun5_hairSamples$animalID ~ "both",
      twin3 %in% md_tamRun5_bloodSamples$animalID & !twin3 %in% md_tamRun5_hairSamples$animalID ~ "bloodOnly",
      !twin3 %in% md_tamRun5_bloodSamples$animalID & twin3 %in% md_tamRun5_hairSamples$animalID ~ "hairOnly",
      .default = NA
    )
  )

# n = 35 pairs where both have samples in tamRun5
capData_twinList_tamRun5 %>%
  filter(!is.na(twin2_samples)) %>%
  nrow()

# n = 26 pairs where both have blood samples
capData_twinList_tamRun5 %>%
  filter(!is.na(twin2_samples)) %>%
  filter(twin1_samples != "hairOnly") %>%
  filter(twin2_samples != "hairOnly") %>%
  nrow()

# n = 25 pairs where both have blood and hair samples
capData_twinList_tamRun5 %>%
  filter(twin1_samples == "both") %>%
  filter(twin2_samples == "both") %>%
  nrow()

# n = 1 pair in which one twin has bloodOnly
capData_twinList_tamRun5 %>%
  filter(!is.na(twin2_samples)) %>%
  filter(twin1_samples != "hairOnly") %>%
  filter(twin2_samples != "hairOnly") %>%
  filter(twin1_samples == "bloodOnly") %>%
#  filter(twin2_samples == "bloodOnly") %>%
  nrow()
```

Export twinList

```{r}
write.csv(capData_twinList, "./paper3_demographics/twinList_capData_2009to2023.csv", row.names = F)
```

# X Lifespan

## Time present in study

The dataframe below includes the animalIDs of all individuals in
capData_byIndiv_v5 from 2009 to 2023. It includes the first and last
years and groups in which the individual was captured as well as the
difference between those two years.

```{r}
# now last entry
capData_byIndiv_v5_antiSort <- capData_byIndiv_v5 %>%
  arrange(desc(rowID))

capData_byIndiv_first.lastEntry <- capData_byIndiv_v5_antiSort[match(unique(capData_byIndiv_v5_antiSort$animalID), capData_byIndiv_v5_antiSort$animalID),] %>%
  
  filter(animalID != "UNK") %>%
  
  arrange(as.numeric(animalID)) %>%
  mutate(
    captureYear = str_sub(captureDate, 1, 4)
  ) %>%
  select(animalID, captureYear, groupName) %>%
  dplyr::rename("captureYear_last" = "captureYear",
                "groupName_last" = "groupName") %>%
  merge(., capData_byIndiv_firstEntry[, c("animalID", "captureDate", "groupName")], by = "animalID") %>%
  mutate(
    captureYear_first = str_sub(captureDate, 1, 4)
  ) %>%
  select(-captureDate) %>%
  dplyr::rename("groupName_first" = "groupName") %>%
  mutate(
    captureYear_first = as.numeric(captureYear_first),
    captureYear_last = as.numeric(captureYear_last),
    diff_lastFirst = captureYear_last - captureYear_first,
    groupMatch = case_when(
      groupName_first == groupName_last ~ "yes",
      .default = "no"
    )
  ) %>%
  relocate(animalID, groupName_first, groupName_last, groupMatch, captureYear_first, captureYear_last, diff_lastFirst) %>%
  
  # see who started in study as a juvenile
  merge(., birthYear_knownOnly[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  
  # then calculate age at last capture
  mutate(
    age_lastCap = case_when(
      !is.na(birthYear_est) ~ diff_lastFirst,
      .default = NA
    )
  )
```

## Group membership across time

```{r}
groupMembership <- capData_byIndiv_v5 %>%
  
  # filter to 2019 and earlier
#  filter(rowID <= 613) %>%
  # remove rowID 611 (likely animalID2, but missing trapsheets; doesn't matter thoughg b/c already have 2019 info for this indiv)
  filter(rowID != 611) %>%
  
  # ditch UNK animalIDs
  filter(animalID != "UNK") %>%
  
  select(animalID, captureDate, groupName) %>%
  # first need to get cases w/multiple groups in one year into single col
  mutate(captureYear = str_sub(captureDate, 1, 4)) %>%
  distinct() %>%
  mutate(temp = str_c(animalID, "_", captureYear)) %>%
  arrange(temp, captureDate) %>%
  mutate(dup = if_else(duplicated(temp), "entry2", "entry1")) %>%
  select(temp, groupName, dup) %>%
  distinct() %>%
  pivot_wider(names_from = dup,
              values_from = groupName) %>%
  mutate(
    groupName = case_when(
      is.na(entry2) ~ entry1,
      entry1 == entry2 ~ entry1,
      entry1 != entry2 ~ str_c(entry1, entry2, sep = "_")
    )
  ) %>%
  separate("temp", into = c("animalID", "captureYear")) %>%
  select(animalID, captureYear, groupName) %>%
  # now can make big df
  pivot_wider(names_from = captureYear,
              values_from = groupName) %>%
  arrange(as.numeric(animalID)) %>%
  relocate(c(animalID, `2009`, `2010`, `2011`, `2012`, `2013`, `2014`))
```

# XXXXXXXXXXX

# OLD SCRIPTS

# Potential packages

-   [popkin](https://cran.r-project.org/web/packages/popkin/vignettes/popkin.html)
    -   estimates the kinship matrix of individuals and FST from their
        biallelic genotypes
-   [sequoia](https://cran.r-project.org/web/packages/sequoia/vignettes/vignette-main.html)
    -   for 100s of SNPs
-   [skater](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8844523/)
    -   for genome-wide SNP genotypes

# Packages

```{r}
library(lubridate)
library(sequoia)
library(tidyverse)
```

# Data

## Metadata

```{r}
md_tamRun5 <- read.csv("./05_tamRun5/03_run5GTscore/tamRun5_metadata.csv") %>%
  mutate(
    animalID = 
      case_when(
        sampleID == "tamRun5-411" ~ "pcr1Neg_p5.C4",
        .default = animalID
      ),
    sampleType =
      case_when(
        sampleID == "tamRun5-411" ~ "pcr1Neg",
        .default = sampleType
      )
  ) %>%
  mutate(sampleID = gsub("-", "\\.", sampleID))

sampleList_lwedHair <- md_tamRun5 %>%
  filter(species == "LWED") %>%
  filter(sampleType == "hair") %>%
  select(sampleID) %>%
  pull()

sampleList_simpHair <- md_tamRun5 %>%
  filter(species == "SIMP") %>%
  filter(sampleType == "hair") %>%
  select(sampleID) %>%
  pull()
```

## Loci

Below are the loci sets that I'll be using for kinship analyses. These
include ONLY the INDID loci, including general and species-specific
INDID loci.

```{r}
indidLoci_lwed <- read.table("./05_tamRun5/03_run5GTscore/primerProbeFileV3_LWED.txt", sep = "\t", header = T) %>%
  select(Locus) %>%
  filter(!str_detect(Locus, "SEXID|SPECIESID")) %>%
  pull()

indidLoci_simp <- read.table("./05_tamRun5/03_run5GTscore/primerProbeFileV3_SIMP.txt", sep = "\t", header = T) %>%
  select(Locus) %>%
  filter(!str_detect(Locus, "SEXID|SPECIESID")) %>%
  pull()
```

## Genotypes

### Original genos

```{r}
genos_tamRun5_10x <- read.table("./05_tamRun5/03_run5GTscore/fullSet_polyGenResults_singleSNP_10x.txt", header = T) %>%
  rownames_to_column("locus") %>%
  mutate(locus = sub('[_][^_]+$', '', locus)) %>%
  column_to_rownames("locus") %>%
  mutate(across(everything(), ~ gsub(",", "", .)))

# LWED hair genos
genos_lwedHair <- genos_tamRun5_10x %>%
  select(any_of(sampleList_lwedHair)) %>%
  t() %>%
  as.data.frame() %>%
  select(any_of(indidLoci_lwed))

# SIMP hair genos
genos_simpHair <- genos_tamRun5_10x %>%
  select(any_of(sampleList_simpHair)) %>%
  t() %>%
  as.data.frame() %>%
  select(any_of(indidLoci_simp))
```

### Reformat for sequoia

Sequoia requires genotypes to be in a numeric matrix GenoM with one line
per individual and one column per SNP, with each SNP coded as 0, 1, 2
copies of the reference allele, or missing (-9). The rownames should be
the individual IDs, and column names are ignored.

#### LWED

```{r}
genos_lwedHair_seq <- sequoia::GenoConvert(
  InData = genos_lwedHair,
  InFormat = "single",
  Missing = "0",
  OutFile = "./dissChapter_demography/genos_lwedHair_seq.txt",
  OutFormat = "seq")
```

GenoConvert gives the following warnings:

-   There are 14 SNPs scored for \<5% of individuals, these will be
    excluded
-   There are 8 monomorphic (fixed) SNPs, these will be excluded
-   In addition, there are 85 SNPs scored for \<50% of individuals
-   There are 47 individuals scored for \<5% of SNPs, these WILL BE
    IGNORED
-   Warning: In addition, there are 16 individuals scored for \<20% of
    SNPs, it is advised to treat their assignments with caution

After exclusion, There are 91 out of 138 individuals and 132 SNPs.

#### SIMP

```{r}
genos_simpHair_seq <- sequoia::GenoConvert(
  InData = genos_simpHair,
  InFormat = "single",
  Missing = "0",
  OutFile = "./dissChapter_demography/genos_simpHair_seq.txt",
  OutFormat = "seq")
```

GenoConvert gives the following warnings:

-   There are 23 SNPs scored for \<5% of individuals, these will be
    excluded
-   There are 6 monomorphic (fixed) SNPs, these will be excluded
-   In addition, there are 80 SNPs scored for \<50% of individuals
-   There are 34 individuals scored for \<5% of SNPs, these WILL BE
    IGNORED
-   In addition, there are 9 individuals scored for \<20% of SNPs, it is
    advised to treat their assignments with caution

After exclusion, There are 65 out of 99 individuals and 125 SNPs.

### Read in sequoia genos

```{r}
GenoM_lwed <- as.matrix(read.table("./dissChapter_demography/genos_lwedHair_seq.txt", row.names = 1, header = FALSE))

GenoM_simp <- as.matrix(read.table("./dissChapter_demography/genos_simpHair_seq.txt", row.names = 1, header = FALSE))
```

## Life history data

Sequoia requires a life history file that should be a dataframe composed
of 3-5 columns:

-   **ID**
    -   It is probably safest to stick to R's 'syntactically valid
        names', defined as "consists of letters, numbers and the dot or
        underline characters and starts with a letter, or the dot not
        followed by a number".
-   **Sex**
    -   1 = female, 2 = male, 3=unknown, 4=hermaphrodites. All other
        numbers, letters, or NA = unknown
-   **BirthYear**
    -   Year of birth/hatching/germination/. . . In species with more
        than one generation per year, a finer time scale than year of
        birth ought to be used (in round numbers), ensuring that parents
        are always 'born' in a time unit prior to their first offspring
        (e.g. parent's BirthYear=2001 (t = 1) and offspring
        BirthYear=2005 (t = 5)). Negative numbers and NA's are
        interpreted as unknown
-   **BY.min (optional)**
    -   Earliest year in which individual may have been born, if exact
        year is unknown. Ignored when BirthYear is non-missing.
-   **BY.max (optional)**
    -   Latest year in which individual may have been born

```{r}
infancyPeriods <- read.csv("./sampleOrganization/allCaptures_infancyPeriods_2009-2019.csv") %>%
  select(c("animalID", "infStart")) %>%
  distinct() %>%
  na.omit() %>%
  mutate(
    infStart_date = mdy(infStart),
    BirthYear = year(infStart_date)
  )

LifeHistData_lwed <- md_tamRun5 %>%
  filter(species == "LWED") %>%
  filter(sampleType == "hair") %>%
  select(c("animalID", "sampleID", "sex")) %>%
  merge(., infancyPeriods[, c("animalID", "BirthYear")], by = "animalID", all.x = T) %>%
  rename("ID" = "sampleID",
         "Sex" = "sex") %>%
  select(c("ID", "Sex", "BirthYear")) %>%
  mutate(
    Sex = 
      case_when(
        Sex == "F" ~ "1",
        Sex == "M" ~ "2"
      )
  )

LifeHistData_simp <- md_tamRun5 %>%
  filter(species == "SIMP") %>%
  filter(sampleType == "hair") %>%
  select(c("animalID", "sampleID", "sex")) %>%
  merge(., infancyPeriods[, c("animalID", "BirthYear")], by = "animalID", all.x = T) %>%
  rename("ID" = "sampleID",
         "Sex" = "sex") %>%
  select(c("ID", "Sex", "BirthYear")) %>%
  mutate(
    Sex = 
      case_when(
        Sex == "F" ~ "1",
        Sex == "M" ~ "2"
      )
  )
```

# Kinship run

## LWED

### Parentage

```{r}
ParOUT_lwed <- GetMaybeRel(GenoM = GenoM_lwed,
                       LifeHistData = LifeHistData_lwed,
                       Module = "par")

names(ParOUT_lwed)

# export
writeSeq(
  SeqList = ParOUT_lwed,
  MaybeRel = T,
  OutFormat = "xls",
  folder = "./dissChapter_demography/sequoiaOutput",
  file = "sequoia_output_lwedPar.xlsx")
```

# SCRAPS

```{r}
#detach("package:marked", unload=TRUE)
library(RMark)

# 1) create capHist
m1_lwed_capHist <- capHist_2009to2019 %>%
  filter(species == "LWED") %>%
  select(-species) %>%
  merge(., capData_firstEntry[, c("animalID", "ageClass", "ageClass_classifier")], by = "animalID") %>%
  # opting to recode animalID 90 as juv for first capture (see capData notes)
  mutate(
    ageClass = case_when(
      animalID == 90 ~ "juvenile",
      .default = ageClass
    ),
    # also update ageClass names for ease of use later
    ageClass = case_when(
      ageClass == "juvenile" ~ "age1",
      ageClass == "subadult" ~ "age2",
      ageClass_classifier == "adult_young" ~ "age2",
      .default = "age3"
      )
  ) %>%
  dplyr::rename("ageClass1" = "ageClass") %>%
  # for indivs born during study period, recode any caps prior to normalized birthYear to 0
  merge(., birthAssignments[, c("animalID", "birthYear_est")], by = "animalID", all.x = T) %>%
  mutate(
    temp = birthYear_est - 2009,
    ch = case_when(
      !is.na(temp) ~ `substr<-`(ch, temp, temp, "0"),
      .default = ch
      )
  ) %>%
  # remove any all-zero records
  filter(ch != "00000000000") %>%
  # grab ch and grouping variables >> recode grouping vars as factor
  mutate(sex = as.factor(sex),
         ageClass1 = as.factor(ageClass1)) %>%
  arrange(desc(ch)) %>%
  select(ch, sex, ageClass1)

# 1) process data
rmark_m1_lwed.cjs.proc <- process.data(
  m1_lwed_capHist,
  begin.time = 2009,
  model = "CJS",
  groups = "sex",
  time.intervals = m1_lwed_capIntervals
  )

# 2) design data
## 2a)
rmark_m1_lwed.cjs.ddl <- Rmake.design.data(rmark_m1_lwed.cjs.proc)

## 2b) add ageClass


## add effort covariate
#newTimes <- as.character(unique(c(rmark_m1_lwed.cjs.ddl$Phi$time, rmark_m1_lwed.cjs.ddl$p$time)))

#temp <- data.frame(
#  time = newTimes,
#  effort = lwed_capSummary_byGroup[lwed_capSummary_byGroup$captureYear %in% 2010:2019, "nGroups"]
#)

#rmark_m1_lwed.cjs.ddl$p <- merge_design.covariates(rmark_m1_lwed.cjs.ddl$p,
#                                                   temp)

rmark_m1_lwed.cjs.ddl$Phi
rmark_m1_lwed.cjs.ddl$p
```
