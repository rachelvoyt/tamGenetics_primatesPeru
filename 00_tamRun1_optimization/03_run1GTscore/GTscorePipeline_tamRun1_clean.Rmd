---
title: "GTscorePipeline_COMBINED"
output: html_document
date: '2022-06-07'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.path = "tools/")
```

# 1 Packages

```{r load packages, include=FALSE}
source("./GTscore_sourceScripts/GTscore_modified.R") # NOTE- added N=ATGC to script for later analyses (not included in original)
library(gsubfn)
library(phylotools)
library(TidyMultiqc)
library(tidyverse)
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager", version = "3.16")
BiocManager::install("Biostrings")
```

GTscore also requires Perl and the packages "Algorithm::Combinatorics" and "Excel-Writer-XLSX". Perform the following in terminal to install on Linux. NOTE -- be sure to install both perl and the modules in root. See how to install perl packages [here](http://www.cpan.org/modules/INSTALL.html).

NOTE - the old way of installing perl through conda (conda install -c conda-forge perl) doesn't play nice anymore; better to install directly from perl:

```{bash, eval = FALSE}
# Install perl
curl -L http://xrl.us/installperlnix | bash

# Install cpanminus (makes installing perl modules easier)
cpan App::cpanminus

# Install necessary perl modules
sudo cpan Algorithm::Combinatorics
sudo cpan Excel::Writer::XLSX
```

I also recently had issues with installing perl modules with "cpanm" -- installing with "cpan" instead solved things. Generally speaking, perl continues to be a massive pain in new fun ways every time I open this up to re-run something.

# 2 Overview

**This is a cleaned up version of the tamRun1 gtscore pipeline - took the one I originally made in 2022 and updated it to reflect all I've learned in 2024**

## 2.1 About the pipeline

This pipeline includes all steps needed to analyze MiSeq data output, including how to interleave the fasta sequences and create the necessary files for analysis in GTscore. The GTscore part of the pipeline is based on that created by Garrett McKinney (see the associated github here), and combines scripts included in his original "GTscore_pipeline.R" as well as his original "README.md" - there's a good bit of overlap between these files, but a few scripts exist in one but not the other.

In this pipeline, I've included separate analyses of shared loci and species-specific loci, where analyses of species-specific loci only include samples and amplicon reference sequences from the respective species. I've also included a separate analysis of the 76 loci for which bp3 incorrectly designed primers.

## 2.2 About the data

The sequence data used in this pipeline is from tamarinGenetics optimization run #1.

### Metadata

**Quick-load**

```{r}
md <- read.csv("./00_tamRun1_optimization/03_run1GTscore/tamRun1_metadata_v2.csv")
```

**update original md formatting:**

```{r}
# original md has samples that didn't make it to final run + some formatting that doesn't match later runs
run1_md_v1 <- read.csv("./00_tamRun1_optimization/03_run1GTscore/tamRun1_metadata_v1.csv")

run1_md_v2 <- md_tamRun1_v1 %>%
  filter(included_inRun == "yes") %>%
  select(-included_inRun) %>%
  mutate(
    animalID = case_when(
      animalID == "(-) ctrl" ~ "pcr1Neg",
      .default = animalID
    ),
    sampleType = case_when(
      is.na(sampleType) ~ "pcr1Neg",
      .default = sampleType
    ),
    species = case_when(
      species == "SFUS" ~ "LWED",
      is.na(species) ~ "pcr1Neg",
      .default = species
    )
  ) %>%
  mutate(
    sampleFile = str_c(sampleID, ".fastq"),
    sampleFile = gsub("_", "-", sampleFile),
    sampleID = gsub("_", "\\.", sampleID),
    sampleID_md = str_c("s", str_sub(sampleID, 8, -1), "_", tolower(species), "_", animalID, "_", sampleType)
  ) %>%
  relocate(c(sampleFile, sampleID_md), .after = sampleID) %>%
  mutate(
    sampleID_md = case_when(
      is.na(sampleID_md) ~ str_c("s", str_sub(sampleID, 8, -1), "_", animalID),
      .default = sampleID_md
      )
    ) %>%
  dplyr::rename("sampleName" = "sampleTubeNo.") %>%
  mutate(
    sampleName = as.character(sampleName),
    sampleName = case_when(
      sampleType == "blood" ~ str_c("lm_", sampleName),
      sampleType == "hair" ~ str_c("env_", sampleName),
      .default = sampleName
    )
  )

write.csv(run1_md_v2, "./00_tamRun1_optimization/03_run1GTscore/tamRun1_metadata_v2.csv", row.names = F)
```

# 3 Prep sequencing results

## 3.1 Download sequences from BaseSpace

To download all sample files, it's easiest to use the BaseSpace Command Line Interface (CLI).

To install, follow the scripts provided here: <https://developer.basespace.illumina.com/docs/content/documentation/cli/cli-overview>

Note that even if it's already installed, you may need to re-authenticate via the command below. Running it will give a link; click to open in a browser and complete authentication.

```{bash, eval = F}
bs auth
```

Once authentication is complete, you can download the desired files as follows: **[[not updated]]**

```{bash, eval = F}
# Check Project IDs (outputs Project IDs for tamRun3_L1Raquel and Unindexed Reads)
bs list projects

# Sample sequences (tamRun3_L1Raquel, tamRun3b_L1)
bs download project -i 384884910 -o /home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/03_tamRun3/00_run3Seqs --extension=fastq.g]

# Unindexed Reads
bs download project -i 374582211 -o /home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/03_tamRun3/00_run3Seqs/unindexedReads --extension=fastq.gz
```

## 3.2 Extract fast.gz files 

```{bash Extract sequencing results, eval = FALSE}
# Navigate to the directory containing the .fastq.gz files from the sequencing run
cd 00_run1Seqs

# Move all .gz files out of their individual folders and into the current directory & remove empty folders
mv */* ./
find -empty -delete

# Extract all files
gunzip -r .

# Trim filenames to make them more manageable
for f in *R1_001.fastq; do g="${f%%_S*}_R1.fastq"; mv "${f}" "${g}"; done
for f in *R2_001.fastq; do g="${f%%_S*}_R2.fastq"; mv "${f}" "${g}"; done
```

## 3.3 Interleave files

```{bash Interleave fasta seqs}
cd ./../

# Interleave reads 1 & 2 for each sample and place in a new folder
for i in ./00_run1Seqs/*_R1.fastq; do name=$(basename $i _R1.fastq); reformat.sh in=00_run1Seqs/${name}_R1.fastq in2=00_run1Seqs/${name}_R2.fastq out=02_run1Interleaved/${name}.fastq; done
```


AND/OR - create interleaved files from the filtered reads:
```{bash}
# Interleave reads 1 & 2 for each sample and place in a new folder
for i in ./01_optSeqs_filtered/*_filtered_R1.fastq.gz; do name=$(basename $i _filtered_R1.fastq.gz); reformat.sh in=01_optSeqs_filtered/${name}_filtered_R1.fastq.gz in2=01_optSeqs_filtered/${name}_filtered_R2.fastq.gz out=02_optInterleaved_filtered/${name}_interleaved_filtered.fastq.gz; done

# cd to 02_optInterleaved_filtered and extract all .gz files
cd 02_optInterleaved_filtered
gunzip -r .
```

# 4 Quality checks

To get sequence quality scores for each sample, we can use 'fastqc' paired with 'MultiQC' -- 'fastp' is better for paired-end reads, but doesn't play nice when it comes to getting quality scores from the MultiQC report. Note that we'll be running quality checks on reads 1 and 2 separately (vs. interleaved).

## 4.1 fastqc + multiqc

*Note*: use "\--interactive" to force plots to tell you which line belongs to which sample, otherwise it will remove this option since there are so many samples in this run

```{bash eval = F}
# Activate fastqc environment
cd ./01_run1QualityChecks
conda activate fastqc-env

# Run fastqc
for i in ../00_run1Seqs/*; do fastqc $i; done

# Move fastqc files to quality checks folder
mv ../00_run1Seqs/*fastqc* .

# Activate multiqc environment
conda activate multiqc-env

# Run MultiQC on all files within the quality checks folder
multiqc --interactive .
```

## 4.2 TidyMultiqc

To convert the MultiQC into something more usable in R, we can use the package 'TidyMultiqc', which converts the 'multiqc_data.json' file into tidy data frames.

Load FastQC MultiQC report to R

```{r}
MultiQCfastQCpath <- file.path("/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/00_tamRun1_optimization/01_run1QualityChecks/multiqc_data", "multiqc_data.json")

MultiQCfastQC <- TidyMultiqc::load_multiqc(MultiQCfastQCpath, sections = c("general", "raw"))
```

### 4.2.1 Obtain median sequence quality scores

For the analyses in this section, I followed [this vignette](https://cran.r-project.org/web/packages/TidyMultiqc/vignettes/TidyMultiqc.html) provided by the makers of the TidyMultiqc package.

MultiQC reports do not provide a numerical summary statistic for read quality; they only have mapping quality and pass/fails for the per-base sequence quality. We instead need to pull this data from one of the plots -- I'm using the "Per Sequence Quality Scores" plot here:

```{r}
df <- TidyMultiqc::load_multiqc(
  MultiQCfastQCpath, 
  sections = 'plot',
  plots = "fastqc_per_sequence_quality_scores_plot")
```

This provides a nested data frame as a set of x, y pairs. As it's a histogram plot, we know that the `x` value is the quality score, and `y` is the number of times that score has been counted.

We can use tidyr to unnest the data, HistDat to create a HistDat object for each group, then purr to map each plot data frame into a row of summary statistics:

```{r}
df_unNest <- df %>%
  dplyr::mutate(
    purrr::map_dfr(plot.fastqc_per_sequence_quality_scores_plot, function(plot_df){
      hist = HistDat::HistDat(vals=plot_df$x, counts = plot_df$y)
      list(
        mean_qc = mean(hist),
        median_qc = median(hist),
        max_qc = max(hist)
      )
    }),
    plot.fastqc_per_sequence_quality_scores_plot = NULL
  )
```

This dataframe has separate rows for reads 1 & 2; we can rearrange that to make it easier to work with for our purposes. Since we're most interested in median quality, we'll just pull that value for each sample.

```{r}
seqQC_r1 <- df_unNest %>%
  select(c("metadata.sample_id", "median_qc")) %>%
  filter(grepl("R1", metadata.sample_id)) %>%
  dplyr::rename("medianQC_r1" = "median_qc") %>%
  mutate(sampleNo = substr(metadata.sample_id, start = 9, stop = 11))

seqQC_r2 <- df_unNest %>%
  select(c("metadata.sample_id", "median_qc")) %>%
  filter(grepl("R2", metadata.sample_id)) %>%
  dplyr::rename("medianQC_r2" = "median_qc") %>%
  mutate(sampleNo = substr(metadata.sample_id, start = 9, stop = 11))

seqQC <- merge(seqQC_r1, seqQC_r2, by = "sampleNo") %>%
  select(c("sampleNo", "medianQC_r1", "medianQC_r2")) %>%
  arrange(sampleNo)
```

Let's just take a peek at the distribution of sequence quality scores for now; we'll use it in our other analyses later on:

```{r}
ggplot(seqQC, aes(medianQC_r1)) +
  geom_bar(stat = "count") +
  theme_bw()

ggplot(seqQC, aes(medianQC_r2)) +
  geom_bar(stat = "count") +
  theme_bw()
```

# 5 Create primer-probe & sample files

Prior to running the GTscore pipeline itself, we need to make a few files, including 1) sample files 2) primer-probe files for each species. I'm separating them out like this so that we have more accurate read counts and genotype rates for each sample and locus.

## 5.1 Sample files

We need three sets of sample files total: 1) all samples 2) LWED samples only + all negatives 3) SIMP samples only + all negatives.

**Quick-load**

```{r}
sf_fullSet <- read.table("./00_tamRun1_optimization/03_run1GTscore/sampleFiles_fullSet.txt")

sf_pos <- read.table("./00_tamRun1_optimization/03_run1GTscore/sampleFiles_pos.txt")

sf_lwed <- read.table("./00_tamRun1_optimization/03_run1GTscore/sampleFiles_LWED.txt")

sf_simp <- read.table("./00_tamRun1_optimization/03_run1GTscore/sampleFiles_SIMP.txt")
```

**File creation**

Create file for all samples in bash

```{bash}
cd ./../02_run5Interleaved

for i in *fastq; do echo $i; done > ./../03_run1GTscore/sampleFiles_fullSet.txt
```

Load into R

```{r}
sf_fullSet <- read.table("./00_tamRun1_optimization/03_run1GTscore/sampleFiles_fullSet.txt")
```

Use md file to create sample file species subsets; ditch negatives from species-specific sets

```{r}
# Create subsets
lwed <- filter(md, species == "LWED")
simp <- filter(md, species == "SIMP")

sf_lwed <- sf_fullSet %>%
  filter(V1 %in% lwed$sampleFile)

sf_simp <- sf_fullSet %>%
  filter(V1 %in% simp$sampleFile)

sf_pos <- rbind(sf_lwed, sf_simp) %>%
  arrange(V1)

# Export sample files
write.table(sf_lwed, file = "./00_tamRun1_optimization/03_run1GTscore/sampleFiles_LWED.txt", sep = "\t", row.names = F, col.names = F, quote = F)

write.table(sf_simp, file = "./00_tamRun1_optimization/03_run1GTscore/sampleFiles_SIMP.txt", sep = "\t", row.names = F, col.names = F, quote = F)

write.table(sf_pos, file = "./00_tamRun1_optimization/03_run1GTscore/sampleFiles_pos.txt", sep = "\t", row.names = F, col.names = F, quote = F)
```

## 5.2 Primer probe files

**Quick-load**

```{r}
pp_fullSet <- read.table("./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_fullSet.txt", header = T)

pp_dual <- read.table("./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_dual.txt", header = T)

pp_lwed <- read.table("./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_LWED.txt", header = T)

pp_simp <- read.table("./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_SIMP.txt", header = T)
```

**File prep**

there was a lot of fiddling around with these files, but for the sake of time, the primer-probe file that has the correct info for the bp3-error loci is in laLab_run1. I've included the original scripts that I used to create the primer-probe file for run1, but it doesn't seem to contain the bp3 error loci - apparently I stuck that in a different rmd file. Even there though, the probe and snp location info for those bp3 loci doesn't seem to be correct - based on my other rmd docs, it doesn't look like I got the updated stuff til GTscorePipeline_laLab_run1. SO - for the sake of getting the correct run metrics, I'm using the laLab primer probe file here PLUS adding the non-rescued bp3 error loci back in

```{r}
laLabrun1_pp_fullSet <- read.table("./02_laLab_run1/03_laLab_run1GTscore/primerProbeFile_fullSet.txt", header = T)


samFiles_pp_updated <- read.csv("./samFiles/updated_probes_rachel_26.09.22.csv", sep = "\t") %>%
  select(!Updated) %>%
  mutate_at(vars(Probe1, Probe2, Primer), ~ str_replace_all(., c("R"="AG",
                                                                 "Y"="CT",
                                                                 "S"="GC",
                                                                 "W"="AT",
                                                                 "K"="GT",
                                                                 "M"="AC",
                                                                 "N"="ATGC")))

# samFiles_pp_updated is missing LWED_281 (lwed_281 isn't a bp3error locus); I noted this in laLab GTscore rmd file and added it back in to the main primer probe file
laLabrun1_pp_fullSet %>%
  filter(!Primer %in% samFiles_pp_updated$Primer)
```

Redo tamRun1 primerProbeFile w/laLab file:

```{r}
# 226 loci that had no bp3 error or were "rescued"
pp_bp3clean <- read.table("./00_tamRun1_optimization/03_run1GTscore/primerProbeFile.txt", header = T) %>%
  mutate(Locus = sub('\\..*', '', Locus)) %>%
  mutate(
    Locus = case_when(
      Locus == "SEXID_195" ~ "SEXID_LWED_195",
      Locus == "SEXID_208" ~ "SEXID_LWED_208",
      Locus == "SEXID_211" ~ "SEXID_LWED_211",
      
      Locus == "SEXID_197" ~ "SEXID_SIMP_197",
      Locus == "SEXID_198" ~ "SEXID_SIMP_198",
      Locus == "SEXID_203" ~ "SEXID_SIMP_203",
      Locus == "SEXID_218" ~ "SEXID_SIMP_218",
      
      .default = Locus
    )
  )

# 76 loci w/bp3 error that couldn't be "rescued" immediately; but Sam apparently used MSA sequences to identify other variants for 36
pp_bp3error <- read.table("./00_tamRun1_optimization/03_run1GTscore/bp3error_primerProbeFile.txt", header = T) %>%
  mutate(Locus = sub('\\..*', '', Locus)) %>%
  mutate(
    Locus = case_when(
      Locus == "SEXID_195" ~ "SEXID_LWED_195",
      Locus == "SEXID_208" ~ "SEXID_LWED_208",
      Locus == "SEXID_211" ~ "SEXID_LWED_211",
      
      Locus == "SEXID_197" ~ "SEXID_SIMP_197",
      Locus == "SEXID_198" ~ "SEXID_SIMP_198",
      Locus == "SEXID_203" ~ "SEXID_SIMP_203",
      Locus == "SEXID_218" ~ "SEXID_SIMP_218",
      
      .default = Locus
    )
  )

pp_fullSet <- rbind(pp_bp3clean, pp_bp3error) %>%
  filter(!Primer %in% laLabrun1_pp_fullSet$Primer) %>%
  rbind(., laLabrun1_pp_fullSet)

pp_dual <- pp_fullSet %>%
  filter(!str_detect(Locus, "LWED")) %>%
  filter(!str_detect(Locus, "SIMP"))

pp_lwed <- pp_fullSet %>%
  filter(!str_detect(Locus, "SIMP"))

pp_simp <- pp_fullSet %>%
  filter(!str_detect(Locus, "LWED"))

pp_spec <- pp_fullSet %>%
  filter(!Locus %in% pp_dual$Locus)

# Export
write.table(pp_fullSet, "./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_fullSet.txt", sep = "\t", row.names = F, col.names = T, quote = F)

write.table(pp_lwed, "./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_LWED.txt", sep = "\t", row.names = F, col.names = T, quote = F)

write.table(pp_simp, "./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_SIMP.txt", sep = "\t", row.names = F, col.names = T, quote = F)

write.table(pp_dual, "./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_dual.txt", sep = "\t", row.names = F, col.names = T, quote = F)

write.table(pp_spec, "./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_spec.txt", sep = "\t", row.names = F, col.names = T, quote = F)
```

The files needed to create the primer-probe file (plus their respective scripts, such as to obtain SNP position & references amplicon sequences) were created by Sam, with edits where needed by RV. The script for creating the final primerProbeFile.txt files is below:

**Code used to create original primer probe file:**

```{r Create primer-probe files}
# Load files
probes226 <- read.csv("assay_info_probes_final_rvEdits.csv", header = F, sep = ",") %>% 
  dplyr::rename(c(name=V1, primer=V2, probe1=V3, probe2=V4)) #locus name, probe1&2, & primer for the 226 loci where bp3 successfully recognized SNP [] and/or are informative; RV edited to include brackets around every IUB (some bracket pairs had multiple IUB codes inside)
probeInfo <- read.csv("probe_info_ALL.csv") #locus name, allele1&2, probe1&2 for ALL loci
snpPos <- read.csv("pos_amplicon.csv", sep = ",", colClasses = "character") #SNP position for the 226 loci; read in all as character so as not to strip leading zeros in snp position
nameTranslation <- read.csv("primers_seqName_to_shortName.csv") #file to translate sequence names to shorter bp3 names (for easier readability)

# Add allele1 & allele2 info from probeInfo to probes226
pp1 <- merge(probes226, probeInfo, by = "name", all.x = T, all.y = F) %>%
  select(c("name", "allele1", "allele2", "probe1.x", "probe2.x", "primer"))

# Add SNP position from snpPos
pp2 <- merge(pp1, snpPos, by.x = "name", by.y = "SNP_name") %>%
  select(c("name", "allele1", "allele2", "probe1.x", "probe2.x", "primer", "pos_in_amplicon")) %>%
  dplyr::rename(c(Allele1=allele1, Allele2=allele2, Probe1=probe1.x, Probe2=probe2.x,
           Primer=primer, SNPpos = pos_in_amplicon))
View(pp2)

# Change locus name to short name, add ploidy column
pp3 <- merge(pp2, nameTranslation, by.x = "name", by.y = "seqID1") %>%
  select("primerName2", "Allele1", "Allele2", "Probe1", "Probe2", "SNPpos", "Primer") %>%
  dplyr::rename(Locus=primerName2) %>%
  mutate(Ploidy=2, .after=Locus) %>%
  relocate(SNPpos, .after=Ploidy)
View(pp3)
length(pp3$Locus) #226; good!

# Replace IUPAC codes with bases
pp4 <- pp3 %>%
  mutate_at(vars(Probe1, Probe2, Primer), ~ str_replace_all(., c("R"="AG",
                                                                 "Y"="CT",
                                                                 "S"="GC",
                                                                 "W"="AT",
                                                                 "K"="GT",
                                                                 "M"="AC",
                                                                 "N"="ATGC")))
View(pp4)

# Create separate LWED and SIMP primer-probe files
ppLWED <- pp4 %>%
  filter(!str_detect(Locus, "SIMP"))
View(ppLWED)

ppSIMP <- pp4 %>%
  filter(!str_detect(Locus, "LWED"))
View(ppSIMP)

# Export
write.table(pp4, "primerProbeFile.txt", sep = "\t", row.names = F, quote = F)
write.table(ppLWED, "primerProbeFile_LWED.txt", sep = "\t", row.names = F, quote = F)
write.table(ppSIMP, "primerProbeFile_SIMP.txt", sep = "\t", row.names = F, quote = F)
```

# 6 Count reads for amplicons

Once the files are created, we can proceed with the first step in the GTscore pipeline - counting amplicon reads. We'll be doing doing this for the full set of data (all samples, all loci) as well as the species subsets of the data to allow for more accurate analyses of loci and sample performance.

## 6.1 Info on AmpliconReadCounter.pl

The read counter is written in perl (AmpliconReadCounter.pl), but can be called from R. Running it does the following:

1.  Identifies each unique sequence, then counts the number of times each unique sequence occurs within an individual

2.  Aligns each unique sequence with primer and probe; if the sequence doesn't align, then it is excluded as an off-target sequence and reports by individual and by locus are given.

-   Note: By default, all primers are trimmed to the length of the shortest primer to increase speed. Optionally the full length primer can be used for the primer but this may significantly increase run timing depending on variation in primer lengths across loci.

Input flags for this script are:

-   --p a tab delimited file containing primer/probe information for each locus
-   --files a text file containing a list of .fastq sequence files to count reads from

Optional flags:

-   --prefix optional prefix for output file names
-   --inDir option to specify directory containing sequence data
-   --inputType fq or fastqgz (defaults to fastqgz)
-   --useFullPrimer uses the full primer for counting reads rather than the trimmed primer
-   --alleleOrder order of alleles output in locusTable file. Options are original (matches primer-probe file order) or alphabetical (default)
-   --printMatched outputs matched reads for each individual
-   --printDiscarded outputs discarded reads for each individual

## 6.2 Run AmpliconReadCounterl.pl

To run from the command line, use: perl AmpliconReadCounter.pl -p primerProbeFile.txt --files sampleList.txt. To run from R, use the scripts below.

```{r count reads for amplicons, eval=FALSE}
# all samples, all loci (includes negatives)
system2("perl",
        args="./GTscore_sourceScripts/AmpliconReadCounter_modified.pl -p ./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_fullSet.txt --files ./00_tamRun1_optimization/03_run1GTscore/sampleFiles_fullSet.txt --inDir ./00_tamRun1_optimization/02_run1Interleaved/ --outDir ./00_tamRun1_optimization/03_run1GTscore/ --prefix fullSet_")

# pos samples (no negs), dual loci
system2("perl",
        args="./GTscore_sourceScripts/AmpliconReadCounter_modified.pl -p ./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_dual.txt --files ./00_tamRun1_optimization/03_run1GTscore/sampleFiles_pos.txt --inDir ./00_tamRun1_optimization/02_run1Interleaved/ --outDir ./00_tamRun1_optimization/03_run1GTscore/ --prefix posDual_")

# lwed samples, lwed + dual loci
system2("perl",
        args="./GTscore_sourceScripts/AmpliconReadCounter_modified.pl -p ./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_LWED.txt --files ./00_tamRun1_optimization/03_run1GTscore/sampleFiles_LWED.txt --inDir ./00_tamRun1_optimization/02_run1Interleaved/ --outDir ./00_tamRun1_optimization/03_run1GTscore/ --prefix LWED_")

# simp samples, simp + dual loci
system2("perl",
        args="./GTscore_sourceScripts/AmpliconReadCounter_modified.pl -p ./00_tamRun1_optimization/03_run1GTscore/primerProbeFile_SIMP.txt --files ./00_tamRun1_optimization/03_run1GTscore/sampleFiles_SIMP.txt --inDir ./00_tamRun1_optimization/02_run1Interleaved/ --outDir ./00_tamRun1_optimization/03_run1GTscore/ --prefix SIMP_")
```

AmpliconReadCounter.pl outputs a LocusTable file and an AlleleReads file for single-SNP and haplotype data, plus two summary files.

The default names for these files are as follows, with _LWED and _SIMP appended to files associated with species-specific analyses:

* LocusTable_singleSNPs.txt - locus name, ploidy, and alleles for each SNP
* AlleleReads_singleSNPs.txt - counts for each SNP allele (rows are loci, columns are individuals)
* LocusTable_haplotypes.txt - same as above (doesn't matter for us since we're only using single SNPs)
* AlleleReads_haplotypes.txt - same as above (doesn't matter for us since we're only using single SNPs)
* GTscore_individualSummary.txt - counts by individual of total reads, off-target reads, primer-only reads, and primer probe reads
* GTscore_locusSummary.txt - counts by locus of primer reads and primer probe reads

# 7 Genotyping

Genotyping is accomplished using the polyGen function. The genotyping algorithm is described in McKinney et al. 2018 and is a maximum likelihood algorithm capable of genotyping any number of alleles and ploidy per locus. This allows genoyping of single SNPs as well as microhaplotypes, and loci with elevated ploidy.

Two arguments are required for polyGen, the locusTable and alleleReads files output by AmpliconReadCounter.

Optional arguments for polyGen are:

* p_thresh  - threshold p-value for likelihood ratio test (default 0.05)
* epsilon   - error rate for genotyping model (default 0.01)

**NOTE** that only primer probe reads are used in genotyping!

Note also that GTscore doesn't have a coverage cutoff for genotyping - as such I'm running the genotyping function as-is plus again w/a 10x cutoff

## 7.1 0x cutoff

### Full set genos

```{r}
#load locus table and 0x allele reads file
fullSet_singleSNP_locusTable <- read.delim("./00_tamRun1_optimization/03_run1GTscore/fullSet_LocusTable_singleSNPs.txt", header = TRUE, stringsAsFactors = FALSE)

fullSet_singleSNP_alleleReads_0x <- read.delim("./00_tamRun1_optimization/03_run1GTscore/fullSet_AlleleReads_singleSNPs.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

#generate singleSNP genotypes using the polyGen algorithm, adjust "0" formatting
fullSet_polyGenResults_singleSNP_0x <- polyGen(fullSet_singleSNP_locusTable, fullSet_singleSNP_alleleReads_0x)

# write results
write.table(fullSet_polyGenResults_singleSNP_0x, "./00_tamRun1_optimization/03_run1GTscore/fullSet_polyGenResults_singleSNP_0x.txt", quote = FALSE, sep = "\t")
```

### Species subsets

#### pos samples only (no negs)

```{r Genotyping}
#load locus table and 10x allele reads file
posDual_singleSNP_locusTable <- read.delim("./00_tamRun1_optimization/03_run1GTscore/posDual_LocusTable_singleSNPs.txt", header = TRUE, stringsAsFactors = FALSE)

posDual_singleSNP_alleleReads_0x <- read.delim("./00_tamRun1_optimization/03_run1GTscore/posDual_AlleleReads_singleSNPs.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

#generate singleSNP genotypes using the polyGen algorithm
posDual_polyGenResults_singleSNP_0x <- polyGen(posDual_singleSNP_locusTable, posDual_singleSNP_alleleReads_0x)

#write results
write.table(posDual_polyGenResults_singleSNP_0x, "./00_tamRun1_optimization/03_run1GTscore/posDual_polyGenResults_singleSNP_0x.txt", quote = FALSE, sep = "\t")
```

#### LWED

```{r Genotyping}
#load locus table and 10x allele reads file
LWED_singleSNP_locusTable <- read.delim("./00_tamRun1_optimization/03_run1GTscore/LWED_LocusTable_singleSNPs.txt", header = TRUE, stringsAsFactors = FALSE)

LWED_singleSNP_alleleReads_0x <- read.delim("./00_tamRun1_optimization/03_run1GTscore/LWED_AlleleReads_singleSNPs.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

#generate singleSNP genotypes using the polyGen algorithm
LWED_polyGenResults_singleSNP_0x <- polyGen(LWED_singleSNP_locusTable, LWED_singleSNP_alleleReads_0x)

#write results
write.table(LWED_polyGenResults_singleSNP_0x, "./00_tamRun1_optimization/03_run1GTscore/LWED_polyGenResults_singleSNP_0x.txt", quote = FALSE, sep = "\t")
```

#### SIMP

```{r}
#load locus table and 10x allele reads file
SIMP_singleSNP_locusTable <- read.delim("./00_tamRun1_optimization/03_run1GTscore/SIMP_LocusTable_singleSNPs.txt", header = TRUE, stringsAsFactors = FALSE)

SIMP_singleSNP_alleleReads_0x <- read.delim("./00_tamRun1_optimization/03_run1GTscore/SIMP_AlleleReads_singleSNPs.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

#generate singleSNP genotypes using the polyGen algorithm
SIMP_polyGenResults_singleSNP_0x <- polyGen(SIMP_singleSNP_locusTable, SIMP_singleSNP_alleleReads_0x)

#write results
write.table(SIMP_polyGenResults_singleSNP_0x, "./00_tamRun1_optimization/03_run1GTscore/SIMP_polyGenResults_singleSNP_0x.txt", quote = FALSE, sep = "\t")
```

## 7.2 10x cutoff

### Recode loci \<10x coverage

Step 1: Recode loci with \<10x coverage in the full set of allele read counts

```{r}
# Read in allele counts for the full dataset
readCounts_original <- read.table("./00_tamRun1_optimization/03_run1GTscore/fullSet_AlleleReads_singleSNPs.txt")

# Create read counts copy for 10x coverage
readCounts10x <- readCounts_original

# Set up a function to sum the read counts per allele for each locus, using package gsubfn
repl <- function(x) gsubfn("(\\d+),(\\d+)", ~ as.numeric(x) + as.numeric(y), paste(x))

# Then apply the function to readCounts to sum each set of allele reads for each locus
readCounts_sum10x <- replace(readCounts10x, TRUE, lapply(readCounts10x, repl)) %>%
  mutate(across(everything(),as.numeric))

# Recode <10x loci with "0"
readCounts10x[readCounts_sum10x < 10] <- "0,0"
```

Step 2: Create lwed & simp subsets & create new AlleleReads_singleSNPs files

```{r}
# lwed and simp loci sets
lwed_loci <- read.delim("./00_tamRun1_optimization/03_run1GTscore/LWED_LocusTable_singleSNPs.txt", header = TRUE, stringsAsFactors = FALSE)

simp_loci <- read.delim("./00_tamRun1_optimization/03_run1GTscore/SIMP_LocusTable_singleSNPs.txt", header = TRUE, stringsAsFactors = FALSE)

readCounts10x_lwed <- readCounts10x %>%
  select(lwed$sampleID) %>%
  filter(rownames(.) %in% lwed_loci$Locus_ID)

readCounts10x_simp <- readCounts10x %>%
  select(simp$sampleID) %>%
  filter(rownames(.) %in% simp_loci$Locus_ID)

readCounts10x_posDual <- readCounts10x %>%
  select(colnames(posDual_singleSNP_alleleReads_0x)) %>%
  filter(rownames(.) %in% rownames(posDual_singleSNP_alleleReads_0x))
  
# Export new 10x AlleleReads_singleSNPs files
write.table(readCounts10x, "./00_tamRun1_optimization/03_run1GTscore/fullSet_AlleleReads_singleSNPs_10x.txt", quote = FALSE, sep = "\t")

write.table(readCounts10x_posDual, "./00_tamRun1_optimization/03_run1GTscore/posDual_AlleleReads_singleSNPs_10x.txt", quote = FALSE, sep = "\t")

write.table(readCounts10x_lwed, "./00_tamRun1_optimization/03_run1GTscore/LWED_AlleleReads_singleSNPs_10x.txt", quote = FALSE, sep = "\t")

write.table(readCounts10x_simp, "./00_tamRun1_optimization/03_run1GTscore/SIMP_AlleleReads_singleSNPs_10x.txt", quote = FALSE, sep = "\t")
```

Genotyping is accomplished using the polyGen function. The genotyping algorithm is described in McKinney et al. 2018 and is a maximum likelihood algorithm capable of genotyping any number of alleles and ploidy per locus. This allows genoyping of single SNPs as well as microhaplotypes, and loci with elevated ploidy.

Two arguments are required for polyGen, the locusTable and alleleReads files output by AmpliconReadCounter.

Optional arguments for polyGen are:

-   p_thresh - threshold p-value for likelihood ratio test (default 0.05)
-   epsilon - error rate for genotyping model (default 0.01)

**NOTE** that only primer probe reads are used in genotyping!

Note also that I'm making three genotype files, one for all loci vs. all samples and two species-specific sets - this allows our genotyping metrics to be more accurate.

### Full set genos

```{r}
#load locus table and 10x allele reads file
fullSet_singleSNP_locusTable <- read.delim("./00_tamRun1_optimization/03_run1GTscore/fullSet_LocusTable_singleSNPs.txt", header = TRUE, stringsAsFactors = FALSE)

fullSet_singleSNP_alleleReads_10x <- read.delim("./00_tamRun1_optimization/03_run1GTscore/fullSet_AlleleReads_singleSNPs_10x.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

#generate singleSNP genotypes using the polyGen algorithm, adjust "0" formatting
fullSet_polyGenResults_singleSNP_10x <- polyGen(fullSet_singleSNP_locusTable, fullSet_singleSNP_alleleReads_10x)

# write results
write.table(fullSet_polyGenResults_singleSNP_10x, "./00_tamRun1_optimization/03_run1GTscore/fullSet_polyGenResults_singleSNP_10x.txt", quote = FALSE, sep = "\t")
```

### Subsets

#### pos samples only

```{r Genotyping}
#load locus table and 10x allele reads file
posDual_singleSNP_locusTable <- read.delim("./00_tamRun1_optimization/03_run1GTscore/posDual_LocusTable_singleSNPs.txt", header = TRUE, stringsAsFactors = FALSE)

posDual_singleSNP_alleleReads_10x <- read.delim("./00_tamRun1_optimization/03_run1GTscore/posDual_AlleleReads_singleSNPs_10x.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

#generate singleSNP genotypes using the polyGen algorithm
posDual_polyGenResults_singleSNP_10x <- polyGen(posDual_singleSNP_locusTable, posDual_singleSNP_alleleReads_10x)

#write results
write.table(posDual_polyGenResults_singleSNP_10x, "./00_tamRun1_optimization/03_run1GTscore/posDual_polyGenResults_singleSNP_10x.txt", quote = FALSE, sep = "\t")
```

#### LWED

```{r Genotyping}
#load locus table and 10x allele reads file
LWED_singleSNP_locusTable <- read.delim("./00_tamRun1_optimization/03_run1GTscore/LWED_LocusTable_singleSNPs.txt", header = TRUE, stringsAsFactors = FALSE)

LWED_singleSNP_alleleReads_10x <- read.delim("./00_tamRun1_optimization/03_run1GTscore/LWED_AlleleReads_singleSNPs_10x.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

#generate singleSNP genotypes using the polyGen algorithm
LWED_polyGenResults_singleSNP_10x <- polyGen(LWED_singleSNP_locusTable, LWED_singleSNP_alleleReads_10x)

#write results
write.table(LWED_polyGenResults_singleSNP_10x, "./00_tamRun1_optimization/03_run1GTscore/LWED_polyGenResults_singleSNP_10x.txt", quote = FALSE, sep = "\t")
```

#### SIMP

```{r}
#load locus table and 10x allele reads file
SIMP_singleSNP_locusTable <- read.delim("./00_tamRun1_optimization/03_run1GTscore/SIMP_LocusTable_singleSNPs.txt", header = TRUE, stringsAsFactors = FALSE)

SIMP_singleSNP_alleleReads_10x <- read.delim("./00_tamRun1_optimization/03_run1GTscore/SIMP_AlleleReads_singleSNPs_10x.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

#generate singleSNP genotypes using the polyGen algorithm
SIMP_polyGenResults_singleSNP_10x <- polyGen(SIMP_singleSNP_locusTable, SIMP_singleSNP_alleleReads_10x)

#write results
write.table(SIMP_polyGenResults_singleSNP_10x,"./00_tamRun1_optimization/03_run1GTscore/SIMP_polyGenResults_singleSNP_10x.txt", quote = FALSE, sep = "\t")
```

# 8 Data summaries

## 8.1 Locus summaries

### Summarize single SNP results for loci

The summarizeGTscore command generates summary data for each locus in table form. The summary data includes genotype rate, average read depth, minor (least frequent) allele frequency, major (most frequent) allele frequency, alleles per locus, and frequency per allele. Minor allele frequency is a common metric for filtering loci that are likely to be uninformative for population genetics; however, loci with haplotype alleles may have an allele with very low frequency but still have appreciable frequency at multiple other alleles. Because of this, the major allele frequency is included in output, as well as the observed frequencies for all alleles at a given locus.

**gtscore0x**

```{r}
fullSet_singleSNP_alleleReads <- read.delim("./00_tamRun1_optimization/03_run1GTscore/fullSet_AlleleReads_singleSNPs.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

posDual_singleSNP_alleleReads <- read.delim("./00_tamRun1_optimization/03_run1GTscore/posDual_AlleleReads_singleSNPs.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

LWED_singleSNP_alleleReads <- read.delim("./00_tamRun1_optimization/03_run1GTscore/LWED_AlleleReads_singleSNPs.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

SIMP_singleSNP_alleleReads <- read.delim("./00_tamRun1_optimization/03_run1GTscore/SIMP_AlleleReads_singleSNPs.txt", header = TRUE, row.names = 1, stringsAsFactors = FALSE)

#summarize single SNP results
fullSet_singleSNP_summary_0x <- summarizeGTscore(fullSet_singleSNP_alleleReads, fullSet_singleSNP_locusTable, fullSet_polyGenResults_singleSNP_0x)

posDual_singleSNP_summary_0x <- summarizeGTscore(posDual_singleSNP_alleleReads, posDual_singleSNP_locusTable, posDual_polyGenResults_singleSNP_0x)

LWED_singleSNP_summary_0x <- summarizeGTscore(LWED_singleSNP_alleleReads, LWED_singleSNP_locusTable, LWED_polyGenResults_singleSNP_0x)

SIMP_singleSNP_summary_0x <- summarizeGTscore(SIMP_singleSNP_alleleReads, SIMP_singleSNP_locusTable, SIMP_polyGenResults_singleSNP_0x)

#write results
write.table(fullSet_singleSNP_summary_0x, "./00_tamRun1_optimization/03_run1GTscore/fullSet_singleSNP_summary_0x.txt", quote = FALSE, sep = "\t", row.names = FALSE)

write.table(posDual_singleSNP_summary_0x, "./00_tamRun1_optimization/03_run1GTscore/posDual_singleSNP_summary_0x.txt", quote = FALSE, sep = "\t", row.names = FALSE)

write.table(LWED_singleSNP_summary_0x, "./00_tamRun1_optimization/03_run1GTscore/LWED_singleSNP_summary_0x.txt", quote = FALSE, sep = "\t", row.names = FALSE)

write.table(SIMP_singleSNP_summary_0x, "./00_tamRun1_optimization/03_run1GTscore/SIMP_singleSNP_summary_0x.txt", quote = FALSE, sep = "\t", row.names = FALSE)
```

**gtscore10x**

```{r}
#summarize single SNP results
fullSet_singleSNP_summary_10x <- summarizeGTscore(fullSet_singleSNP_alleleReads, fullSet_singleSNP_locusTable, fullSet_polyGenResults_singleSNP_10x)

posDual_singleSNP_summary_10x <- summarizeGTscore(posDual_singleSNP_alleleReads, posDual_singleSNP_locusTable, posDual_polyGenResults_singleSNP_10x)

LWED_singleSNP_summary_10x <- summarizeGTscore(LWED_singleSNP_alleleReads, LWED_singleSNP_locusTable, LWED_polyGenResults_singleSNP_10x)

SIMP_singleSNP_summary_10x <- summarizeGTscore(SIMP_singleSNP_alleleReads, SIMP_singleSNP_locusTable, SIMP_polyGenResults_singleSNP_10x)

#write results
write.table(fullSet_singleSNP_summary_10x, "./00_tamRun1_optimization/03_run1GTscore/fullSet_singleSNP_summary_10x.txt", quote = FALSE, sep = "\t", row.names = FALSE)

write.table(posDual_singleSNP_summary_10x, "./00_tamRun1_optimization/03_run1GTscore/posDual_singleSNP_summary_10x.txt", quote = FALSE, sep = "\t", row.names = FALSE)

write.table(LWED_singleSNP_summary_10x, "./00_tamRun1_optimization/03_run1GTscore/LWED_singleSNP_summary_10x.txt", quote = FALSE, sep = "\t", row.names = FALSE)

write.table(SIMP_singleSNP_summary_10x, "./00_tamRun1_optimization/03_run1GTscore/SIMP_singleSNP_summary_10x.txt", quote = FALSE, sep = "\t", row.names = FALSE)
```

### Master locus summary

Generate locus summary files with single SNP summaries + GTscore locus summaries created earlier

```{r}
# per-locus read summaries
ls_posDual <- read.table("./00_tamRun1_optimization/03_run1GTscore/posDual_GTscore_locusSummary.txt", header = T, sep = "\t") %>%
  mutate(
    sampleSet = "posSamples"
  )

ls_lwed <- read.table("./00_tamRun1_optimization/03_run1GTscore/LWED_GTscore_locusSummary.txt", header = T, sep = "\t") %>%
  mutate(
    sampleSet = "lwedSamples"
  )

ls_simp <- read.table("./00_tamRun1_optimization/03_run1GTscore/SIMP_GTscore_locusSummary.txt", header = T, sep = "\t") %>%
  mutate(
    sampleSet = "simpSamples"
  )

# gtscore0x per-locus depth/geno/etc summaries
ss_posDual_0x <- posDual_singleSNP_summary_0x %>%
  mutate(
    sampleSet = "posSamples"
  )

ss_lwed_0x <- LWED_singleSNP_summary_0x %>%
  mutate(
    sampleSet = "lwedSamples"
  )

ss_simp_0x <- SIMP_singleSNP_summary_0x %>%
  mutate(
    sampleSet = "simpSamples"
  )

# gtscore10x per-locus depth/geno/etc summaries
ss_posDual_10x <- posDual_singleSNP_summary_10x %>%
  mutate(
    sampleSet = "posSamples"
  )

ss_lwed_10x <- LWED_singleSNP_summary_10x %>%
  mutate(
    sampleSet = "lwedSamples"
  )

ss_simp_10x <- SIMP_singleSNP_summary_10x %>%
  mutate(
    sampleSet = "simpSamples"
  )

# master summary
ls_combo <- rbind(ls_posDual, ls_lwed, ls_simp)
ss_combo_0x <- rbind(ss_posDual_0x, ss_lwed_0x, ss_simp_0x) %>%
  mutate(Locus_ID = sub('[_][^_]+$', '', Locus_ID))
ss_combo_10x <- rbind(ss_posDual_10x, ss_lwed_10x, ss_simp_10x) %>%
  mutate(Locus_ID = sub('[_][^_]+$', '', Locus_ID))

master_locusSummary <- ls_combo %>%
  merge(., ss_combo_0x, by.x = c("Locus", "sampleSet"), by.y = c("Locus_ID", "sampleSet")) %>%
  merge(., ss_combo_10x[, c("Locus_ID", "sampleSet", "GenotypeRate", "minAF", "majAF", "allFreqs", "conScore")], by.x = c("Locus", "sampleSet"), by.y = c("Locus_ID", "sampleSet"), suffixes = c("_0x", "_10x")) %>%
  mutate(
    metricUse = case_when(
      str_detect(Locus, "LWED") & sampleSet == "lwedSamples" ~ "for_panelMetrics",
      str_detect(Locus, "SIMP") & sampleSet == "simpSamples" ~ "for_panelMetrics",
      sampleSet == "posSamples" ~ "for_panelMetrics",
      .default = "for_spMetrics"
    )
  )

write.csv(master_locusSummary, "./00_tamRun1_optimization/03_run1GTscore/summaryFiles/master_locusSummary.csv", row.names = F)
```

### Plots

plot genotype rate

```{r locus genotype rate, warning=FALSE}
# gtscore0x
master_locusSummary %>%
  filter(metricUse == "for_panelMetrics") %>%
  ggplot() +
  geom_histogram(aes(x = GenotypeRate_0x), binwidth = 0.03) +
  xlim(-0.01,1.01) +
  labs(title = "GTscore 0x: Locus genotype rate",
       x = "Genotype rate",
       y="count") +
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

# gtscore10x
master_locusSummary %>%
  filter(metricUse == "for_panelMetrics") %>%
  ggplot() +
  geom_histogram(aes(x = GenotypeRate_10x), binwidth = 0.03) +
  xlim(-0.01,1.01) +
  labs(title = "GTscore 10x: Locus genotype rate",
       x = "Genotype rate",
       y="count") +
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```

plot average read depth for single SNP data

```{r locus read depth}
# gtscore0x/10x (avg read depth is sampe for both)
master_locusSummary %>%
  filter(metricUse == "for_panelMetrics") %>%
  ggplot() + 
  geom_histogram(aes(x = AvgReadDepth), binwidth = 1)+
  labs(title = "Average Read Depth per SNP",
       x = "Average Read Depth",
       y = "Count") +
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle=element_text(hjust = 0.5))
```

plot genotype rate relative to average depth

```{r locus genotype rate vs read depth}
# gtscore0x
master_locusSummary %>%
  filter(metricUse == "for_panelMetrics") %>%
  ggplot() + 
  geom_point(aes(x = AvgReadDepth,
                 y = GenotypeRate_0x)) +
  ylim(0, 1) +
  labs(title = "0x Genotype Rate vs Average Depth per SNP",
       x = "Average Depth",
       y = "Genotype Rate") +
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

# gtscore10x
master_locusSummary %>%
  filter(metricUse == "for_panelMetrics") %>%
  ggplot() + 
  geom_point(aes(x = AvgReadDepth,
                 y = GenotypeRate_10x)) +
  ylim(0, 1) +
  labs(title = "10x Genotype Rate vs Average Depth per SNP",
       x = "Average Depth",
       y = "Genotype Rate") +
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```

plot distribution of minor allele frequency

```{r histogram of MAF, warning=FALSE}
# gtscore0x
master_locusSummary %>%
  filter(metricUse == "for_panelMetrics") %>%
  ggplot() + 
  geom_histogram(aes(x = minAF_0x),
                 binwidth = 0.01)+
  labs(title = "0x Minor Allele Frequency Single SNP",
       x = "Minor Allele Frequency",
       y = "Count") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5))

# gtscore10x
master_locusSummary %>%
  filter(metricUse == "for_panelMetrics") %>%
  ggplot() + 
  geom_histogram(aes(x = minAF_10x),
                 binwidth = 0.01)+
  labs(title = "10x Minor Allele Frequency Single SNP",
       x = "Minor Allele Frequency",
       y = "Count") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5))
```

plot distribution of major allele frequency

```{r histogram of MajAF, warning=FALSE}
# gtscore0x
master_locusSummary %>%
  filter(metricUse == "for_panelMetrics") %>%
  ggplot() + 
  geom_histogram(aes(x = majAF_0x),
                 binwidth = 0.01)+
  labs(title = "0x Major Allele Frequency Single SNP",
       x = "Major Allele Frequency",
       y = "Count") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5))

# gtscore10x
master_locusSummary %>%
  filter(metricUse == "for_panelMetrics") %>%
  ggplot() + 
  geom_histogram(aes(x = majAF_10x),
                 binwidth = 0.01)+
  labs(title = "10x Major Allele Frequency Single SNP",
       x = "Major Allele Frequency",
       y = "Count") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5))
```

## 8.2 Sample summaries

### Summarize single SNP summaries for samples

**gtscore 0x**

```{r}
fullSet_singleSNP_sampleSummary_0x <- summarizeSamples(fullSet_polyGenResults_singleSNP_0x, fullSet_singleSNP_alleleReads_0x)

posDual_singleSNP_sampleSummary_0x <- summarizeSamples(posDual_polyGenResults_singleSNP_0x, posDual_singleSNP_alleleReads_0x)

LWED_singleSNP_sampleSummary_0x <- summarizeSamples(LWED_polyGenResults_singleSNP_0x, LWED_singleSNP_alleleReads_0x)

SIMP_singleSNP_sampleSummary_0x <- summarizeSamples(SIMP_polyGenResults_singleSNP_0x, SIMP_singleSNP_alleleReads_0x)

write.csv(fullSet_singleSNP_sampleSummary_0x, "./00_tamRun1_optimization/03_run1GTscore/fullSet_singleSNP_sampleSummary_0x.csv", row.names = F)

write.csv(posDual_singleSNP_sampleSummary_0x, "./00_tamRun1_optimization/03_run1GTscore/posDual_singleSNP_sampleSummary_0x.csv", row.names = F)

write.csv(LWED_singleSNP_sampleSummary_0x, "./00_tamRun1_optimization/03_run1GTscore/LWED_singleSNP_sampleSummary_0x.csv", row.names = F)

write.csv(SIMP_singleSNP_sampleSummary_0x, "./00_tamRun1_optimization/03_run1GTscore/SIMP_singleSNP_sampleSummary_0x.csv", row.names = F)
```

**gtscore 10x**

```{r}
fullSet_singleSNP_sampleSummary_10x <- summarizeSamples(fullSet_polyGenResults_singleSNP_10x, fullSet_singleSNP_alleleReads_10x)

posDual_singleSNP_sampleSummary_10x <- summarizeSamples(posDual_polyGenResults_singleSNP_10x, posDual_singleSNP_alleleReads_10x)

LWED_singleSNP_sampleSummary_10x <- summarizeSamples(LWED_polyGenResults_singleSNP_10x, LWED_singleSNP_alleleReads_10x)

SIMP_singleSNP_sampleSummary_10x <- summarizeSamples(SIMP_polyGenResults_singleSNP_10x, SIMP_singleSNP_alleleReads_10x)

write.csv(fullSet_singleSNP_sampleSummary_10x, "./00_tamRun1_optimization/03_run1GTscore/fullSet_singleSNP_sampleSummary_10x.csv", row.names = F)

write.csv(posDual_singleSNP_sampleSummary_10x, "./00_tamRun1_optimization/03_run1GTscore/posDual_singleSNP_sampleSummary_10x.csv", row.names = F)

write.csv(LWED_singleSNP_sampleSummary_10x, "./00_tamRun1_optimization/03_run1GTscore/LWED_singleSNP_sampleSummary_10x.csv", row.names = F)

write.csv(SIMP_singleSNP_sampleSummary_10x, "./00_tamRun1_optimization/03_run1GTscore/SIMP_singleSNP_sampleSummary_10x.csv", row.names = F)
```

### Master sample summary

Sample metrics for genotypes and such are based on species sample/loci sets -

-   LWED sample metrics are based on dual loci + lwed-specific loci
-   SIMP sample metrics are based on dual loci + simp-specific loci
-   negCtrl sample metrics are based on all loci

```{r}
# import individual summaries from AmpliconReadCounter.pl output
is_neg <- read.delim("./00_tamRun1_optimization/03_run1GTscore/fullSet_GTscore_individualSummary.txt", header = TRUE, stringsAsFactors = FALSE) %>%
  mutate(Sample = gsub("-", "\\.", Sample)) %>%
  filter(!Sample %in% lwed$sampleID) %>%
  filter(!Sample %in% simp$sampleID)

is_lwed <- read.delim("./00_tamRun1_optimization/03_run1GTscore/LWED_GTscore_individualSummary.txt", header = TRUE, stringsAsFactors = FALSE) %>%
  mutate(Sample = gsub("-", "\\.", Sample))

is_simp <- read.delim("./00_tamRun1_optimization/03_run1GTscore/SIMP_GTscore_individualSummary.txt", header = TRUE, stringsAsFactors = FALSE) %>%
  mutate(Sample = gsub("-", "\\.", Sample))

# gtscore0x sample summary (from above)
sampleSum_fullSet_0x <- fullSet_singleSNP_sampleSummary_0x %>%
  mutate(lociSet = "fullSet")

sampleSum_neg_0x <- sampleSum_fullSet_0x %>%
  filter(!sample %in% lwed$sampleID) %>%
  filter(!sample %in% simp$sampleID)

sampleSum_lwed_0x <- LWED_singleSNP_sampleSummary_0x %>%
  mutate(lociSet = "lwedSet")

sampleSum_simp_0x <- SIMP_singleSNP_sampleSummary_0x %>%
  mutate(lociSet = "simpSet")

# gtscore10x sample summary (from above)
sampleSum_fullSet_10x <- fullSet_singleSNP_sampleSummary_10x %>%
  mutate(lociSet = "fullSet")

sampleSum_neg_10x <- sampleSum_fullSet_10x %>%
  filter(!sample %in% lwed$sampleID) %>%
  filter(!sample %in% simp$sampleID)

sampleSum_lwed_10x <- LWED_singleSNP_sampleSummary_10x %>%
  mutate(lociSet = "lwedSet")

sampleSum_simp_10x <- SIMP_singleSNP_sampleSummary_10x %>%
  mutate(lociSet = "simpSet")

# combos
indSum_combo <- rbind(is_neg, is_lwed, is_simp) %>%
  arrange(Sample)

sampleSum_combo_0x <- sampleSum_neg_0x %>%
  rbind(sampleSum_lwed_0x, sampleSum_simp_0x) %>%
  arrange(sample)

sampleSum_combo_10x <- sampleSum_neg_10x %>%
  rbind(sampleSum_lwed_10x, sampleSum_simp_10x) %>%
  arrange(sample) %>%
  select(-lociSet)

# master summary
master_sampleSummary <- indSum_combo %>%
  merge(., sampleSum_combo_0x, by.x = "Sample", by.y = "sample") %>%
  merge(., sampleSum_combo_10x, by.x = "Sample", by.y = "sample", suffixes = c("_0x", "_10x")) %>%
  relocate(lociSet, .after = Sample) %>%
  dplyr::rename("sampleID" = "Sample") %>%
  # add metadata
  merge(., md[, c("sampleID", "sampleID_md")], by = "sampleID") %>%
  relocate(sampleID_md, .after = sampleID)

write.csv(master_sampleSummary, "./00_tamRun1_optimization/03_run1GTscore/summaryFiles/master_sampleSummary.csv", row.names = F)
```

### Plots

plot histogram of genotype rate

```{r histogram of genotype rate, warning=FALSE}
# gtscore0x
master_sampleSummary %>%
  ggplot() +
  geom_histogram(aes(x = GenotypeRate_0x), binwidth = 0.01) +
  xlim(-0.01, 1.01) +
  labs(title = "0x Sample Genotype Rate",
       x = "Genotype Rate",
       y = "Count") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

# gtscore10x
master_sampleSummary %>%
  ggplot() +
  geom_histogram(aes(x = GenotypeRate_10x), binwidth = 0.01) +
  xlim(-0.01, 1.01) +
  labs(title = "10x Sample Genotype Rate",
       x = "Genotype Rate",
       y = "Count") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```

plot histogram of heterozygosity

```{r histogram of heterozygosity, warning=FALSE}
# gtscore0x
master_sampleSummary %>%
  ggplot() +
  geom_histogram(aes(x = Heterozygosity_0x), binwidth = 0.03) + 
  xlim(-0.01, 1.01)+
  labs(title = "0x Sample Heterozygosity",
       x = "Heterozygosity",
       y = "Count")+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle=element_text(hjust = 0.5))

# gtscore10x
master_sampleSummary %>%
  ggplot() +
  geom_histogram(aes(x = Heterozygosity_10x), binwidth = 0.03) + 
  xlim(-0.01, 1.01)+
  labs(title = "10x Sample Heterozygosity",
       x = "Heterozygosity",
       y = "Count")+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle=element_text(hjust = 0.5))
```

plot genotype rate vs primer probe reads

```{r genotype rate vs primer probe reads}
#dashed line added at 90% genotype rate, this is not a strict threshold, just a goal to aim for

# gtscore0x
master_sampleSummary %>%
  separate(sampleID_md, into = c("id", "species", "animalID", "sampleType"), sep = "_") %>%
  ggplot(aes(x = Primer.Probe.Reads,
             y = GenotypeRate_0x,
             color = sampleType)) +
  geom_point(stat = "identity") +
  geom_smooth(method = "loess") +
  labs(title = "0x Genotype Rate vs Total Reads per Sample",
       x = "Primer Probe Reads",
       y = "Genotype Rate")+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  geom_hline(yintercept = 0.9, lty = "dashed")

# gtscore10x
master_sampleSummary %>%
  separate(sampleID_md, into = c("id", "species", "animalID", "sampleType"), sep = "_") %>%
  ggplot(aes(x = Primer.Probe.Reads,
             y = GenotypeRate_10x,
             color = sampleType)) +
  geom_point(stat = "identity") +
  geom_smooth(method = "loess") +
  labs(title = "10x Genotype Rate vs Total Reads per Sample",
       x = "Primer Probe Reads",
       y = "Genotype Rate")+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  geom_hline(yintercept = 0.9, lty = "dashed")
```

Samples with unusually high heterozygosity may be contaminated or have elevated ploidy. [[Given chimerism, however, this isn't super helpful for blood samples]]

plot heterozygosity vs primer probe reads

```{r heterozygosity vs primer probe reads}
# gtscore0x
master_sampleSummary %>%
  separate(sampleID_md, into = c("id", "species", "animalID", "sampleType"), sep = "_") %>%
  ggplot() +
  geom_point(aes(x = Primer.Probe.Reads,
                 y = Heterozygosity_0x,
                 color = sampleType))+
  labs(title = "0x Heterozygosity vs Total Reads per Sample",
       x = "Primer Probe Reads",
       y = "Heterozygosity")+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))+
  geom_hline(yintercept = 0.3, lty = "dashed")

# gtscore10x
master_sampleSummary %>%
  separate(sampleID_md, into = c("id", "species", "animalID", "sampleType"), sep = "_") %>%
  ggplot() +
  geom_point(aes(x = Primer.Probe.Reads,
                 y = Heterozygosity_10x,
                 color = sampleType))+
  labs(title = "10x Heterozygosity vs Total Reads per Sample",
       x = "Primer Probe Reads",
       y = "Heterozygosity")+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))+
  geom_hline(yintercept = 0.3, lty = "dashed")
```

## 5) Quality control
#### Identify duplicate samples

The IDduplicateSamples function does all pairwise comparisons of samples and outputs two metrics:

* proportionCommon - The proportion of loci that had genotypes for both samples in a pair 
* proportionMatch  - The proportion of loci that have identical genotypes in the sample pair

```{r identify duplicate samples,eval=FALSE}
#convert missing genotypes "0" to NA
polyGenResults_singleSNP_NA<-polyGenResults_singleSNP
polyGenResults_singleSNP_NA[polyGenResults_singleSNP_NA=="0"]<-NA

#compare all samples, for each comparison get proportion of loci that have genotypes
#in both samples (proportionCommon) and proportion of shared loci that have identical
#genotypes (proportionMatch).
#Samples with a high proportionCommon and high proportionMatch are likely duplicates
polyGenResults_dupTest<-IDduplicateSamples(polyGenResults_singleSNP_NA)

write.table(polyGenResults_dupTest,"polyGenResults_dupTest.txt",quote=FALSE,sep="\t",row.names=FALSE)

```

```{r duplicate sample results}
polyGenResults_dupTest<-read.delim("polyGenResults_dupTest.txt",stringsAsFactors=FALSE)
head(polyGenResults_dupTest)
```
polyGenResults_dupTest

Plot results of IDduplicateSamples

McKinney says that he generally sets thresholds of proportionMatch > 0.8 and proportionCommon > 0.75 to identify duplicate sample pairs, but the appropriate thresholds will depend on the marker set being used and the relatedness among samples. In this plot, he notes that it is possible that individuals at the lower range of identical genotypes (~0.85) are relatives rather than duplicated samples.

```{r plot IDduplicateSamples results}
#potential duplicates are proportionMatch>0.8 and proportionCommon>0.75
#feel free to adjust these thresholds as needed
matchThresh=0.8
commonThresh=0 #switched to 0, looks like some loci were successfully genotyped for one sample and some for the other

#plot results
ggplot()+geom_point(data=polyGenResults_dupTest,aes(x=proportionCommon,y=proportionMatch))+
  geom_segment(aes(x=commonThresh,xend=1,y=matchThresh,yend=matchThresh),lty="dashed")+
  geom_segment(aes(x=commonThresh,xend=commonThresh,y=matchThresh,yend=1),lty="dashed")
```

Identify duplicate sample pairs with thresholds set previously
```{r}
#filter to potentially duplicated samples using thresholds above
polyGenResults_dupTest %>% filter(proportionMatch>=matchThresh,proportionCommon>=commonThresh)

```

1-29 YES
2-30 YES
3-31 YES
5-27 YES
5-33 YES
6-17 NO (but in same group)
6-28 YES
6-34 YES
17-19 NO (but in same group)
17-28 NO (but in same group)

Note that the three that aren NOT actually duplicates have the lowest proportion matched (0.86-0.83)

#### Identify contaminated samples

Contaminated samples can be identified through elevated heterozygosity. NOTE- this isn't going to be helpful for us given the blood chimerism.

```{r identify contaminated samples (heterozygosity)}
#plot heterozygosity vs genotype rate per sample
#samples with unusually high heterozygosity relative to others are candidates for contamination
#the sample above the dashed line in this example is likely contaminated
ggplot()+geom_point(data=GTscore_individualSummary,aes(x=GenotypeRate,y=Heterozygosity))+
  labs(title="Heterozygosity vs Genotype Rate per Sample", x="Genotype Rate", y="Heterozygosity")+
  theme_bw()+theme(plot.title=element_text(hjust=0.5),plot.subtitle=element_text(hjust=0.5))+
  geom_hline(yintercept=0.30, lty="dashed")
```

Set heterozygosity treshold to identify likely contaminated sample
```{r}
#identify likely contaminated sample
contaminatedSample<-GTscore_individualSummary %>% filter(Heterozygosity>0.30) %>% pull(Sample)
contaminatedSample
```

Contaminated samples can also be identified by an elevated contamination score.  In this example, samples with a contamination score > 0.3 are known to be contaminated.
```{r }
#plot histogram of contamination score
ggplot()+geom_histogram(data=GTscore_individualSummary,aes(x=conScore),binwidth=0.02)+geom_vline(xintercept=0.3,lty="dashed")

```

Set contamination score treshold to identify contaminated samples
```{r}
#identify likely contaminated samples
contaminatedSamples2<-GTscore_individualSummary %>% filter(conScore>=0.3) %>% pull(Sample)
contaminatedSamples2
```


Plot genotype scatterplots for each sample
```{r}
#Scatter Plots can show evidence of contamination or elevated ploidy
plotGenotypes_sample(singleSNP_locusTable, singleSNP_alleleReads, polyGenResults_singleSNP, type='scatter', savePlot="Y", saveDir="scatterPlots_sample")
#look at plots for samples, particularly for putatively contaminated samples identified by high heterozygosity
```

```{r,echo = FALSE}
library(knitr)
```

#### Identify poor quality loci to remove

Flag SNPs with < 50% genotype rate as candidates for removal. Will need to do this with LWED and SIMP samples separately, then recombine. 
```{r}
poorQualitySNPs <- singleSNP_summary %>% filter(GenotypeRate<0.5) %>% mutate(Locus_ID=as.character(Locus_ID)) %>% pull(Locus_ID)

poorQualitySNPs_LWED <- singleSNP_summary_LWED %>% filter(GenotypeRate<0.5) %>% mutate(Locus_ID=as.character(Locus_ID)) %>% pull(Locus_ID)

poorQualitySNPs_SIMP <- singleSNP_summary_SIMP %>% filter(GenotypeRate<0.5) %>% mutate(Locus_ID=as.character(Locus_ID)) %>% pull(Locus_ID)

pq_lwed <- data.frame(name=poorQualitySNPs_LWED) %>%
  mutate(species="LWED")
pq_simp<- data.frame(name=poorQualitySNPs_SIMP) %>%
  mutate(species="SIMP")

pq_both <- rbind(pq_lwed, pq_simp)
View(pq_both)

pq_both2 <- pq_both %>%
  group_by(name) %>%
  mutate(count=n()) %>%
  distinct(name, .keep_all = T) %>%
  within(species[count == '2'] <- "both")
View(pq_both2)

# Export file
write.csv(pq_both2, "./summaryFiles/poorQualitySNPs_combined.csv", row.names = F)
```

#### plots
Ratio & Scatter Plots can show evidence of systemic issues in read counting (off-target reads, biases) or elevated ploidy

Plot genotype ratio & scatterplots for each locus
```{r}
#Allele Ratio Plots  
plotGenotypes(singleSNP_locusTable, singleSNP_alleleReads, polyGenResults_singleSNP, type='ratio', savePlot="Y", saveDir="ratioPlots_loci")
#Scatter Plots 
plotGenotypes(singleSNP_locusTable, singleSNP_alleleReads, polyGenResults_singleSNP, type='scatter', savePlot="Y", saveDir="scatterPlots_loci")
```


Plot histogram of contamination score for loci. An arbitrary score of 0.3 was set to identify problematic loci, but a lower or higher threshold may be more suitable.  Visual examination of loci with elevated scores is recommended.  In cases where there are very few heterozygous individuals, a high contamination score may be not truly reflect locus performance..
```{r, warning=FALSE}
#loci with high contamination scores should have scatterplots examined to ensure genotypes look accurate
singleSNP_summary %>% ggplot(data=.) + geom_histogram(aes(x=conScore),binwidth=0.01)+geom_vline(xintercept=0.3)
```

Plot contamination score vs minor allele frequency.  Loci with both a high contamination score and high minor allele frequency are likely to be problematic.
```{r, warning=FALSE}
singleSNP_summary %>% ggplot(data=.) + geom_point(aes(x=conScore,y=minAF))
```

Get list of loci with high contamination score
```{r}
singleSNP_summary %>% filter(conScore>0.3)
```
Look at scatterplots for loci with high contamination score. See orignal GTscore README.Rmd for examples of a paralog, locus w/likely off-target sequence, locus w/high contamination score but may be fine. 

## 6) Export genotype files (unfiltered & filtered)
When exporting files, you can either export the full results and remove any poor quality samples or loci afterwards, or you can use whitelists or blacklists to filter during export.  Both the exportGenepop and exportRubias functions have the following options: sampleWhitelist, locusWhitelist, sampleBlacklist, locusBlacklist.  The whitelists are a list of samples or loci to retain, the blacklists are lists of samples or loci to discard.

#### Genepop format

export genepop format - no filtering
```{r}
#export genepop, no filtering
exportGenepop(polyGenResults_singleSNP,singleSNP_locusTable,filename="polyGenResults_singleSNP_genepop.txt")
exportGenepop(polyGenResults_singleSNP_LWED,singleSNP_locusTable_LWED,filename="polyGenResults_singleSNP_genepop_LWED.txt")
exportGenepop(polyGenResults_singleSNP_SIMP,singleSNP_locusTable_SIMP,filename="polyGenResults_singleSNP_genepop_SIMP.txt")
```

export genepop format - poor quality loci removed
```{r}
#example with poor quality loci and contaminated sample removed
exportGenepop(polyGenResults_singleSNP,singleSNP_locusTable,
              locusBlacklist=poorQualitySNPs,
              filename="polyGenResults_singleSNP_genepop_filtered.txt")
exportGenepop(polyGenResults_singleSNP_LWED,singleSNP_locusTable_LWED,
              locusBlacklist=poorQualitySNPs_LWED,
              filename="polyGenResults_singleSNP_genepop_filtered_LWED.txt")
exportGenepop(polyGenResults_singleSNP_SIMP,singleSNP_locusTable_SIMP,
              locusBlacklist=poorQualitySNPs_SIMP,
              filename="polyGenResults_singleSNP_genepop_filtered_SIMP.txt")
```

#### Rubias format
Data output for Rubias should have metadata associated with each sample that specifies the sample type, mixture if a mixture sample, reference if a baseline sample, the reporting group, the sample collection, and individual name.

Sample metadata columns should have the following names: sample_type, repunit, collection, indiv

metadata can be created here or loaded from file

create sample metadata for mixture sample
```{r}
#load sample data file
sampleMetaData<-read.delim("sampleMetaData.csv",header=TRUE, sep = ",")
#adjust indiv names in metadata (some of the GTscore functions change - to .)
sampleMetaData$indiv <- sub('tamOpt-', 'tamOpt.', sampleMetaData$indiv)
#view
View(sampleMetaData)
```


export Rubias format with no filtering
```{r}
#export rubias format
exportRubias(polyGenResults_singleSNP,singleSNP_locusTable,sampleMetaData,filename="polyGenResults_singleSNP_rubias.txt")
exportRubias(polyGenResults_singleSNP_LWED,singleSNP_locusTable_LWED,sampleMetaData,filename="polyGenResults_singleSNP_rubias_LWED.txt")
exportRubias(polyGenResults_singleSNP_SIMP,singleSNP_locusTable_SIMP,sampleMetaData,filename="polyGenResults_singleSNP_rubias_SIMP.txt")
```

export Rubias format with poor quality loci and contaminated sample removed
```{r}
exportRubias(polyGenResults_singleSNP,singleSNP_locusTable,sampleMetaData,
             locusBlacklist=poorQualitySNPs,
             filename="polyGenResults_singleSNP_rubias_filtered.txt")
exportRubias(polyGenResults_singleSNP_LWED,singleSNP_locusTable_LWED,sampleMetaData,
             locusBlacklist=poorQualitySNPs_LWED,
             filename="polyGenResults_singleSNP_rubias_filtered_LWED.txt")
exportRubias(polyGenResults_singleSNP_SIMP,singleSNP_locusTable_SIMP,sampleMetaData,
             locusBlacklist=poorQualitySNPs_SIMP,
             filename="polyGenResults_singleSNP_rubias_filtered_SIMP.txt")
```

## 7) Locus diagnostics
Diagnostic functions are provided to help in identifying patterns of sequence variation for loci.  This can assist in identifying SNPs that were not accounted for in the initial probe design and in adjusting the in-silico probes to exclude off-target sequence from genotyping.  

There are two approaches used by GTscore: First, plotting the number of nucleotide mismatches by position in the sequence data relative to the reference sequence for each locus, and second, performing sequence alignments using the program MSA (Bodenhofer et al. 2015).  Plotting the mismatches by position is fast and easy to interpret except in the case of indels.  The MSA alignments take longer to complete but facilitate the visualization of indels.

The first step for both methods is to get the sequences that aligned to each locus, this can be done based on primer alignments or primer-probe alignments using the script matchReads.pl.

### Sequence alignment to each locus (Perl)
Input flags for this script are:
* p    a tab delimited file containing primer/probe information for each locus
* --files  a text file containing a list of .fastq sequence files to count reads from
* --matchType the match type chosen for retaining sequences for each locus. Options are primer to retain sequences that match the primer for a locus or primerProbe to retain sequences that match both the primer and probe.  primerProbe is the default if no option is specified.

Optional flags:
* --prefix  optional prefix for output file names

You can run matchReads.pl from the command line using the following example:
perl matchReads.pl -p primerProbeFile.txt --files sampleFiles.txt --matchType primerProbe [--prefix]

Alternatively, you can also run it through R:
```{r match reads, eval=FALSE}
#primer match
system2("perl",
        args="matchReads.pl -p primerProbeFile.txt --files sampleFiles.txt --matchType primer")
system2("perl",
        args="matchReads.pl -p primerProbeFile.txt --files sampleFiles_LWED.txt --matchType primer --prefix LWED_")
system2("perl",
        args="matchReads.pl -p primerProbeFile.txt --files sampleFiles_SIMP.txt --matchType primer --prefix SIMP_")

#primer AND probe match
system2("perl",
        args="matchReads.pl -p primerProbeFile.txt --files sampleFiles.txt --matchType primerProbe")
system2("perl",
        args="matchReads.pl -p primerProbeFile.txt --files sampleFiles_LWED.txt --matchType primerProbe --prefix LWED_")
system2("perl",
        args="matchReads.pl -p primerProbeFile.txt --files sampleFiles_SIMP.txt --matchType primerProbe --prefix SIMP_")
```

The default output file names are matchReads_primerAligned.txt or matchReads_primerProbeAligned.txt depending on which match type was chosen.

### Create reference amplicon sequences file
To conduct locus diagnostics, we need both a text file and fasta file of reference amplicon sequences. The sequences are already in Sam's pos_amplicon.csv file, we just need to get it in the right format:

Text file first:
```{r create reference sequences file}
# Packages
library(Biostrings)
library(tidyverse)

# Import data
amplicon_csv <- read.csv("pos_amplicon.csv", sep = ",")
View(amplicon_csv)
translation <- read.csv("primers_seqName_to_shortName.csv")
View(translation)

# Subset to get names and amplicon sequences only & remove brackets
amplicons <- amplicon_csv %>%
  select(c("SNP_name", "amplicon")) %>%
  mutate(amplicon = str_replace_all(amplicon, "\\[|\\]", ""))
View(amplicons)

# Add short names to to amplicon seqs
amplicons_shortnames <- merge(amplicons, translation, by.x = "SNP_name", by.y = "seqID1") %>%
  select(c("primerName2", "amplicon")) %>%
  dplyr::rename(Locus=primerName2, refSeq=amplicon)
View(amplicons_shortnames)
length(amplicons_shortnames$Locus) #226 - good!

# Create LWED and SIMP subsets
amplicons_lwed <- amplicons_shortnames %>%
  filter(!str_detect(Locus, "SIMP"))

amplicons_simp <- amplicons_shortnames %>%
  filter(!str_detect(Locus, "LWED"))


# Export
write.table(amplicons_shortnames, "./ampliconRefSeqs.txt", sep= "\t", row.names = F, quote = F)
write.table(amplicons_lwed, "./ampliconRefSeqs_LWED.txt", sep= "\t", row.names = F, quote = F)
write.table(amplicons_simp, "./ampliconRefSeqs_SIMP.txt", sep= "\t", row.names = F, quote = F)
```

Then fasta file:
```{r create amplicon fasta file}
library(phylotools)

amplicon_txt <- read.table("ampliconRefSeqs.txt", header = T) %>%
  dplyr::rename(c(seq.name=Locus, seq.text=refSeq))
View(amplicon_txt)

dat2fasta(amplicon_txt, outfile = "ampliconRefSeqs.fasta")

amplicon_txt_lwed <- read.table("ampliconRefSeqs_LWED.txt", header = T) %>%
  dplyr::rename(c(seq.name=Locus, seq.text=refSeq))
View(amplicon_txt_lwed)

dat2fasta(amplicon_txt_lwed, outfile = "ampliconRefSeqs_LWED.fasta")

amplicon_txt_simp <- read.table("ampliconRefSeqs_SIMP.txt", header = T) %>%
  dplyr::rename(c(seq.name=Locus, seq.text=refSeq))
View(amplicon_txt_simp)

dat2fasta(amplicon_txt_simp, outfile = "ampliconRefSeqs_SIMP.fasta")
```

### MSA alignment (GTscore.R)
MSA alignment of the matched reads can be done directly on the output from matchReads.pl using the alignMatchedSeqs command in GTscore. Probe sequence is incorporated into the alignment to visualize how probes may be affecting read counting, and reference sequence can optionally be included to facilitate comparison of the observed sequence with the target locus. The probe sequence is obtained from the primer-probe file originally used by AmpliconReadCounter.pl; the reference sequence file has a two column format where the first column is the locus name and the second column is the reference sequence for the locus amplicon. MSA will take a very long time to run if too many sequences are included for alignment so a minimum read threshold (minReads) is included as an option in the alignment command (suggest begin with minReads=20). In addition, a maximum of 100 unique sequences (ranked by number of reads) will be aligned.  The maximum number of reads allowed for alignment can be changed using the maxAlignedSeqs option. Be sure the required perl package has been installed (Excel-Writer-XLSX).

```{r MSA alignment}
#load reference sequences in table format
referenceSeqs<-read.delim("ampliconRefSeqs.txt", header=TRUE, stringsAsFactors=FALSE )
referenceSeqs_LWED<-read.delim("ampliconRefSeqs_LWED.txt", header=TRUE, stringsAsFactors=FALSE )
referenceSeqs_SIMP<-read.delim("ampliconRefSeqs_SIMP.txt", header=TRUE, stringsAsFactors=FALSE )
View(referenceSeqs)
length(referenceSeqs$Locus)

#load primer probe file
primerProbes<-read.delim("primerProbeFile.txt", header=TRUE, stringsAsFactors=FALSE)
primerProbes_LWED<-read.delim("primerProbeFile_LWED.txt", header=TRUE, stringsAsFactors=FALSE)
primerProbes_SIMP<-read.delim("primerProbeFile_SIMP.txt", header=TRUE, stringsAsFactors=FALSE)
View(primerProbes)
length(primerProbes$Locus)

#primer aligned reads
primerMatchedReads<-read.delim("matchedReads_primerAligned.txt", header=TRUE, stringsAsFactors=FALSE)
View(primerMatchedReads)
alignMatchedSeqs(referenceSeqs=referenceSeqs,primerProbes=primerProbes,matchedReads=primerMatchedReads,minReads=20, maxAlignedSeqs=100,type="primer",saveDir="MSA_primerMatched")

primerMatchedReads_LWED<-read.delim("LWED_matchedReads_primerAligned.txt", header=TRUE, stringsAsFactors=FALSE)
View(primerMatchedReads_LWED)
alignMatchedSeqs(referenceSeqs=referenceSeqs_LWED,primerProbes=primerProbes_LWED,matchedReads=primerMatchedReads_LWED,minReads=20, maxAlignedSeqs=100,type="primer",saveDir="MSA_primerMatched_LWED")

primerMatchedReads_SIMP<-read.delim("SIMP_matchedReads_primerAligned.txt", header=TRUE, stringsAsFactors=FALSE)
View(primerMatchedReads_SIMP)
alignMatchedSeqs(referenceSeqs=referenceSeqs_SIMP,primerProbes=primerProbes_SIMP,matchedReads=primerMatchedReads_SIMP,minReads=20, maxAlignedSeqs=100,type="primer",saveDir="MSA_primerMatched_SIMP")

#primer probe aligned reads
primerProbeMatchedReads<-read.delim("matchedReads_primerProbeAligned.txt", header=TRUE, stringsAsFactors=FALSE)
alignMatchedSeqs(referenceSeqs=referenceSeqs, primerProbes=primerProbes, matchedReads=primerProbeMatchedReads,minReads=20, maxAlignedSeqs=100,type="primerProbe",saveDir="MSA_primerProbeMatched")

primerProbeMatchedReads_LWED<-read.delim("LWED_matchedReads_primerProbeAligned.txt", header=TRUE, stringsAsFactors=FALSE)
alignMatchedSeqs(referenceSeqs=referenceSeqs_LWED, primerProbes=primerProbes_LWED, matchedReads=primerProbeMatchedReads_LWED,minReads=20, maxAlignedSeqs=100,type="primerProbe",saveDir="MSA_primerProbeMatched_LWED")

primerProbeMatchedReads_SIMP<-read.delim("SIMP_matchedReads_primerProbeAligned.txt", header=TRUE, stringsAsFactors=FALSE)
alignMatchedSeqs(referenceSeqs=referenceSeqs_SIMP, primerProbes=primerProbes_SIMP, matchedReads=primerProbeMatchedReads_SIMP,minReads=20, maxAlignedSeqs=100,type="primerProbe",saveDir="MSA_primerProbeMatched_SIMP")
```

Excel files are output for each locus within the directory specified by savDir. The first row is a consensus sequence based on the sequence alignments. This is followed by the probes, reference sequence if included, and then the sequence alignments.


### Plotting mismatches by position (Perl and GTscore.R)
#### Calculate sequence mismatches by position (Perl)
Plotting the number of mismatches by position requires first comparing each matched sequence against the reference sequence and summing the number of mismatches for each nucleotide position.  This is done with the perl script seqMismatchPositions.pl.  

Input flags for this script are 
* --amplicon    a fasta file containing the reference amplicon sequence for each locus
* --matchedSeqs  a tab delimited file containing sequences that matched each locus.  This file is generated by matchReads.pl
* --matchType the match type chosen for retaining sequences for each locus.  Options are primer to retain sequences that match the primer for a locus or primerProbe to retain sequences that match both the primer and probe.  primerProbe is the default if no option is specified.

Optional flags
* --prefix  optional prefix for output file names

You can run matchReads.pl from the command line using the following example:
perl seqMismatchPositions.pl --amplicon ampliconRefSeqs.fasta --matchedSeqs matchedReads_primerAligned.txt  --matchType primer [--prefix]

Alternatively, you can also run it through R:
```{r sequence mismatches, eval=FALSE}
# Combined
system2("perl",
        args="seqMismatchPositions.pl --amplicon ampliconRefSeqs.fasta --matchedSeqs matchedReads_primerAligned.txt --matchType primer")
system2("perl",
        args="seqMismatchPositions.pl --amplicon ampliconRefSeqs.fasta --matchedSeqs matchedReads_primerProbeAligned.txt --matchType primerProbe")

# LWED
system2("perl",
        args="seqMismatchPositions.pl --amplicon ampliconRefSeqs_LWED.fasta --matchedSeqs LWED_matchedReads_primerAligned.txt --matchType primer --prefix LWED_")
system2("perl",
        args="seqMismatchPositions.pl --amplicon ampliconRefSeqs_LWED.fasta --matchedSeqs LWED_matchedReads_primerProbeAligned.txt --matchType primerProbe --prefix LWED_")

# SIMP
system2("perl",
        args="seqMismatchPositions.pl --amplicon ampliconRefSeqs_SIMP.fasta --matchedSeqs SIMP_matchedReads_primerAligned.txt --matchType primer --prefix SIMP_")
system2("perl",
        args="seqMismatchPositions.pl --amplicon ampliconRefSeqs_SIMP.fasta --matchedSeqs SIMP_matchedReads_primerProbeAligned.txt --matchType primerProbe --prefix SIMP_")
```
The default output file names are mismatchPositions_primer.txt or mismatchPositions_primerProbe.txt depending on which match type was chosen.  The output files will be used by the summarizeMismatches function in GTscore to generate plots of mismatches by position for each locus.

#### Plot of sequence mismatches by position (GTscore.R)
```{r}
#load results from seqMismatchPositions.pl
#primer matched sequences
mismatchPositionData_primer<-read.delim("mismatchPositions_primer.txt", header=TRUE, stringsAsFactors=FALSE)
mismatchPositionData_primer_LWED<-read.delim("mismatchPositions_LWED_primer.txt", header=TRUE, stringsAsFactors=FALSE)
mismatchPositionData_primer_SIMP<-read.delim("mismatchPositions_SIMP_primer.txt", header=TRUE, stringsAsFactors=FALSE)
#primer probe matched sequences
mismatchPositionData_primerProbe<-read.delim("mismatchPositions_primerProbe.txt", header=TRUE, stringsAsFactors=FALSE)
mismatchPositionData_primerProbe_LWED<-read.delim("mismatchPositions_LWED_primerProbe.txt", header=TRUE, stringsAsFactors=FALSE)
mismatchPositionData_primerProbe_SIMP<-read.delim("mismatchPositions_SIMP_primerProbe.txt", header=TRUE, stringsAsFactors=FALSE)


#generate plots of mismatches by position
#primer matched sequences
summarizeMismatches(mismatchPositionData_primer,saveDir="mismatchPositionPlots_primer")
summarizeMismatches(mismatchPositionData_primer_LWED,saveDir="mismatchPositionPlots_primer_LWED")
summarizeMismatches(mismatchPositionData_primer_SIMP,saveDir="mismatchPositionPlots_primer_SIMP")
#primer probe matched sequences
summarizeMismatches(mismatchPositionData_primerProbe,saveDir="mismatchPositionPlots_primerProbe")
summarizeMismatches(mismatchPositionData_primerProbe_LWED,saveDir="mismatchPositionPlots_primerProbe_LWED")
summarizeMismatches(mismatchPositionData_primerProbe_SIMP,saveDir="mismatchPositionPlots_primerProbe_SIMP")
```

## 8) FILTERED analysis & summaries

Need to remove:
1) underperforming loci
2) underperforming samples

First, we'll make new sampleFiles.txt and primerProbes.txt by filtering out 1) underperforming samples and 2) underperforming loci based on that analyses performed earlier. We'll first set a cutoff of 2000 total primer-probe reads per sample, which leaves us with 28 samples.

For the loci, we'll set a cut-off of 280 total primer-probe reads since we want at least 10x coverage per sample. Note that because our read counts at present include those from the samples we cut, we may miss some loci that should be cut (particularly those with just above 280 reads) - this is also why we're not using avg read depth as a cutoff at this point. We'll look at total read count per loci again after re-running the analyses.
```{r}
# Filter samples by removing those with under 2000 reads (each species set has a little over 200 loci, 200 * 10x coverage = 2000)
sampleFiles <- read.table("sampleFiles.txt", header = F)
sampleFiles_LWED <- read.table("sampleFiles_LWED.txt", header = F)
sampleFiles_SIMP <- read.table("sampleFiles_SIMP.txt", header = F)
failedSamples <- c("tamOpt-004_S4_L001_interleaved.fastq","tamOpt-007_S7_L001_interleaved.fastq","tamOpt-022_S25_L001_interleaved.fastq","tamOpt-025_S16_L001_interleaved.fastq","tamOpt-035_S33_L001_interleaved.fastq")

sampleFiles_filtered <- sampleFiles %>%
  filter(!V1 %in% failedSamples)
View(sampleFiles_filtered)

sampleFiles_filtered_LWED <- sampleFiles_LWED %>%
  filter(!V1 %in% failedSamples)
sampleFiles_filtered_SIMP <- sampleFiles_SIMP %>%
  filter(!V1 %in% failedSamples)

# Export
write.table(sampleFiles_filtered, "f_sampleFiles.txt", col.names = F, row.names = F, quote = F)
write.table(sampleFiles_filtered_LWED, "f_sampleFiles_LWED.txt", col.names = F, row.names = F, quote = F)
write.table(sampleFiles_filtered_SIMP, "f_sampleFiles_SIMP.txt", col.names = F, row.names = F, quote = F)

# Create list of loci with under 10x avg read depth
under10 <- ls_ss %>%
  filter(AvgReadDepth < 10)
View(under10)

# Create filtered primerProbe files
ppf <- pp4 %>%
  filter(!Locus %in% under10$Locus)
View(ppf)
ppfLWED <- ppf %>%
  filter(!str_detect(Locus, "SIMP"))
ppfSIMP <- ppf %>%
  filter(!str_detect(Locus, "LWED"))

write.table(ppf, "./filteredLociSamples/primerProbeFile-f.txt", sep = "\t", row.names = F, quote = F)
write.table(ppfLWED, "./filteredLociSamples/primerProbeFile_LWED-f.txt", sep = "\t", row.names = F, quote = F)
write.table(ppfSIMP, "./filteredLociSamples/primerProbeFile_SIMP-f.txt", sep = "\t", row.names = F, quote = F)
```

Now we can re-run AmmpliconReadCounter.pl
```{r count reads for amplicons, eval=FALSE}
# Unfiltered reads
## All
system2("perl",
        args="AmpliconReadCounter.pl -p f_primerProbeFile.txt --files f_sampleFiles.txt --prefix f_")

## LWED
system2("perl",
        args="AmpliconReadCounter.pl -p f_primerProbeFile_LWED.txt --files f_sampleFiles_LWED --prefix f_LWED_")

## SIMP
system2("perl",
        args="AmpliconReadCounter.pl -p f_primerProbeFile_SIMP.txt --files f_sampleFiles_SIMP.txt --prefix f_SIMP_")
```


### 8.1) Genotyping
```{r Genotyping}
#load locus table and allele reads file
singleSNP_locusTable_f<-read.delim("f_LocusTable_singleSNPs.txt",header=TRUE,stringsAsFactors=FALSE)
singleSNP_alleleReads_f<-read.delim("f_AlleleReads_singleSNPs.txt",header=TRUE,row.names=1,stringsAsFactors=FALSE)

head(singleSNP_locusTable_f)
singleSNP_alleleReads_f[1:5,1:5]

singleSNP_locusTable_LWED_f<-read.delim("f_LWED_LocusTable_singleSNPs.txt",header=TRUE,stringsAsFactors=FALSE)
singleSNP_alleleReads_LWED_f<-read.delim("f_LWED_AlleleReads_singleSNPs.txt",header=TRUE,row.names=1,stringsAsFactors=FALSE)

head(singleSNP_locusTable_LWED)
singleSNP_alleleReads_LWED[1:5,1:5]

singleSNP_locusTable_SIMP_f<-read.delim("f_SIMP_LocusTable_singleSNPs.txt",header=TRUE,stringsAsFactors=FALSE)
singleSNP_alleleReads_SIMP_f<-read.delim("f_SIMP_AlleleReads_singleSNPs.txt",header=TRUE,row.names=1,stringsAsFactors=FALSE)

head(singleSNP_locusTable_SIMP)
singleSNP_alleleReads_SIMP[1:5,1:5]

#generate singleSNP genotypes using the polyGen algorithm
polyGenResults_singleSNP_f<-polyGen(singleSNP_locusTable_f,singleSNP_alleleReads_f)
polyGenResults_singleSNP_LWED_f<-polyGen(singleSNP_locusTable_LWED_f,singleSNP_alleleReads_LWED_f)
polyGenResults_singleSNP_SIMP_f<-polyGen(singleSNP_locusTable_SIMP_f,singleSNP_alleleReads_SIMP_f)

#look at first five rows and columns
polyGenResults_singleSNP_f[1:5,1:5]
polyGenResults_singleSNP_LWED_f[1:5,1:5]
polyGenResults_singleSNP_SIMP_f[1:5,1:5]

#write results
write.table(polyGenResults_singleSNP_f,"f_polyGenResults_singleSNP.txt",quote=FALSE,sep="\t")
write.table(polyGenResults_singleSNP_LWED_f,"f_polyGenResults_singleSNP_LWED.txt",quote=FALSE,sep="\t")
write.table(polyGenResults_singleSNP_SIMP_f,"f_polyGenResults_singleSNP_SIMP.txt",quote=FALSE,sep="\t")
```


### 8.2) Sample summaries
load sample summary from AmpliconReadCounter
```{r}
GTscore_individualSummary_f<-read.delim("f_GTscore_individualSummary.txt",header=TRUE,stringsAsFactors=FALSE)
head(f_GTscore_individualSummary)

GTscore_individualSummary_LWED_f<-read.delim("f_LWED_GTscore_individualSummary.txt",header=TRUE,stringsAsFactors=FALSE)
head(f_GTscore_individualSummary_LWED)

GTscore_individualSummary_SIMP_f<-read.delim("f_SIMP_GTscore_individualSummary.txt",header=TRUE,stringsAsFactors=FALSE)
head(f_GTscore_individualSummary_SIMP)
```

summarize single SNP results for samples
```{r}
singleSNP_sampleSummary_f<-summarizeSamples(f_polyGenResults_singleSNP,f_singleSNP_alleleReads)
head(f_singleSNP_sampleSummary)

singleSNP_sampleSummary_LWED_f<-summarizeSamples(f_polyGenResults_singleSNP_LWED,f_singleSNP_alleleReads_LWED)
head(f_singleSNP_sampleSummary_LWED)

singleSNP_sampleSummary_SIMP_f<-summarizeSamples(f_polyGenResults_singleSNP_SIMP,f_singleSNP_alleleReads_SIMP)
head(f_singleSNP_sampleSummary_SIMP)
```

combine AmpliconReadCounter individual summary data with GTscore sample summary
```{r}
# make new copies
gt_indivSummary_f <- GTscore_individualSummary_f
gt_indivSummary_LWED_f <- GTscore_individualSummary_LWED_f
gt_indivSummary_SIMP_f <- GTscore_individualSummary_SIMP_f

#first adjust names from sample_genotypeRate_singleSNP to match GTscore_individualSummary (some of the GTscore functions change - to .)
gt_indivSummary_f$Sample <- sub('tamOpt-', 'tamOpt.', gt_indivSummary_f$Sample)
gt_indivSummary_f<-merge(gt_indivSummary_f,singleSNP_sampleSummary_f,by.x="Sample",by.y="sample")

gt_indivSummary_LWED_f$Sample <- sub('tamOpt-', 'tamOpt.', gt_indivSummary_LWED_f$Sample)
gt_indivSummary_LWED_f<-merge(gt_indivSummary_LWED_f,singleSNP_sampleSummary_LWED_f,by.x="Sample",by.y="sample")

gt_indivSummary_SIMP_f$Sample <- sub('tamOpt-', 'tamOpt.', gt_indivSummary_SIMP_f$Sample)
gt_indivSummary_SIMP_f<-merge(gt_indivSummary_SIMP_f,singleSNP_sampleSummary_SIMP_f,by.x="Sample",by.y="sample")

# Combine LWED & SIMP to form one
gt_indivSummary_combined_f <- rbind(gt_indivSummary_LWED_f, gt_indivSummary_SIMP_f)
View(gt_indivSummary_combined_f)

# Export
write.csv(gt_indivSummary_f, "./summaryFiles/f_individualSummary_FULL.csv", row.names = F)
write.csv(gt_indivSummary_LWED_f, "./summaryFiles/f_individualSummary_LWED_FULL.csv", row.names = F)
write.csv(gt_indivSummary_SIMP_f, "./summaryFiles/f_individualSummary_SIMP_FULL.csv", row.names = F)
write.csv(gt_indivSummary_combined_f, "./summaryFiles/f_individualSummary_combined_FULL.csv", row.names = F)
```

### 8.4) Locus summaries
```{r}
#summarize single SNP results
singleSNP_summary_f<-summarizeGTscore(singleSNP_alleleReads_f, singleSNP_locusTable_f, polyGenResults_singleSNP_f)
singleSNP_summary_LWED_f<-summarizeGTscore(singleSNP_alleleReads_LWED_f, singleSNP_locusTable_LWED_f, polyGenResults_singleSNP_LWED_f)
singleSNP_summary_SIMP_f<-summarizeGTscore(singleSNP_alleleReads_SIMP_f, singleSNP_locusTable_SIMP_f, polyGenResults_singleSNP_SIMP_f)
#view results
View(singleSNP_summary_f)
View(singleSNP_summary_LWED_f)
View(singleSNP_summary_SIMP_f)
#write results
write.table(singleSNP_summary_f,"./summaryFiles/f_singleSNP_summary.txt",quote=FALSE,sep="\t",row.names=FALSE)
write.table(singleSNP_summary_LWED_f,"./summaryFiles/f_singleSNP_summary_LWED.txt",quote=FALSE,sep="\t",row.names=FALSE)
write.table(singleSNP_summary_SIMP_f,"./summaryFiles/f_singleSNP_summary_SIMP.txt",quote=FALSE,sep="\t",row.names=FALSE)
```

May also be helpful to combine single SNP summaries with the GTscore locus summary created earlier:
```{r}
# Load data
ls_f <- read.table("f_GTscore_locusSummary.txt", header = T, sep = "\t")
ls_lwed_f <- read.table("LWED-f_GTscore_locusSummary.txt", header = T, sep = "\t")
ls_simp_f <- read.table("SIMP-f_GTscore_locusSummary.txt", header = T, sep = "\t")

# Separate summaries into results from shared and species-specific loci analyses
ls1_f <- ls_f %>%
  filter(!str_detect(Locus, "LWED|SIMP"))
ls_lwed1_f <- ls_lwed_f %>%
  filter(str_detect(Locus, "LWED"))
ls_simp1_f <- ls_simp_f %>%
  filter(str_detect(Locus, "SIMP"))

ss_f <- singleSNP_summary_f %>%
  filter(!str_detect(Locus_ID, "LWED|SIMP"))
ss_lwed_f <- singleSNP_summary_LWED_f %>%
  filter(str_detect(Locus_ID, "LWED"))
ss_simp_f <- singleSNP_summary_SIMP_f %>%
  filter(str_detect(Locus_ID, "SIMP"))

# Recombine gtscore & single snp summary files, then merge the two
ls_recombine_f <- rbind(ls1_f, ls_lwed1_f, ls_simp1_f)
View(ls_recombine_f)
ss_recombine_f <- rbind(ss_f, ss_lwed_f, ss_simp_f)
ss_recombine_f$Locus_ID <- substr(ss_recombine_f$Locus_ID,0,nchar(ss_recombine_f$Locus_ID)-4) # change locus names to match ls
View(ss_recombine_f)

ls_ss_f <- merge(ls_recombine_f, ss_recombine_f, by.x = "Locus", by.y = "Locus_ID") 
View(ls_ss_f)

# Export
write.csv(ls_ss_f, "./summaryFiles/f_locusSummary_combined.csv", row.names = F)
```
