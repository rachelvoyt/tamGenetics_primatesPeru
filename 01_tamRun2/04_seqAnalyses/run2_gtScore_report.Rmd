---
title: 'Report for tamGenetics sequencing Run 2'
author: Rachel Voyt
output: 
  rmdformats::downcute:
    downcute_theme: "chaos"
date: "2022-09-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
```

```{r, echo=FALSE}
library(here)
library(tidyverse)
library(TidyMultiqc)
library(HistDat)
library(matrixStats)
library(gsubfn)
library(scales)
library(kableExtra)
```

# 1 Overview

The following report is for "tamGenetics Run 2", the second MiSeq run. This run has a total of **142 samples**, including:

1.  **44 testing samples (+ 2 negatives)**, allowing us to assess:

    1.  Full vs. split primer pools
    2.  0.025 vs. 0.05 uM primer concentration
    3.  4 ul sample vs. dilute 1:1 sample with water
    4.  a couple chelex samples
    5.  blood samples run with the Burgess PCR1 protocol
    6.  Diluting PCR1 products 1:10 vs. 1:20 prior to running PCR2
    7.  duplicates for many of the above as well as for the fecal/hair/blood paired samples

2.  **30 paired samples (+ 4 PCR1 negatives + 1 PCR2 negative)**, with DNA extractions from the same 30 individuals across three different sample types: fecal, hair, and blood

## 1.1 Additional details on PCR conditions

This run includes three different sets of PCR1 conditions, including:

1.  "gt-seq" - generally follows the original gt-seq PCR1 conditions used by Campbell et al. (2015), but optimized for blood samples and our particular set of primers.

2.  "d" - follows the PCR1 conditions from Burgess et al. (2022), which they used successfully with fecal and hair samples

    1.  Note - this is the same protocol provided in the "Qiagen Multiplex PCR Handbook" for "Amplification of Microsatellite Loci using Multiplex PCR"

3.  "d-plus" - same conditions as "d", but with a 5-minute hotstart instead of 15 minutes. I changed the hotstart time because while the regular Qiagen Multiplex Mastermix requires a 15-minute hotstart, Qiagen Multiplex Mastermix PLUS requires only a 5-minute hotstart (both according to Qiagen documentation). It seemed better not to have our lower-quality samples at such a high temperature for so long a time, and since we're using the PLUS mastermix I opted to change the hotstart to 5 minutes. A couple notes on this:

    1.  Campbell et al. (2015) used the PLUS mastermix with a 15-min hotstart instead of 5-min, and I have been using those conditions with the blood samples without a problem.

    2.  Qiagen reps weren't able to tell me the difference between the PLUS vs. non-PLUS taqs, and there is no indication on the mastermix tube that it even contains the PLUS version despite coming in the Mastermix PLUS kit.

### "gt-seq" PCR1 conditions

| Step                      | Temp | Time | Cycles |
|---------------------------|------|------|--------|
| Taq activation            | 95C  | 15 m | 1      |
| Denaturation              | 94C  | 30 s |        |
| Annealing + 1C/s rampdown | 54C  | 90 s | 5      |
| Extension                 | 72C  | 90 s |        |
|                           |      |      |        |
| Denaturation              | 94C  | 30 s |        |
| Annealing                 | 60C  | 90 s | 20     |
| Extension                 | 72C  | 90 s |        |
|                           |      |      |        |
| Final extension           | 72C  | 10 m | 1      |
| Hold                      | 4C   | \-   | 1      |

### "d" & "d-plus" PCR1 conditions

| Step            | Temp | Time                          | Cycles |
|-----------------|------|-------------------------------|--------|
| Taq activation  | 95C  | 15 m ("d") OR 15 m ("d-plus") | 1      |
| Denaturation    | 94C  | 30 s                          |        |
| Annealing       | 60C  | 90 s                          | 35     |
| Extension       | 72C  | 60 s                          |        |
| Final extension | 60C  | 30 m                          | 1      |
| Hold            | 4C   | \-                            | 1      |

## 1.2 Additional details on primer pools

The primer pools tested include the following:

-   **Full pool** - where samples were run with ALL primers whose loci passed the optimization run

    -   **Primer Pool 1**: 221 loci (442 primers)

-   **Split pools** - where samples were run with only HALF the primers whose loci passed the optimization run

    -   **Primer Pool 2**: 111 loci (222 primers)

    -   **Primer Pool 3**: 110 loci (220 primers)

Split primer pools were tested with hair and fecal samples, with primarily hair samples included in the sequencing run.

# 2 Quality checks

I used fastQC to get sequence quality scores for each sample -- fastp is better for paired-end reads, but doesn't play nice when it comes to getting quality scores from the MultiQC report (though I do have the fastp-multiqc report as well).

## 2.1 Run FastQC & create MultiQC report

Step 1: Run FastQC & create MultiQC report

((*Note*: use "\--interactive" to force plots to tell you which line belongs to which sample, otherwise it will remove this option since there are so many samples in this run.))

```{bash eval = F}
conda activate fastqc-env
for i in ../01_run2Seqs/*; do fastqc $i; done
mv ../01_run2Seqs/*fastqc* .
conda activate multiqc-env
multiqc --interactive .
```

Step 2: Load FastQC MultiQC report to R

```{r}
MultiQCfastQCpath <- file.path("/home/rachelvoyt/Documents/UT-Grad/Development/repos/tamGenetics_primatesPeru/01_run2_fecalHairBlood/00_qualityChecksFastQC/multiqc_data", "multiqc_data.json")

MultiQCfastQC <- TidyMultiqc::load_multiqc(MultiQCfastQCpath, sections = c("general", "raw"))
```

## 2.2 Obtain median sequence quality scores

For the analyses in this section, I followed [this vignette](https://cran.r-project.org/web/packages/TidyMultiqc/vignettes/TidyMultiqc.html) provided by the makers of the TidyMultiqc package.

MultiQC reports do not provide a numerical summary statistic for read quality; they only have mapping quality and pass/fails for the per-base sequence quality. We instead need to pull this data from one of the plots -- I'm using the "Per Sequence Quality Scores" plot here:

```{r}
df <- TidyMultiqc::load_multiqc(
  MultiQCfastQCpath, 
  sections = 'plot',
  plots = "fastqc_per_sequence_quality_scores_plot")
```

This provides a nested data frame as a set of x, y pairs. As it's a histogram plot, we know that the `x` value is the quality score, and `y` is the number of times that score has been counted.

We can use tidyr to unnest the data, HistDat to create a HistDat object for each group, then purr to map each plot data frame into a row of summary statistics:

```{r}
df_unNest <- df %>%
  dplyr::mutate(
    purrr::map_dfr(plot.fastqc_per_sequence_quality_scores_plot, function(plot_df){
      hist = HistDat::HistDat(vals=plot_df$x, counts = plot_df$y)
      list(
        mean_qc = mean(hist),
        median_qc = median(hist),
        max_qc = max(hist)
      )
    }),
    plot.fastqc_per_sequence_quality_scores_plot = NULL
  )
```

This dataframe has separate rows for reads 1 & 2; we can rearrange that to make it easier to work with for our purposes. Since we're most interested in median quality, we'll just pull that value for each sample.

```{r}
seqQC_r1 <- df_unNest %>%
  select(c("metadata.sample_id", "median_qc")) %>%
  filter(grepl("R1", metadata.sample_id)) %>%
  rename(medianQC_r1 = median_qc) %>%
  mutate(sampleNo = substr(metadata.sample_id, start = 9, stop = 11))
seqQC_r2 <- df_unNest %>%
  select(c("metadata.sample_id", "median_qc")) %>%
  filter(grepl("R2", metadata.sample_id)) %>%
  rename(medianQC_r2 = median_qc) %>%
  mutate(sampleNo = substr(metadata.sample_id, start = 9, stop = 11))
seqQC <- merge(seqQC_r1, seqQC_r2, by = "sampleNo") %>%
  select(c("sampleNo", "medianQC_r1", "medianQC_r2")) %>%
  arrange(sampleNo)
```

Let's just take a peek at the distribution of sequence quality scores for now; we'll use it in our other analyses later on:

```{r}
ggplot(seqQC, aes(medianQC_r1)) +
  geom_bar(stat = "count") +
  theme_bw()
```

# 2 Loci & sample initial assessment

This section focuses on loci performance, which in turn requires an assessment of sample performance - we'll use the results here to identify underperforming loci and samples, then remove those from the loci/sample lists and re-run the GTscore pipeline before continuing our analyses.

## 2.1 Load files

Locus and summary files were created via the GTscore pipeline for analysis of GT-seq sequencing data from Run 2 ("GTscorePipeline_run2.Rmd"). Note that these sequences were not filtered prior to running them through the pipeline.

**Loci: GTscore summary file**

```{r}
# GTscore loci summary file
loci <- read.csv(here('./01_run2_fecalHairBlood/03_run2GTscore/summaryFiles/p123_master_locusSummary.csv'))
```

**Samples: MultiQC report & GTscore summary file**

```{r}
# GTscore summary file
samples <- read.csv(here('./01_run2_fecalHairBlood/03_run2GTscore/summaryFiles/p123_master_sampleSummary.csv'))

# Samples without the negative controls
samplesNoNeg <- samples %>%
  filter(!sampleType == "(-)")

# List negative controls
samplesNeg. <- samples %>%
  filter(sampleType == "(-)") %>%
  distinct(sampleID) %>%
  mutate(sampleID = gsub("_", ".", sampleID))
```

## 2.2 Loci with zero reads

For now we just want to see which loci produced ZERO reads. We end up with just three -- HOWEVER, since they only got zero reads in the split primer pool, but not the full primer pull, we can retain these loci.

```{r}
noReads <- loci %>%
  filter(Primer.Probe.Reads == "0") %>%
  select(c(Locus, primerPool))
noReads %>%
  kbl(align = "c") %>%
  kable_material(full_width = F)
```

## 2.3 Underperforming samples

To get a better sense of how the loci performed, we also need to identify and remove underperforming samples.

Note that I'm considering samples with \< 50% genotyping success as "failed", a fairly low cutoff.

### 2.3.1 Which samples failed?

69 samples had less than a 50% genotyping success rate. Seven of these are negative controls, and 62 are actual samples - all of which were either fecal or hair sample types.

```{r}
failedSamples <- samples %>%
  filter(GenotypeRate < 0.5) %>%
  distinct_at(vars(sampleID), .keep_all = T)
length(failedSamples$sampleID) # 69 samples out of 142
table(failedSamples$sampleType)
```

Nearly all failed samples (59 out of 62) were run with Primer Pool 1.

57 out of those 59 were from the paired 30x3 plate, including 28 fecal samples and 29 hair samples.

```{r}
# Remove negative controls
failedSamples_noNeg <- failedSamples %>%
  filter(!sampleType == "(-)")
table(failedSamples_noNeg$primerPool.x)

# Visualize failed samples across primer pools
ggplot(failedSamples, aes(as.character(primerPool.x), fill=as.character(primerPool.x))) +
  geom_bar(stat = "count") +
  labs(x = "Primer Pool", y = "Number of samples", fill = "Primer Pool", title = "Number of samples failed across primer pools")

# How many of the 62 fecal/hair samples were from the 30x3 test?
failedSamples_fhb <- failedSamples %>%
  filter(sampleType %in% c("fecal", "hair")) %>%
  filter(str_detect(pcr1Description, "(again)"))
length(failedSamples_fhb$sampleID) # 57 out of 62 samples
sum(failedSamples_fhb$sampleType == "fecal") # 28 fecal samples
sum(failedSamples_fhb$sampleType == "hair") # 29 hair samples
```

As for the other 5 samples, we have 3 fecal samples, 1 hair sample, and 1 hair sample extracted with chelex:

-   \_037 (hair) & \_032 (fecal) were both run with Primer Pool 1, which seems to give low genotyping rates for fecal/hair samples regardless of primer-probe reads (see below)
    -   With that said, \_032 did have a geno-rate of 0.49 - so pretty close to our cutoff
    -   Note also that I ran 3 fecals and 3 hair samples total with Primer Pool 1
-   \_026 (fecal) had only 6 primer-probe reads, so low geno-rate makes sense
-   \_012 only had 2 ul sample added to the PCR1 reaction (part of a dilution test)
-   \_031 was a chelex extraction - I found these to be hit or miss with whether they gave amplicon bands

```{r}
failedSamples_other <- failedSamples_noNeg %>%
  filter(!str_detect(pcr1Description, "(again)")) %>%
  select(c(sampleID, Primer.Probe.Reads, GenotypeRate, primerPool.x, animalID, sampleType, primerCon_uM, ulAdded, pcr1Protocol))
failedSamples_other %>%
  kbl(align = "c", col.names = c("Sample ID", "Primer probe reads", "Genotype rate", "Primer pool", "Animal ID", "Sample type", "Primer concentration (uM)", "uLs of sample added", "PCR1 protocol")) %>%
  kable_material(full_width = F) %>%
  scroll_box(fixed_thead = list(enabled = T, background = "#363636"))
```

### 2.3.2 Why did the samples fail?

The analyses below show us that that our failed samples have the following characteristics:

1.  \< 50% of loci were successfully genotyped

2.  For the loci that *were* genotyped, we often get a LOT of primer-probe reads

3.  Median sequence quality for those primer-probe reads is quite good across nearly samples

4.  All of which suggests that the loci that amplified for our failed samples may be overamplifiers; supported by my brief investigation below

Beyond that though, the conditions that appear to have caused sample failure appear to be related to 1) sample quality and 2) primer pool, where the fecal/hair samples run with the full primer pool were more likely to fail.

#### 2.3.2.1 Primer-probe reads

Despite a low genotyping rate, failed samples often have a high primer-probe read count.

```{r}
# Barplot showing primer-probe reads per sample, colored by primer pool
ggplot(failedSamples_noNeg, aes(x=Primer.Probe.Reads, y=reorder(sampleID,Primer.Probe.Reads))) +
  geom_bar(stat = "identity", aes(fill=as.character(sampleType))) +
  labs(title = "Primer-probe reads per failed sample", x="Total primer-probe reads", y="", fill="Sample type") +
  theme(plot.title=element_text(hjust=0.5),plot.subtitle=element_text(hjust=0.5)) +
  theme_bw() +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

And when we look across the entire dataset, while we see a general increase in genotype success with increasing read count, there are still a lot of successful samples (genotype rate \> 50%) with primer-probe read counts on par with that of the failed samples.

```{r}
# Scatterplot showing primer-probe reads vs. genotype rate for all samples, colored by primer pool. Dashed line added at 50% genotype rate
ggplot() +
  geom_point(data=samples,aes(x=Primer.Probe.Reads,y=GenotypeRate, shape=sampleType, color=as.character(primerPool.x)), size = 3) +
               labs(title="Genotype rate vs total primer-probe reads per sample", x="Total primer-probe reads", y="Genotype rate") +
  theme(plot.title=element_text(hjust=0.5),plot.subtitle=element_text(hjust=0.5)) +
  geom_hline(yintercept=0.5,lty="dashed") +
  labs(color = "Primer pool", shape = "Sample type") +
  theme_bw()
```

#### 2.3.2.2 Read quality

With that said, the number of primer-probe read counts don't necessarily matter if these reads are low quality -- HOWEVER, we can see below that median read quality for most failed samples (aside from those that just completely didn't work) is actually quite good.

Note that I've only included read 1 QC scores here - a quick check showed that read 2 score look the same.

```{r}
# Subset failedSamples to get sample type & primer pool
failedSamples_list <- failedSamples_noNeg %>%
  mutate(sampleNo = substr(sampleID, start = 9, stop = 11)) %>%
  select(c(sampleID, sampleNo, sampleType))

seqQC_failedSamples <- seqQC %>%
  filter(seqQC$sampleNo %in% failedSamples_list$sampleNo) %>%
  left_join(x = ., y = failedSamples_list, by = "sampleNo")

ggplot(seqQC_failedSamples, aes(x = reorder(sampleNo, medianQC_r1), y = medianQC_r1, fill=sampleType)) +
  geom_bar(stat = "identity") +
  labs(x = "Sample number", y = "Median QC - Read 1", fill = "Species", title = "Median sequence QC per failed sample") +
  theme_bw() +
  theme(axis.text.x=element_text(angle=90,hjust=1))
```

#### 2.3.2.3 Distribution of reads

If we have low genotyping success per sample, but lot of primer-probe reads per sample plus a high median sequence-quality per sample, this instead suggests that the reads from which these values were calculated are representative of only a small subset of loci; i.e., some loci are overamplifying.

To investigate, we can look at the reads per locus per sample and see how they're distributed.

##### Entire dataset

First we'll look at the dataset as a whole, which shows us that **we have a handful of loci that are overrepresented.**

```{r}
# Load read counts
readCounts <- read.table(here("./01_run2_fecalHairBlood/03_run2GTscore/fullSet_AlleleReads_singleSNPs.txt"))

# First set up a function to add the read counts per allele for each locus, using package gsubfn
repl <- function(x) gsubfn("(\\d+),(\\d+)", ~ as.numeric(x) + as.numeric(y), paste(x))

# Then apply the function to readCounts & get the sum & median of all reads for each locus
readCounts_all <- replace(readCounts, TRUE, lapply(readCounts, repl)) %>%
  rownames_to_column("Locus") %>%
  mutate(Locus = sub("(_[^_]+)_.*", "\\1", Locus)) %>%
  column_to_rownames("Locus") %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column("sampleID") %>%
  mutate(sampleID = substr(sampleID, start = 1, stop = 11)) %>%
  filter(!sampleID %in% samplesNeg.$sampleID) %>%
  column_to_rownames("sampleID") %>%
  t() %>%
  as.data.frame() %>%
  mutate(across(everything(),as.numeric)) %>%
  mutate(readSum = rowSums(.[1:135])) %>%
  mutate(readMedian = rowMedians(as.matrix(.[,c(1:135)])))

# Define a function to find outliers
findoutlier <- function(x) {
  return(x < quantile(x, .25) - 1.5*IQR(x) | x > quantile(x, .75) + 1.5*IQR(x))
}

# Subset readCounts_all just to the sum & median for each locus, then note outliers
sumReads_perLocus <- readCounts_all %>%
  rownames_to_column("Locus") %>%
  select(c("Locus", "readSum", "readMedian")) %>%
  mutate(sumOutlier = ifelse(findoutlier(readSum), Locus, NA)) %>%
  relocate(sumOutlier, .after = readSum) %>%
  mutate(medianOutlier = ifelse(findoutlier(readMedian), Locus, NA)) %>%
  relocate(medianOutlier, .after = readMedian) %>%
  arrange(-readSum)
summary(sumReads_perLocus$readSum)
summary(sumReads_perLocus$readMedian)

# Plots - SUM
ggplot(sumReads_perLocus, aes(x=readSum, y=factor(0))) +
  geom_boxplot() +
  labs(title = "Total reads per locus (all samples)", x = "Total number of reads", y = "") +
  theme_bw()

ggplot(sumReads_perLocus, aes(x = readSum, y = reorder(Locus, readSum))) +
  geom_bar(stat = "identity") +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) +
  labs(title = "Total reads per locus (all samples)", x = "Total number of reads", y = "")

# Plots - MEDIAN
ggplot(sumReads_perLocus, aes(x=readMedian, y=factor(0))) +
  geom_boxplot() +
  labs(title = "Median reads per locus (all samples)", x = "Median number of reads", y = "") +
  theme_bw()

ggplot(sumReads_perLocus, aes(x = readMedian, y = reorder(Locus, readMedian))) +
  geom_bar(stat = "identity") +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) +
  labs(title = "Median reads per locus (all samples)", x = "Median number of reads", y = "")
```

In total, **we have 22 outliers when looking at total reads, and 40 outliers when looking at median reads**. NOTE, however, that these values are based on a dataset that 1) includes underperforming samples, and 2) isn't subset by species or primer pool, which makes it hard to say whether they're truly overamplifying. With that said, INDID_389.1 (and possibly SIMP_356.1) may be exceptions, with these two holding the spots for highest total and median read counts.

```{r}
sumReads_perLocus %>%
  arrange(-readSum) %>%
  kbl(align = "c", col.names = c("Locus", "Total primer-probe reads", "Outlier locus (sum)", "Median primer-probe reads", "Outlier locus (median)")) %>%
  kable_material(full_width = F) %>%
  scroll_box(height = "500px", fixed_thead = list(enabled = T, background = "#363636"))
length(sumReads_perLocus$medianOutlier %>%
         na.omit())
```

##### Failed samples only

We can now look specifically at the failed samples, where we again see a number of outliers (46 here). INDID_389.1 and SIMP_356.1 are high here as well, along with SIMP_311.3. A couple things to note--

-   The median number of reads for these loci is *higher* than with the full dataset

-   Over half of the 200,000 total reads that we saw for INDID_389.1 in the full dataset seem to be coming from these failed samples

Which means that perhaps these loci aren't necessarily overamplifiers generally, but are more likely to do so with lower-quality samples.

```{r}
# List sampleIDs from failedSamples & reformat
failedSamples_rcList <- failedSamples_list %>%
  mutate(sampleID = gsub("_", ".", sampleID))
  
# Subset to failed samples and recalculate sums & medians
readCounts_failedSamples <- readCounts_all %>%
  select(failedSamples_rcList$sampleID) %>%
  mutate(across(everything(),as.numeric)) %>%
  mutate(readSum = rowSums(.[1:62])) %>%
  mutate(readMedian = rowMedians(as.matrix(.[,c(1:62)])))
  
sumReads_perLocus_failedSamples <- readCounts_failedSamples %>%
  rownames_to_column("Locus") %>%
  select(c("Locus", "readSum", "readMedian")) %>%
  mutate(sumOutlier = ifelse(findoutlier(readSum), Locus, NA)) %>%
  relocate(sumOutlier, .after = readSum) %>%
  mutate(medianOutlier = ifelse(findoutlier(readMedian), Locus, NA)) %>%
  relocate(medianOutlier, .after = readMedian) %>%
  arrange(-readSum)
summary(sumReads_perLocus_failedSamples$readSum)
summary(sumReads_perLocus_failedSamples$readMedian)

# Table
sumReads_perLocus_failedSamples %>%
  dplyr::select(c(readSum, sumOutlier, readMedian, medianOutlier)) %>%
  na.omit() %>%
  arrange(-readSum) %>%
  kbl(align = "c", col.names = c("Total primer-probe reads", "Outlier locus (sum)", "Median primer-probe reads", "Outlier locus (median)")) %>%
  kable_material(full_width = F) %>%
  scroll_box(height = "500px", fixed_thead = list(enabled = T, background = "#363636"))

# Plots
## SUM
ggplot(sumReads_perLocus_failedSamples, aes(x = readSum, y = reorder(Locus, readSum))) +
  geom_bar(stat = "identity") +
  labs(title = "Total reads per locus (failed samples)", x = "Number of reads", y = "") +
   theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) +
  scale_x_continuous(labels = comma)

ggplot(sumReads_perLocus_failedSamples, aes(x=readSum, y=factor(0))) +
  geom_boxplot() +
  labs(title = "Total reads per locus (failed samples)", x = "Number of reads", y = "") +
  scale_x_continuous(labels = comma)

## MEDIAN
ggplot(sumReads_perLocus_failedSamples, aes(x = readMedian, y = reorder(Locus, readMedian))) +
  geom_bar(stat = "identity") +
  labs(title = "Median reads per locus (failed samples)", x = "Median number of reads", y = "") +
   theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) +
  scale_x_continuous(labels = comma)

ggplot(sumReads_perLocus_failedSamples, aes(x=readMedian, y=factor(0))) +
  geom_boxplot() +
  labs(title = "Median reads per locus (failed samples)", x = "Median number of reads", y = "") +
  scale_x_continuous(labels = comma)
```

##### Successful samples only

We can now check whether these same loci overamplify when samples have \> 50% genotype success. INDID_389.1 is no longer at the top spot (but still overrepresented); instead we see a lot of the species-specific individual IDs as outliers.

```{r}
# Subset to successful samples and recalculate sumReads
readCounts_passedSamples <- readCounts_all %>%
  select(!failedSamples_rcList$sampleID) %>%
  mutate(across(everything(),as.numeric)) %>%
  mutate(readSum = rowSums(.[1:73])) %>%
  mutate(readMedian = rowMedians(as.matrix(.[,c(1:73)])))
  
sumReads_perLocus_passedSamples <- readCounts_passedSamples %>%
  rownames_to_column("Locus") %>%
  select(c("Locus", "readSum", "readMedian")) %>%
  mutate(sumOutlier = ifelse(findoutlier(readSum), Locus, NA)) %>%
  relocate(sumOutlier, .after = readSum) %>%
  mutate(medianOutlier = ifelse(findoutlier(readMedian), Locus, NA)) %>%
  relocate(medianOutlier, .after = readMedian) %>%
  arrange(-readSum)
summary(sumReads_perLocus_passedSamples$readSum)
summary(sumReads_perLocus_passedSamples$readMedian)

# Table
sumReads_perLocus_passedSamples %>%
  select(c(readSum, sumOutlier, readMedian, medianOutlier)) %>%
  na.omit() %>%
  arrange(-readSum) %>%
  kbl(align = "c", col.names = c("Total primer-probe reads", "Outlier (total reads)", "Median primer-probe reads", "Outlier (medians)")) %>%
  kable_material(full_width = F) %>%
  scroll_box(height = "500px", fixed_thead = list(enabled = T, background = "#363636"))

# Plots
## SUM
ggplot(sumReads_perLocus_passedSamples, aes(x = readSum, y = reorder(Locus, readSum))) +
  geom_bar(stat = "identity") +
  labs(title = "Total reads per locus (successful samples)", x = "Total reads", y = "") +
  scale_x_continuous(labels = comma) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

ggplot(sumReads_perLocus_passedSamples, aes(x=readSum, y=factor(0))) +
  geom_boxplot() +
  labs(title = "Total reads per locus (successful samples)", x = "Total reads", y = "") +
  scale_x_continuous(labels = comma)

## MEDIAN
ggplot(sumReads_perLocus_passedSamples, aes(x = readMedian, y = reorder(Locus, readMedian))) +
  geom_bar(stat = "identity") +
  labs(title = "Median reads per locus (successful samples)", x = "Median reads", y = "") +
  scale_x_continuous(labels = comma) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

ggplot(sumReads_perLocus_passedSamples, aes(x=readMedian, y=factor(0))) +
  geom_boxplot() +
  labs(title = "Median reads per locus (successful samples)", x = "Median reads", y = "") +
  scale_x_continuous(labels = comma)
```

##### A closer look at INDID_389.1

I wanted to look into INDID_389.1 a bit further since it had such a high read count (200,000 total reads). We saw earlier that a little over half of these reads were coming from the failed samples, and here we see that the samples with the highest read counts for this locus were run with Primer Pool 1.

(Note that Primer Pool 2 does not contain this locus.)

```{r}
readCounts_indid389.1 <- readCounts_all %>%
  select(-readSum) %>%
  rownames_to_column("Locus") %>%
  filter(Locus == "INDID_389.1") %>%
  column_to_rownames("Locus") %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column("sampleID") %>%
  mutate(sampleID = gsub("\\.", "_", sampleID)) %>%
  arrange(-INDID_389.1)
summary(readCounts_indid389.1$INDID_389.1)

readCounts_indid389.1_md <- merge(readCounts_indid389.1, samples, by = "sampleID") %>%
  select(c(sampleID, INDID_389.1, sampleType, primerPool.x)) %>%
  arrange(INDID_389.1)

ggplot(readCounts_indid389.1_md, aes(x=as.character(primerPool.x), y=INDID_389.1)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(aes(color=sampleType)) +
  labs(x = "Primer pool", y = "Reads per sample", title = "INDID_389.1 reads per sample across primer pools") +
  theme_bw()

readCounts_indid389.1_md %>%
  arrange(-INDID_389.1) %>%
  kbl(align = "c", col.names = c("Sample ID", "Reads for INDID_389.1", "Sample type", "Primer pool")) %>%
  kable_material(full_width = F) %>%
  scroll_box(height = "500px", fixed_thead = list(enabled = T, background = "#363636"))
```

#### 2.3.2.3 Broader reasons for sample failure

Beyond characterizing the reads themselves, we also need to look back at the conditions that may have produced those reads. These conditions are most related to a combination of 1) sample type and 2) primer pool - Burgess et al. (2022) had similar results when running low-quality samples (fecal & hair) with their full primer pool as well.

We saw this earlier in "Which samples failed?", which showed that all samples with \< 50% genotype success were either fecal or hair samples, and nearly all of these were run with Primer Pool 1. However, those samples were also almost all part of the 30x3 set, prompting a couple questions:

-   Is sample failure primarily related to Primer Pool?

-   Is sample failure primarily related to other conditions, perhaps to do with how the 30x3 samples were prepped vs. the test samples?

We can get at this a bit by looking at the fecal/hair samples that were run both in the paired-plate AND in a separate test, all with Primer Pool 1. Boxplots suggest that **samples had a lower genotype rate when run in the paired-plate (fecal-hair-blood) vs. the test.**

While we have a small sample size, the data is normally distributed, and a paired t-test shows that **this difference is statistically significant, with a mean difference between samples of 15%.**

```{r}
fhbVtest <- samples %>%
  filter(xtnTube %in% c('F12', 'F1', 'F8', '4-H5', '23', '169')) %>%
  filter(primerPool.x == "1") %>%
  mutate(pcr1Description2 = recode(pcr1Description, 
                                   "test PCR with fecals & hair" = "testSamples",
                                   "set 2 (hair) again" = "fhbSamples",
                                   "set 1 (fecal) again" = "fhbSamples"))

ggplot(fhbVtest, aes(x=pcr1Description2, y=GenotypeRate)) +
  geom_boxplot() +
  geom_jitter(aes(shape=xtnTube)) +
  labs(x = "PCR1 set", y = "Genotype rate")


## Is this difference significant?
ttest <- fhbVtest %>%
  select(c("pcr1Description2", "GenotypeRate"))

### Small sample size; do Shapiro-Wilk normality test to see if normally distributed (H-null = normal, H-alt = not normal)
d <- with(ttest, 
        GenotypeRate[pcr1Description2 == "testSamples"] - GenotypeRate[pcr1Description2 == "fhbSamples"])
shapiro.test(d) # normally distributed

t.test(GenotypeRate ~ pcr1Description2, data = fhbVtest, paired = T) # difference is statistically significant
```

However, if we pull out the samples that were *not* in the 30x3 plate but *were* run in both full and split pools in my set of testing samples (including only those where the other variables are the same, e.g., pcr1 dilution level), we see an even larger difference between samples run with Primer Pool 1 vs. the split pools. From this, we see that **genotype success is significantly higher in the split pools vs. the full pool**, and difference in medians for each group is 10-20% higher than that seen with primer pool 1 samples in 30x3 vs. testing sample sets.

-   34% higher genotyping success with Primer Pool 2 (median 0.8837123) vs. Primer Pool 1 (median 0.5449735)
-   26% higher genotyping success with Primer Pool 3 (median 0.8088697) vs. Primer Pool 1 (median 0.5449735)

```{r}
# Subset data
splitTest <- samples %>%
  filter(xtnTube %in% c("4-C1","4-F3","4-G8","4-H2","4-H8")) %>%
  filter(dilution == "‘1:20") %>%
  filter(pcr1Protocol == "d-plus")

splitTest <- samples %>%
  filter(sampleType %in% c("hair", "fecal")) %>%
  filter(pcr1Protocol == "d-plus") %>%
  filter(dilution == "‘1:20") %>%
  filter(primerCon_uM == "0.025") %>%
  filter(ulAdded == "4") %>%
  filter(!pcr1Description %in% c("set 2 (hair) again", "set 1 (fecal) again"))

# Genotype rate per pool
ggplot(splitTest, aes(x=as.character(primerPool.x), y=GenotypeRate, fill=as.character(primerPool.x))) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter() +
  labs(x = "Primer pool", y = "Genotype rate", fill="Primer pool") +
  ggtitle("Genotype success per pool for testing samples") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

## Is this difference significant?
ttest2 <- splitTest %>%
  select(c(as.character("primerPool.x"), "GenotypeRate")) %>%
  dplyr::rename(primerPool = primerPool.x)

ttest2_1v2 <- ttest2 %>%
  filter(primerPool %in% c("1", "2"))

ttest2_1v3 <- ttest2 %>%
  filter(primerPool %in% c("1", "3"))

### Small sample size; do Shapiro-Wilk normality test to see if normally distributed (H-null = normal, H-alt = not normal)
with(ttest2, shapiro.test(GenotypeRate[primerPool == "1"])) 
with(ttest2, shapiro.test(GenotypeRate[primerPool == "2"]))
with(ttest2, shapiro.test(GenotypeRate[primerPool == "3"]))

# Since samples run with Primer Pool 2 aren't normally distributed, we'll run a Wilcoxon test instead of an unpaired t-test for primer pools 1 vs. 2
wilcox.test(GenotypeRate ~ as.character(primerPool), data = ttest2_1v2, exact = F) # difference is statistically significant

# Can run a regular unpaired t-test for primer pools 1 vs. 3
t.test(GenotypeRate ~ as.character(primerPool), data = ttest2_1v3, paired = F) # difference is statistically significant
```

# 3 Locus assessment post-filter

After identifying zero-read loci and underperforming samples in parts I and II, I removed these loci and samples from the primer-probe files and sample files, respectively, and reran the GTscore pipeline (GTscorePipeline_run2_postFilter.Rmd).

Locus summary file from GTscore pipeline:

```{r}
lociPF <- read.csv(here('./01_run2_fecalHairBlood/03_run2GTscore/summaryFiles/p123_postFilter_master_locusSummary.csv'))
```

Given the differences in sample success between full and split primer pools, I chose to assess locus performance between full and split pools as well - details below.

### 3.1 Loci that failed in full AND split primer pools

I assessed loci performance via genotype success rate, considering loci with genotype success rates under 50% in BOTH full and split pools as failures. I use genotype success here rather than average read depth because the two don't always go hand in hand (most of the time, but not always) - and of the two variables, I think that genotype success is ultimately more important since read depth doesn't mean anything if they're not good enough to give a trustworthy genotype.

In total, there were **ten loci that failed in BOTH full and split pools**, including **nine INDID loci** and **one SEXID locus**:

```{r}
# Get loci with under 50% genotype rate
lociPF_under50 <- lociPF %>%
  filter(GenotypeRate < 0.5)

# Subset to loci performing poorly in both full and split pools
lociPF_under50Paired <- lociPF_under50 %>%
  group_by(Locus) %>% filter(n()>1)
length(unique(lociPF_under50Paired$Locus))
```

### 3.2 Loci that failed in full OR split pools

There were **38 loci that failed in one, but not both, full and split primer pools**.

```{r}
# Get a list of unique loci with genotype rates under 50%
lociPF_under50_names <- unique(lociPF_under50$Locus)

# Subset the locus summary to loci that have <50% genotype rate in at least one, but not both, full and split primer pools
lociPF_under50b <- lociPF %>%
  filter(Locus %in% lociPF_under50_names) %>%
  filter(!Locus %in% lociPF_under50Paired$Locus)
length(unique(lociPF_under50b$Locus))
```

We see in this first plot that **we have many more locus failures in Primer Pool 1 vs. either of the split pools.**

```{r}
# Primer pool vs. locus genotype rate
grVpp <- ggplot(lociPF, aes(x=as.character(primerPool), y=GenotypeRate, fill=as.character(primerPool))) +
  geom_boxplot(outlier.shape = NA, alpha=0.5) +
  geom_jitter(aes(color=as.character(primerPool))) +
  xlab("Primer Pool") +
  ylab("Genotype Rate") +
  ggtitle("Locus genotype rate vs. primer pool") +
  geom_hline(yintercept=0.5,lty="dashed") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
grVpp
```

And can look at this a bit more closely using a dumbbell plot, which shows us that **in 30 out of 38 cases,** **loci that failed in the full pool did better (often a LOT better) in the split pools**.

Something to consider for the 8 loci that failed in the split pools - all of these were in Primer Pool 3, which was run with 10 hair samples (11 including the one underperforming sample that was filtered out).

```{r}
# Recode Primer Pools 2 & 3 to "splitPool"
lociPF_under50c <- lociPF_under50b %>%
  mutate(primerPool2 = recode(primerPool, "2"="splitPool", "3"="splitPool", "1"="fullPool"))
length(unique(lociPF_under50c$Locus))

# Create new df for full vs. split primer pools, put fullPool in order of genotype rate then match the splitpool
fullPool <- lociPF_under50c %>%
  filter(primerPool2 == "fullPool") %>%
  arrange(GenotypeRate)
splitPool <- lociPF_under50c %>%
  filter(primerPool2 == "splitPool")
splitPool <- splitPool[match(fullPool$Locus, splitPool$Locus),]

# Now we can create our dumbbell plot
dplot <- ggplot(lociPF_under50c) +
  geom_segment(data = fullPool,
                aes(x=GenotypeRate, y=reorder(Locus, GenotypeRate),
                    yend=splitPool$Locus, xend=splitPool$GenotypeRate),
               color = "#aeb6bf",
              size = 2, #Note that I sized the segment to fit the points
              alpha = .5) +
  geom_point(aes(x=GenotypeRate, y=Locus, color=primerPool2), size=2) +
  labs(x="Genotype Rate", y="Locus Name", color = "Primer pool") +
  theme_bw()
dplot
```

Given this discrepancy in loci performance between primer pools, it's hard to judge which are working best - might be worth it in future to pull those that failed in both full and split primer pools, but for the rest it's hard to say.

# 4 Additional sample tests

## 4.1 Blood samples run with "gt-seq" vs. "d-plus" PCR1 protocol

No significant difference between PCR1 protocols for blood; **continue with the gt-seq PCR1 protocol for blood samples.**

```{r}
# Pull out blood samples tested with d-plus protocol
blood_pcr1Test_samples <- samples %>%
  filter(sampleType == "blood") %>%
  filter(dilution == "‘1:20") %>%
  filter(primerCon_uM == "0.025") %>%
  filter(pcr1Protocol %in% c("d-plus")) %>%
  select(xtnTube) %>%
  pull()

blood_pcr1Test <- samples %>%
  filter(xtnTube %in% blood_pcr1Test_samples)

ggplot(blood_pcr1Test, aes(x=as.character(pcr1Protocol), y=GenotypeRate, fill=pcr1Protocol)) +
  geom_boxplot(position = position_dodge(1), alpha = 0.2) +
  geom_point(position=position_jitterdodge(jitter.width = 0.1,dodge.width = 1), aes(shape=xtnTube)) +
  xlab("PCR1 conditions") +
  ylab("Genotype rate") +
  theme_bw()

### Small sample size; do Shapiro-Wilk normality test to see if normally distributed (H-null = normal, H-alt = not normal)
b <- with(blood_pcr1Test, 
        GenotypeRate[pcr1Protocol == "d-plus"] - GenotypeRate[pcr1Protocol == "gt-seq"])
shapiro.test(b) # normally distributed; continue with paired t-test

t.test(GenotypeRate ~ pcr1Protocol, data = blood_pcr1Test, paired = T) 
```

## 4.2 Dilution 1:20 vs. 1:10

The dilution test includes 3 samples (xtnTube 4-C1, 4-F3, and 4-G8), with the same 3 samples used for each of the 3 primer pools. There is no clear difference between the two dilution conditions; **continue with 1:20 dilution**.

```{r}
# Create list of samples diluted 1:10
oneTenSamples <- samples %>%
  filter(dilution == "‘1:10") %>%
  select(xtnTube) %>%
  pull()

# Pull out same samples from the dataset
dilutionTest <- samples %>%
  filter(xtnTube %in% oneTenSamples)

# Genotype rate per dilution type
ggplot(dilutionTest, aes(x=as.character(primerPool.x), y=GenotypeRate, fill=dilution)) +
  geom_boxplot(position = position_dodge(1), alpha = 0.2) +
  geom_point(position=position_jitterdodge(jitter.width = 0.05,dodge.width = 1), aes(shape=xtnTube, group=dilution, color=dilution), size = 3) +
  xlab("Primer pool") +
  ylab("Genotype rate") +
  theme_bw()
```

# 5 Sample genotype assessment

Using the genotypes generated in the GTscore pipeline, we can look to see if our genotypes are telling us what we need to know -- specifically:

-   Are sex and species genotypes congruent with metadata?
-   Are INDID and species-specific INDID loci to differentiate individuals?
-   Among duplicated individuals, how do genotypes compare...
    -   within the same sample types?

    -   between sample types?

    -   overall?

Since I just want to know if the genotypes are matching up correctly, regardless of how many loci we have genotypes for per sample, in this section I'll be using *all* samples, including those with \< 50% genotype rate.

```{r}
knitr::knit_exit()
```

## 5.1 Sex & species loci vs. metadata

### 5.1.1 Load genotypes & keys

Genotype assignments are from the GTscore pipeline, which uses the "polygen" function, a custom-made function from McKinney et al. (2018), to assign genotypes.

```{r}
fullSet_genos <- read.table(here("./01_run2_fecalHairBlood/03_run2GTscore/fullSet_polyGenResults_singleSNP.txt")) %>%
  rownames_to_column("Locus") %>%
  mutate(Locus = sub("(_[^_]+)_.*", "\\1", Locus)) %>%
  column_to_rownames("Locus") %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column("sampleID") %>%
  mutate(sampleID = substr(sampleID, start = 1, stop = 11)) %>%
  column_to_rownames("sampleID") %>%
  t() %>%
  as.data.frame()

fullSet_genos_sexid <- fullSet_genos %>%
  rownames_to_column("Locus") %>%
  filter(str_detect(Locus, "SEXID"))
```

Genotype keys:

```{r}
sexKey_original <- read.csv(here("./01_run2_fecalHairBlood/sexSNP_key_original.csv"))
speciesKey_original <- read.csv(here("./01_run2_fecalHairBlood/speciesSNP_key_original.csv"))
```

Reformat sex key:

```{r}
# First add the loci names that I've been using using our primer-probe file 
primerProbe_sexid <- read.table(here("./01_run2_fecalHairBlood/03_run2GTscore/run2_primerProbeFile_original.txt"), header = T) %>% 
  select(c(Locus, Primer)) %>% 
  filter(str_detect(Locus, "SEXID"))
primerProbe_sexid$Primer

sexKey_original_plusLoci <- sexKey_original %>% 
  mutate(primer_f = toupper(primer_f))
sexKey_original_plusLoci <- merge(sexKey_original_plusLoci, primerProbe_sexid, by.x = "primer_f", by.y = "Primer") %>%
  select(c(Locus, targetSpecies, lwed_M, lwed_F, simp_M, simp_F))

sexKey_lwed_M <- sexKey_original_plusLoci %>%
  filter(!targetSpecies == "simp") %>%
  select(c(Locus, targetSpecies, lwed_M)) %>%
  dplyr::rename(genotype = lwed_M) %>%
  mutate(sex = "M") %>%
  na.omit()
sexKey_lwed_F <- sexKey_original_plusLoci %>%
  filter(!targetSpecies == "simp") %>%
  select(c(Locus, targetSpecies, lwed_F)) %>%
  dplyr::rename(genotype = lwed_F) %>%
  mutate(sex = "F") %>%
  na.omit()
sexKey_simp_M <- sexKey_original_plusLoci %>%
  filter(!targetSpecies == "simp") %>%
  select(c(Locus, targetSpecies, simp_M)) %>%
  dplyr::rename(genotype = simp_M) %>%
  mutate(sex = "M") %>%
  na.omit()
sexKey_simp_F <- sexKey_original_plusLoci %>%
  filter(!targetSpecies == "simp") %>%
  select(c(Locus, targetSpecies, simp_F)) %>%
  dplyr::rename(genotype = simp_F) %>%
  mutate(sex = "F") %>%
  na.omit()

sexKey <- rbind(sexKey_lwed_M, sexKey_lwed_F, sexKey_simp_M, sexKey_simp_F) %>%
  distinct()
```

Reformat species key:

```{r}

```

### 4.1.2 Sex assignments

Step 1: Check the genotypes against the sexKey to assign either F or M to each.

```{r}
# Prep sex key for merge
sexKey_toAssign <- sexKey %>%
  select(c(Locus, genotype, sex))

# Assign FM
fullSet_genos_sexid_FM <- fullSet_genos_sexid %>% 
  mutate(across(everything(), as.character)) %>%
  pivot_longer(!Locus,
               names_to = "sampleID",
               values_to = "genotype") %>%
  left_join(sexKey_toAssign, by = c("Locus", "genotype")) %>%
  mutate(sex = coalesce(sex, genotype)) %>%
  select(c(Locus, sampleID, sex)) %>%
  pivot_wider(names_from = sampleID,
              values_from = sex)
```

Step 2: Subset by primer pool and species, since loci are split across primer pools 2 & 3 and some sexid loci are species-specific

```{r}


```
